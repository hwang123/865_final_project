{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of 865 Project",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LmZU8UVM8rGR",
        "colab_type": "text"
      },
      "source": [
        "Sophia and Harry's Project!!!!!!!\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kAF23DyX9AOm",
        "colab_type": "text"
      },
      "source": [
        "Steps:\n",
        "\n",
        "1) get input data\n",
        "2) build model architecture\n",
        "3) write the loss functions\n",
        "4) write the training procedure\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZZ6dGPeUXqNs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DLyMM81Z9gf7",
        "colab_type": "text"
      },
      "source": [
        "# New Section"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TJ9wryFY9ucg",
        "colab_type": "code",
        "outputId": "c3158dc6-c9f9-4a10-a03e-48a1c3024ef1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.python.keras.preprocessing import image as kp_image\n",
        "\n",
        "# Keras is only used to load VGG19 model as a high level API to TensorFlow \n",
        "from keras.applications.vgg19 import VGG19\n",
        "from keras.models import Model\n",
        "from keras import backend as K\n",
        "\n",
        "# pillow is used for loading and saving images\n",
        "from PIL import Image\n",
        "\n",
        "# numPy is used for manipulation of array of object i.e Image in our case\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o81j1iu5TolN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_img(path_to_img):\n",
        "\n",
        "  max_dim  = 512\n",
        "  img      = Image.open(path_to_img)\n",
        "  img = img.convert('RGB')\n",
        "  img_size = max(img.size)\n",
        "  scale    = max_dim/img_size\n",
        "  img      = img.resize((round(img.size[0]*scale), round(img.size[1]*scale)), Image.ANTIALIAS)\n",
        "\n",
        "  img      = kp_image.img_to_array(img)\n",
        "\n",
        "  # We need to broadcast the image array such that it has a batch dimension \n",
        "  img = np.expand_dims(img, axis=0)\n",
        "\n",
        "  # preprocess raw images to make it suitable to be used by VGG19 model\n",
        "  out = tf.keras.applications.vgg19.preprocess_input(img)\n",
        "\n",
        "  return tf.convert_to_tensor(out)\n",
        "\n",
        "def deprocess_img(processed_img):\n",
        "  x = processed_img.copy()\n",
        "  \n",
        "  # perform the inverse of the preprocessiing step\n",
        "  x[:, :, 0] += 103.939\n",
        "  x[:, :, 1] += 116.779\n",
        "  x[:, :, 2] += 123.68\n",
        "\n",
        "  x = x[:, :, ::-1]\n",
        "\n",
        "  x = np.clip(x, 0, 255).astype('uint8')\n",
        "\n",
        "  return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8T15q8Rl_svK",
        "colab_type": "text"
      },
      "source": [
        "### Build VGG"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IG8JwOgFCmkw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# list of layers to be considered for calculation of Content and Style Loss\n",
        "content_layers = ['block3_conv3']\n",
        "style_layers   = ['block1_conv1','block2_conv2','block4_conv3']\n",
        "\n",
        "num_content_layers = len(content_layers)\n",
        "num_style_layers   = len(style_layers)\n",
        "\n",
        "# path where the content and style images are located\n",
        "content_path = 'content.jpg'\n",
        "style_path   = 'style.jpg'\n",
        "\n",
        "# Save the result as\n",
        "save_name = 'generated.jpg'\n",
        "\n",
        "# path to where Vgg19 model weight is located\n",
        "vgg_weights = \"vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u4I4N8dJ-1Yj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_model(content_layers,style_layers):\n",
        "\n",
        "  # Load our model. We load pretrained VGG, trained on imagenet data\n",
        "  vgg19 = VGG19(weights='imagenet', include_top=False)\n",
        "\n",
        "  # We don't need to (or want to) train any layers of our pre-trained vgg model, so we set it's trainable to false.\n",
        "  vgg19.trainable = False\n",
        "\n",
        "  style_model_outputs = [vgg19.get_layer(name).output for name in style_layers]\n",
        "  content_model_outputs =  [vgg19.get_layer(name).output for name in content_layers]\n",
        "  \n",
        "  model_outputs = content_model_outputs + style_model_outputs\n",
        "\n",
        "  # Build model \n",
        "  return Model(inputs = vgg19.input, outputs = model_outputs), vgg19"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WwocPJIbFZW4",
        "colab_type": "text"
      },
      "source": [
        "### Compute Losses"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I1EkUas1FMUH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### Content Loss Function\n",
        "def get_content_loss(content, target):\n",
        "  return tf.reduce_mean(tf.square(content - target)) /2\n",
        "\n",
        "\n",
        "### Style Loss Fucntion\n",
        "def gram_matrix(input_tensor):\n",
        "\n",
        "  # if input tensor is a 3D array of size Nh x Nw X Nc\n",
        "  # we reshape it to a 2D array of Nc x (Nh*Nw)\n",
        "  \n",
        "  channels = int(input_tensor.shape[-1])\n",
        "  a = tf.reshape(input_tensor, [-1, channels])\n",
        "  n = tf.shape(a)[0]\n",
        "\n",
        "  # get gram matrix \n",
        "  gram = tf.matmul(a, a, transpose_a=True)\n",
        "  \n",
        "  return gram\n",
        "\n",
        "def get_style_loss(base_style, gram_target):\n",
        "\n",
        "  height, width, channels = base_style.get_shape().as_list()\n",
        "  gram_style = gram_matrix(base_style)\n",
        "  \n",
        "  # Original eqn as a constant to divide i.e 1/(4. * (channels ** 2) * (width * height) ** 2)\n",
        "  return tf.reduce_mean(tf.square(gram_style - gram_target)) / (channels**2 * width * height) #(4.0 * (channels ** 2) * (width * height) ** 2)\n",
        "\n",
        "\n",
        "\n",
        "### Use to pass content and style image through it \n",
        "def get_feature_representations(model, content_path, style_path, num_content_layers):\n",
        "\n",
        "  # Load our images in \n",
        "  content_image = load_img(content_path)\n",
        "  style_image   = load_img(style_path)\n",
        "  \n",
        "  # batch compute content and style features\n",
        "  content_outputs = model(content_image)\n",
        "  style_outputs   = model(style_image)\n",
        "  \n",
        "  # Get the style and content feature representations from our model  \n",
        "  style_features   = [ style_layer[0]  for style_layer    in style_outputs[num_content_layers:] ]\n",
        "  content_features = [ content_layer[0] for content_layer in content_outputs[:num_content_layers] ]\n",
        "\n",
        "  return style_features, content_features\n",
        "\n",
        "\n",
        "### Total Loss\n",
        "def compute_loss(model, loss_weights, generated_output_activations, gram_style_features, content_features, num_content_layers, num_style_layers):\n",
        "\n",
        "  generated_content_activations = generated_output_activations[:num_content_layers]\n",
        "  generated_style_activations   = generated_output_activations[num_content_layers:]\n",
        "\n",
        "  style_weight, content_weight = loss_weights\n",
        "  \n",
        "  style_score = 0\n",
        "  content_score = 0\n",
        "\n",
        "  # Accumulate style losses from all layers\n",
        "  # Here, we equally weight each contribution of each loss layer\n",
        "  weight_per_style_layer = 1.0 / float(num_style_layers)\n",
        "  for target_style, comb_style in zip(gram_style_features, generated_style_activations):\n",
        "    temp = get_style_loss(comb_style[0], target_style)\n",
        "    style_score += weight_per_style_layer * temp\n",
        "    \n",
        "  # Accumulate content losses from all layers \n",
        "  weight_per_content_layer = 1.0 / float(num_content_layers)\n",
        "  for target_content, comb_content in zip(content_features, generated_content_activations):\n",
        "    temp = get_content_loss(comb_content[0], target_content)\n",
        "    content_score += weight_per_content_layer* temp\n",
        "\n",
        "  # Get total loss\n",
        "  loss = style_weight*style_score + content_weight*content_score \n",
        "\n",
        "\n",
        "  return loss, style_score, content_score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UAAMlzBAONnG",
        "colab_type": "text"
      },
      "source": [
        "# TRAINING Procedure"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-lld_LeEOAOX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def run_style_transfer(content_path, style_path, num_iterations=250, content_weight=0.1, style_weight=0.9): \n",
        "\n",
        "  # Create a tensorflow session \n",
        "  sess = tf.Session()\n",
        "\n",
        "  # Assign keras back-end to the TF session which we created\n",
        "  K.set_session(sess)\n",
        "\n",
        "  model, vgg19 = get_model(content_layers,style_layers)\n",
        "\n",
        "  # Get the style and content feature representations (from our specified intermediate layers) \n",
        "  style_features, content_features = get_feature_representations(model, content_path, style_path, num_content_layers)\n",
        "  gram_style_features = [gram_matrix(style_feature) for style_feature in style_features]\n",
        "\n",
        "  # VGG default normalization\n",
        "  norm_means = np.array([103.939, 116.779, 123.68])\n",
        "  min_vals = -norm_means\n",
        "  max_vals = 255 - norm_means \n",
        "    \n",
        "\n",
        "  # In original paper, the initial stylized image is random matrix of same size as that of content image\n",
        "  # but in later images content image was used instead on random values for first stylized image\n",
        "  # because it proved to help to stylize faster\n",
        "  generated_image = load_img(content_path)\n",
        "  # generated_image = np.random.randint(0,255, size=generated_image.shape) \n",
        "  \n",
        "  # Create tensorflow variable to hold a stylized/generated image during the training \n",
        "  generated_image = tf.Variable(generated_image, dtype=tf.float32)\n",
        "\n",
        "  model_outputs = model(generated_image)\n",
        "\n",
        "  # weightages of each content and style images i.e alpha & beta\n",
        "  loss_weights = (style_weight, content_weight)\n",
        "\n",
        "  # Create our optimizer\n",
        "  loss = compute_loss(model, loss_weights, model_outputs, gram_style_features, content_features, num_content_layers, num_style_layers)\n",
        "  opt = tf.train.AdamOptimizer(learning_rate=9, beta1=0.9, epsilon=1e-1).minimize( loss[0], var_list = [generated_image])\n",
        "  \n",
        "  sess.run(tf.global_variables_initializer())\n",
        "  sess.run(generated_image.initializer)\n",
        "  # loading the weights again because tf.global_variables_initializer() resets the weights\n",
        "  vgg19.load_weights(vgg_weights)\n",
        "  # Put loss as infinity before training starts and Create a variable to hold best image (i.e image with minimum loss)\n",
        "  best_loss, best_img = float('inf'), None\n",
        "\n",
        "  for i in range(num_iterations):\n",
        "\n",
        "    # Do optimization\n",
        "    sess.run(opt)\n",
        "\n",
        "    # Make sure image values stays in the range of max-min value of VGG norm \n",
        "    clipped = tf.clip_by_value(generated_image, min_vals, max_vals)\n",
        "    # assign the clipped value to the tensor stylized image\n",
        "    generated_image.assign(clipped)\n",
        "\n",
        "\n",
        "    # Open the Tuple of tensors \n",
        "    total_loss, style_score, content_score = loss\n",
        "    total_loss = total_loss.eval(session=sess)\n",
        "\n",
        "\n",
        "    if total_loss < best_loss:\n",
        "\n",
        "      # Update best loss and best image from total loss. \n",
        "      best_loss = total_loss\n",
        "\n",
        "      # generated image is of shape (1, h, w, 3) convert it to (h, w, 3)\n",
        "      temp_generated_image = sess.run(generated_image)[0]\n",
        "      best_img = deprocess_img(temp_generated_image)\n",
        "\n",
        "      s_loss = sess.run(style_score)\n",
        "      c_loss = sess.run(content_score)\n",
        "\n",
        "      # print best loss\n",
        "      print('best: iteration: ', i ,'loss: ', total_loss ,'  style_loss: ',  s_loss,'  content_loss: ', c_loss)\n",
        "\n",
        "    # Save image after every 100 iterations \n",
        "    #if (i+1)%100 == 0:\n",
        "      #output = Image.fromarray(best_img)\n",
        "      #output.save(str(i+1)+'-'+save_name)\n",
        "\n",
        "  # after num_iterations iterations are completed, close the TF session \n",
        "  sess.close()\n",
        "      \n",
        "  return best_img, best_loss, best_img"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pk5tVZ7SUgOK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!wget https://github.com/hwang123/865_final_project/raw/master/dan_yaha.jpg\n",
        "#!wget https://github.com/hwang123/865_final_project/raw/master/mondrian.jpg\n",
        "#!wget https://github.com/Shashi456/Neural-Style/raw/master/Neural%20Style%20Transfer/examples/content/dancing.jpg\n",
        "!wget https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zYsv6KpnTzGr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "best, best_loss, img = run_style_transfer('dan_yaha.jpg', 'mondrian.jpg', content_weight = 0.95, style_weight = 0.05)\n",
        "img = Image.fromarray(img)\n",
        "img.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sVYnhhiXETqn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img.save('/content/TESTDANWEIGHTS.png')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4BI4vBCvR0_B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "best, best_loss, img = run_style_transfer('dan_yaha.jpg', '/content/sketch.jpg', content_weight = 0.2, style_weight = 0.8)\n",
        "img = Image.fromarray(img)\n",
        "img.show()\n",
        "img.save('/content/TESTDANSKETCH.png')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XWpg0AEsVtGg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "best, best_loss, img = run_style_transfer('dan_yaha.jpg', '/content/cartoon.jpeg', content_weight = 0.2, style_weight = 0.8)\n",
        "img = Image.fromarray(img)\n",
        "img.show()\n",
        "img.save('/content/TESTDANCARTOON.png')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p_TP4A5Lcssb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget https://github.com/hwang123/865_final_project/raw/master/content/dog0.png"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "488JAnACdek7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "best, best_loss, img = run_style_transfer('dog0.png', '/content/sketch.jpg', content_weight = 0.2, style_weight = 0.8)\n",
        "img = Image.fromarray(img)\n",
        "img.show()\n",
        "img.save('/content/TESTDOG.png')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sYw8LNwzf64I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "best, best_loss, img = run_style_transfer('zebra.jpg', '/content/pencil.jpg', num_iterations=100, content_weight = 0.1, style_weight = 0.9)\n",
        "img = Image.fromarray(img)\n",
        "img.show()\n",
        "img.save('/content/TESTZEBRAPENCIL.png')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6tQY51_8A2OG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "best, best_loss, img = run_style_transfer('zebra0.png', '/content/lisafrank.jpg', content_weight = 0.01, style_weight = 0.99)\n",
        "img = Image.fromarray(img)\n",
        "img.show()\n",
        "img.save('/content/TESTZEBRARAINBOWNEW.png')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fCUnf_M_nAk2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget https://github.com/hwang123/865_final_project/raw/master/content/zebra0.png"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nIhOcwWBqrjK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "best, best_loss, img = run_style_transfer('zebra0.png', '/content/linedrawing.png', num_iterations = 150, content_weight = 0.1, style_weight = 0.9)\n",
        "img = Image.fromarray(img)\n",
        "img.show()\n",
        "img.save('/content/ZEBRALINE.png')\n",
        "\n",
        "best, best_loss, img = run_style_transfer('zebra0.png', '/content/pop_art.jpeg', num_iterations = 150, content_weight = 0.1, style_weight = 0.9)\n",
        "img = Image.fromarray(img)\n",
        "img.show()\n",
        "img.save('/content/ZEBRAPOP.png')\n",
        "\n",
        "best, best_loss, img = run_style_transfer('zebra0.png', '/content/starry_night.jpeg', num_iterations = 150, content_weight = 0.1, style_weight = 0.9)\n",
        "img = Image.fromarray(img)\n",
        "img.show()\n",
        "img.save('/content/ZEBRAVANGOGH.png')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fn94HNcA77eF",
        "colab_type": "code",
        "outputId": "8f14a293-19f8-4d90-a76d-7fe185f0796b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 20131
        }
      },
      "source": [
        "best, best_loss, img = run_style_transfer('/content/car2.png', '/content/sketch.jpg', num_iterations = 200, content_weight = 0.1, style_weight = 0.9)\n",
        "img = Image.fromarray(img)\n",
        "img.save('/content/carsketch2.jpeg')\n",
        "\n",
        "best, best_loss, img = run_style_transfer('/content/car2.png', '/content/lisafrank.jpg', num_iterations = 200, content_weight = 0.1, style_weight = 0.9)\n",
        "img = Image.fromarray(img)\n",
        "img.save('/content/carlisafrank2.jpeg')\n",
        "\n",
        "best, best_loss, img = run_style_transfer('/content/car2.png', '/content/pop_art.jpeg', num_iterations = 200, content_weight = 0.1, style_weight = 0.9)\n",
        "img = Image.fromarray(img)\n",
        "img.save('/content/carpopart2.jpeg')\n",
        "\n",
        "best, best_loss, img = run_style_transfer('/content/car2.png', '/content/starry_night.jpeg', num_iterations = 200, content_weight = 0.1, style_weight = 0.9)\n",
        "img = Image.fromarray(img)\n",
        "img.save('/content/carstarrynight2.jpeg')\n",
        "\n",
        "best, best_loss, img = run_style_transfer('/content/car2.png', '/content/linedrawing.png', num_iterations = 200, content_weight = 0.1, style_weight = 0.9)\n",
        "img = Image.fromarray(img)\n",
        "img.save('/content/carlinedrawing2.jpeg')\n",
        "\n",
        "best, best_loss, img = run_style_transfer('/content/car2.png', '/content/pencil.jpg', num_iterations = 200, content_weight = 0.1, style_weight = 0.9)\n",
        "img = Image.fromarray(img)\n",
        "img.save('/content/carpencil2.jpeg')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "80142336/80134624 [==============================] - 2s 0us/step\n",
            "best: iteration:  0 loss:  662301440.0   style_loss:  735888900.0   content_loss:  13955.267\n",
            "best: iteration:  1 loss:  488442200.0   style_loss:  542709900.0   content_loss:  33135.402\n",
            "best: iteration:  2 loss:  339263600.0   style_loss:  376953470.0   content_loss:  54899.25\n",
            "best: iteration:  3 loss:  241033420.0   style_loss:  267806820.0   content_loss:  73027.234\n",
            "best: iteration:  4 loss:  197597520.0   style_loss:  219543260.0   content_loss:  85861.66\n",
            "best: iteration:  5 loss:  188532080.0   style_loss:  209469820.0   content_loss:  92356.516\n",
            "best: iteration:  6 loss:  180023090.0   style_loss:  200015330.0   content_loss:  93150.78\n",
            "best: iteration:  7 loss:  160423890.0   style_loss:  178238700.0   content_loss:  90613.695\n",
            "best: iteration:  8 loss:  138895410.0   style_loss:  154318530.0   content_loss:  87441.55\n",
            "best: iteration:  9 loss:  122723730.0   style_loss:  136350260.0   content_loss:  85118.695\n",
            "best: iteration:  10 loss:  111216660.0   style_loss:  123564750.0   content_loss:  83738.805\n",
            "best: iteration:  11 loss:  101593880.0   style_loss:  112872880.0   content_loss:  82860.8\n",
            "best: iteration:  12 loss:  92538420.0   style_loss:  102811330.0   content_loss:  82270.25\n",
            "best: iteration:  13 loss:  84269224.0   style_loss:  93623360.0   content_loss:  81968.83\n",
            "best: iteration:  14 loss:  77270800.0   style_loss:  85847340.0   content_loss:  81927.6\n",
            "best: iteration:  15 loss:  71608400.0   style_loss:  79555780.0   content_loss:  82000.445\n",
            "best: iteration:  16 loss:  67032770.0   style_loss:  74471740.0   content_loss:  81996.414\n",
            "best: iteration:  17 loss:  63150440.0   style_loss:  70158080.0   content_loss:  81776.45\n",
            "best: iteration:  18 loss:  59642600.0   style_loss:  66260516.0   content_loss:  81338.84\n",
            "best: iteration:  19 loss:  56324880.0   style_loss:  62574236.0   content_loss:  80694.12\n",
            "best: iteration:  20 loss:  53192364.0   style_loss:  59093744.0   content_loss:  79942.56\n",
            "best: iteration:  21 loss:  50319884.0   style_loss:  55902180.0   content_loss:  79248.375\n",
            "best: iteration:  22 loss:  47746420.0   style_loss:  53042830.0   content_loss:  78728.36\n",
            "best: iteration:  23 loss:  45416296.0   style_loss:  50453830.0   content_loss:  78450.03\n",
            "best: iteration:  24 loss:  43292556.0   style_loss:  48094130.0   content_loss:  78387.53\n",
            "best: iteration:  25 loss:  41329030.0   style_loss:  45912424.0   content_loss:  78473.17\n",
            "best: iteration:  26 loss:  39490390.0   style_loss:  43869476.0   content_loss:  78634.27\n",
            "best: iteration:  27 loss:  37759216.0   style_loss:  41945932.0   content_loss:  78782.58\n",
            "best: iteration:  28 loss:  36117764.0   style_loss:  40122080.0   content_loss:  78885.63\n",
            "best: iteration:  29 loss:  34551344.0   style_loss:  38381616.0   content_loss:  78927.77\n",
            "best: iteration:  30 loss:  33049342.0   style_loss:  36712724.0   content_loss:  78916.59\n",
            "best: iteration:  31 loss:  31615746.0   style_loss:  35119840.0   content_loss:  78880.72\n",
            "best: iteration:  32 loss:  30250480.0   style_loss:  33602884.0   content_loss:  78854.12\n",
            "best: iteration:  33 loss:  28957660.0   style_loss:  32166418.0   content_loss:  78849.21\n",
            "best: iteration:  34 loss:  27726448.0   style_loss:  30798400.0   content_loss:  78892.59\n",
            "best: iteration:  35 loss:  26541968.0   style_loss:  29482298.0   content_loss:  78992.95\n",
            "best: iteration:  36 loss:  25425474.0   style_loss:  28241734.0   content_loss:  79153.91\n",
            "best: iteration:  37 loss:  24381266.0   style_loss:  27081478.0   content_loss:  79356.58\n",
            "best: iteration:  38 loss:  23400978.0   style_loss:  25992246.0   content_loss:  79573.84\n",
            "best: iteration:  39 loss:  22466364.0   style_loss:  24953762.0   content_loss:  79788.4\n",
            "best: iteration:  40 loss:  21575748.0   style_loss:  23964168.0   content_loss:  79979.72\n",
            "best: iteration:  41 loss:  20729038.0   style_loss:  23023360.0   content_loss:  80140.17\n",
            "best: iteration:  42 loss:  19920908.0   style_loss:  22125420.0   content_loss:  80283.14\n",
            "best: iteration:  43 loss:  19149062.0   style_loss:  21267798.0   content_loss:  80437.875\n",
            "best: iteration:  44 loss:  18400066.0   style_loss:  20435558.0   content_loss:  80628.45\n",
            "best: iteration:  45 loss:  17677094.0   style_loss:  19632234.0   content_loss:  80838.74\n",
            "best: iteration:  46 loss:  16980998.0   style_loss:  18858774.0   content_loss:  81045.95\n",
            "best: iteration:  47 loss:  16317269.0   style_loss:  18121272.0   content_loss:  81251.555\n",
            "best: iteration:  48 loss:  15677275.0   style_loss:  17410146.0   content_loss:  81437.31\n",
            "best: iteration:  49 loss:  15058792.0   style_loss:  16722924.0   content_loss:  81598.805\n",
            "best: iteration:  50 loss:  14458685.0   style_loss:  16056124.0   content_loss:  81746.59\n",
            "best: iteration:  51 loss:  13876801.0   style_loss:  15409569.0   content_loss:  81886.88\n",
            "best: iteration:  52 loss:  13316311.0   style_loss:  14786787.0   content_loss:  82025.984\n",
            "best: iteration:  53 loss:  12783769.0   style_loss:  14195061.0   content_loss:  82144.69\n",
            "best: iteration:  54 loss:  12276220.0   style_loss:  13631107.0   content_loss:  82246.41\n",
            "best: iteration:  55 loss:  11783612.0   style_loss:  13083752.0   content_loss:  82361.6\n",
            "best: iteration:  56 loss:  11310911.0   style_loss:  12558515.0   content_loss:  82481.555\n",
            "best: iteration:  57 loss:  10851650.0   style_loss:  12048210.0   content_loss:  82610.984\n",
            "best: iteration:  58 loss:  10401093.0   style_loss:  11547576.0   content_loss:  82740.195\n",
            "best: iteration:  59 loss:  9962998.0   style_loss:  11060790.0   content_loss:  82871.125\n",
            "best: iteration:  60 loss:  9543127.0   style_loss:  10594254.0   content_loss:  82988.87\n",
            "best: iteration:  61 loss:  9138983.0   style_loss:  10145192.0   content_loss:  83099.27\n",
            "best: iteration:  62 loss:  8758406.0   style_loss:  9722318.0   content_loss:  83199.45\n",
            "best: iteration:  63 loss:  8394023.0   style_loss:  9317436.0   content_loss:  83313.34\n",
            "best: iteration:  64 loss:  8036351.0   style_loss:  8920007.0   content_loss:  83449.06\n",
            "best: iteration:  65 loss:  7689198.5   style_loss:  8534267.0   content_loss:  83584.664\n",
            "best: iteration:  66 loss:  7357523.5   style_loss:  8165725.5   content_loss:  83703.63\n",
            "best: iteration:  67 loss:  7037597.5   style_loss:  7810241.0   content_loss:  83809.51\n",
            "best: iteration:  68 loss:  6724826.5   style_loss:  7462707.0   content_loss:  83905.89\n",
            "best: iteration:  69 loss:  6419917.0   style_loss:  7123908.0   content_loss:  84003.74\n",
            "best: iteration:  70 loss:  6126982.0   style_loss:  6798414.5   content_loss:  84092.0\n",
            "best: iteration:  71 loss:  5847079.0   style_loss:  6487401.5   content_loss:  84174.74\n",
            "best: iteration:  72 loss:  5581760.0   style_loss:  6192594.5   content_loss:  84252.34\n",
            "best: iteration:  73 loss:  5326027.0   style_loss:  5908436.5   content_loss:  84342.516\n",
            "best: iteration:  74 loss:  5074684.0   style_loss:  5629156.5   content_loss:  84436.945\n",
            "best: iteration:  75 loss:  4831914.0   style_loss:  5359402.5   content_loss:  84518.41\n",
            "best: iteration:  76 loss:  4600789.5   style_loss:  5102591.5   content_loss:  84574.04\n",
            "best: iteration:  77 loss:  4378917.0   style_loss:  4856061.0   content_loss:  84620.7\n",
            "best: iteration:  78 loss:  4169615.2   style_loss:  4623498.5   content_loss:  84663.07\n",
            "best: iteration:  79 loss:  3966717.2   style_loss:  4398051.5   content_loss:  84710.39\n",
            "best: iteration:  80 loss:  3770623.8   style_loss:  4180164.8   content_loss:  84756.414\n",
            "best: iteration:  81 loss:  3582103.8   style_loss:  3970693.8   content_loss:  84792.805\n",
            "best: iteration:  82 loss:  3404384.5   style_loss:  3773226.0   content_loss:  84812.78\n",
            "best: iteration:  83 loss:  3237870.0   style_loss:  3588207.5   content_loss:  84832.62\n",
            "best: iteration:  84 loss:  3082104.5   style_loss:  3415132.8   content_loss:  84849.54\n",
            "best: iteration:  85 loss:  2935847.8   style_loss:  3252624.0   content_loss:  84863.97\n",
            "best: iteration:  86 loss:  2797557.0   style_loss:  3098965.5   content_loss:  84879.305\n",
            "best: iteration:  87 loss:  2664754.5   style_loss:  2951406.2   content_loss:  84889.945\n",
            "best: iteration:  88 loss:  2537852.8   style_loss:  2810403.5   content_loss:  84894.77\n",
            "best: iteration:  89 loss:  2419471.8   style_loss:  2678868.8   content_loss:  84902.52\n",
            "best: iteration:  90 loss:  2312620.0   style_loss:  2560142.2   content_loss:  84920.79\n",
            "best: iteration:  91 loss:  2212078.2   style_loss:  2448426.5   content_loss:  84945.78\n",
            "best: iteration:  92 loss:  2115327.5   style_loss:  2340922.0   content_loss:  84977.79\n",
            "best: iteration:  93 loss:  2023301.4   style_loss:  2238668.0   content_loss:  85001.96\n",
            "best: iteration:  94 loss:  1935415.2   style_loss:  2141014.8   content_loss:  85019.51\n",
            "best: iteration:  95 loss:  1852404.6   style_loss:  2048779.5   content_loss:  85030.94\n",
            "best: iteration:  96 loss:  1775472.9   style_loss:  1963298.0   content_loss:  85047.09\n",
            "best: iteration:  97 loss:  1703753.9   style_loss:  1883607.8   content_loss:  85068.71\n",
            "best: iteration:  98 loss:  1636542.9   style_loss:  1808926.2   content_loss:  85093.03\n",
            "best: iteration:  99 loss:  1572741.9   style_loss:  1738034.2   content_loss:  85111.125\n",
            "best: iteration:  100 loss:  1511390.9   style_loss:  1669865.0   content_loss:  85123.945\n",
            "best: iteration:  101 loss:  1453582.0   style_loss:  1605631.2   content_loss:  85139.92\n",
            "best: iteration:  102 loss:  1399268.0   style_loss:  1545281.0   content_loss:  85150.945\n",
            "best: iteration:  103 loss:  1347818.4   style_loss:  1488113.8   content_loss:  85159.93\n",
            "best: iteration:  104 loss:  1298611.1   style_loss:  1433438.5   content_loss:  85165.33\n",
            "best: iteration:  105 loss:  1251959.8   style_loss:  1381602.2   content_loss:  85175.99\n",
            "best: iteration:  106 loss:  1207917.0   style_loss:  1332664.2   content_loss:  85193.39\n",
            "best: iteration:  107 loss:  1166594.1   style_loss:  1286748.2   content_loss:  85209.164\n",
            "best: iteration:  108 loss:  1128048.8   style_loss:  1243919.0   content_loss:  85216.78\n",
            "best: iteration:  109 loss:  1091588.2   style_loss:  1203406.6   content_loss:  85223.41\n",
            "best: iteration:  110 loss:  1056883.9   style_loss:  1164845.2   content_loss:  85230.14\n",
            "best: iteration:  111 loss:  1023907.56   style_loss:  1128204.5   content_loss:  85236.086\n",
            "best: iteration:  112 loss:  992144.1   style_loss:  1092911.0   content_loss:  85241.32\n",
            "best: iteration:  113 loss:  961769.25   style_loss:  1059160.8   content_loss:  85246.66\n",
            "best: iteration:  114 loss:  932714.06   style_loss:  1026876.4   content_loss:  85253.52\n",
            "best: iteration:  115 loss:  905487.7   style_loss:  996624.0   content_loss:  85261.17\n",
            "best: iteration:  116 loss:  879772.0   style_loss:  968050.2   content_loss:  85269.37\n",
            "best: iteration:  117 loss:  855277.44   style_loss:  940832.6   content_loss:  85281.234\n",
            "best: iteration:  118 loss:  832279.0   style_loss:  915277.25   content_loss:  85295.03\n",
            "best: iteration:  119 loss:  810941.06   style_loss:  891566.9   content_loss:  85308.13\n",
            "best: iteration:  120 loss:  791208.3   style_loss:  869641.25   content_loss:  85310.97\n",
            "best: iteration:  121 loss:  772687.8   style_loss:  849063.4   content_loss:  85308.016\n",
            "best: iteration:  122 loss:  755068.56   style_loss:  829486.7   content_loss:  85305.625\n",
            "best: iteration:  123 loss:  738142.0   style_loss:  810679.5   content_loss:  85304.734\n",
            "best: iteration:  124 loss:  721991.4   style_loss:  792734.0   content_loss:  85307.92\n",
            "best: iteration:  125 loss:  706640.6   style_loss:  775676.94   content_loss:  85313.82\n",
            "best: iteration:  126 loss:  691871.75   style_loss:  759266.25   content_loss:  85322.08\n",
            "best: iteration:  127 loss:  677604.75   style_loss:  743412.6   content_loss:  85333.695\n",
            "best: iteration:  128 loss:  663845.9   style_loss:  728123.4   content_loss:  85348.76\n",
            "best: iteration:  129 loss:  650641.06   style_loss:  713449.6   content_loss:  85364.51\n",
            "best: iteration:  130 loss:  637996.8   style_loss:  699398.75   content_loss:  85379.37\n",
            "best: iteration:  131 loss:  625854.25   style_loss:  685905.56   content_loss:  85392.51\n",
            "best: iteration:  132 loss:  614236.5   style_loss:  672995.75   content_loss:  85403.26\n",
            "best: iteration:  133 loss:  603187.94   style_loss:  660718.6   content_loss:  85411.66\n",
            "best: iteration:  134 loss:  592676.9   style_loss:  649039.1   content_loss:  85416.98\n",
            "best: iteration:  135 loss:  582643.0   style_loss:  637889.8   content_loss:  85422.1\n",
            "best: iteration:  136 loss:  573042.3   style_loss:  627221.5   content_loss:  85430.18\n",
            "best: iteration:  137 loss:  563797.25   style_loss:  616948.1   content_loss:  85439.23\n",
            "best: iteration:  138 loss:  554930.75   style_loss:  607095.44   content_loss:  85448.82\n",
            "best: iteration:  139 loss:  546386.4   style_loss:  597600.75   content_loss:  85456.85\n",
            "best: iteration:  140 loss:  538139.06   style_loss:  588436.1   content_loss:  85465.625\n",
            "best: iteration:  141 loss:  530113.2   style_loss:  579517.2   content_loss:  85477.35\n",
            "best: iteration:  142 loss:  522356.4   style_loss:  570896.9   content_loss:  85492.13\n",
            "best: iteration:  143 loss:  514827.94   style_loss:  562530.1   content_loss:  85509.01\n",
            "best: iteration:  144 loss:  507553.12   style_loss:  554445.1   content_loss:  85525.266\n",
            "best: iteration:  145 loss:  500477.5   style_loss:  546581.56   content_loss:  85540.945\n",
            "best: iteration:  146 loss:  493654.88   style_loss:  538999.56   content_loss:  85553.49\n",
            "best: iteration:  147 loss:  487027.75   style_loss:  531634.75   content_loss:  85564.4\n",
            "best: iteration:  148 loss:  480644.4   style_loss:  524541.25   content_loss:  85572.78\n",
            "best: iteration:  149 loss:  474473.44   style_loss:  517683.66   content_loss:  85581.68\n",
            "best: iteration:  150 loss:  468504.62   style_loss:  511050.62   content_loss:  85590.51\n",
            "best: iteration:  151 loss:  462718.2   style_loss:  504620.34   content_loss:  85599.195\n",
            "best: iteration:  152 loss:  457118.75   style_loss:  498397.88   content_loss:  85606.78\n",
            "best: iteration:  153 loss:  451671.44   style_loss:  492344.5   content_loss:  85613.91\n",
            "best: iteration:  154 loss:  446380.8   style_loss:  486465.38   content_loss:  85620.1\n",
            "best: iteration:  155 loss:  441224.1   style_loss:  480734.88   content_loss:  85626.95\n",
            "best: iteration:  156 loss:  436251.5   style_loss:  475209.06   content_loss:  85633.53\n",
            "best: iteration:  157 loss:  431419.28   style_loss:  469838.94   content_loss:  85642.41\n",
            "best: iteration:  158 loss:  426735.25   style_loss:  464633.5   content_loss:  85651.26\n",
            "best: iteration:  159 loss:  422161.1   style_loss:  459550.0   content_loss:  85661.305\n",
            "best: iteration:  160 loss:  417718.34   style_loss:  454612.56   content_loss:  85670.55\n",
            "best: iteration:  161 loss:  413368.7   style_loss:  449778.5   content_loss:  85680.76\n",
            "best: iteration:  162 loss:  409135.75   style_loss:  445074.0   content_loss:  85691.47\n",
            "best: iteration:  163 loss:  404973.72   style_loss:  440448.16   content_loss:  85703.68\n",
            "best: iteration:  164 loss:  400906.1   style_loss:  435927.28   content_loss:  85715.625\n",
            "best: iteration:  165 loss:  396930.38   style_loss:  431508.56   content_loss:  85726.93\n",
            "best: iteration:  166 loss:  393053.84   style_loss:  427200.2   content_loss:  85736.78\n",
            "best: iteration:  167 loss:  389270.78   style_loss:  422995.78   content_loss:  85745.85\n",
            "best: iteration:  168 loss:  385583.3   style_loss:  418897.7   content_loss:  85754.05\n",
            "best: iteration:  169 loss:  381969.0   style_loss:  414880.75   content_loss:  85763.03\n",
            "best: iteration:  170 loss:  378438.5   style_loss:  410956.9   content_loss:  85772.72\n",
            "best: iteration:  171 loss:  374979.47   style_loss:  407112.34   content_loss:  85783.7\n",
            "best: iteration:  172 loss:  371604.28   style_loss:  403360.88   content_loss:  85795.07\n",
            "best: iteration:  173 loss:  368284.62   style_loss:  399671.12   content_loss:  85806.41\n",
            "best: iteration:  174 loss:  365028.7   style_loss:  396052.25   content_loss:  85816.76\n",
            "best: iteration:  175 loss:  361839.56   style_loss:  392507.66   content_loss:  85827.016\n",
            "best: iteration:  176 loss:  358719.66   style_loss:  389039.97   content_loss:  85837.125\n",
            "best: iteration:  177 loss:  355645.28   style_loss:  385622.75   content_loss:  85848.125\n",
            "best: iteration:  178 loss:  352633.2   style_loss:  382274.8   content_loss:  85858.38\n",
            "best: iteration:  179 loss:  349681.12   style_loss:  378993.78   content_loss:  85867.32\n",
            "best: iteration:  180 loss:  346772.72   style_loss:  375761.28   content_loss:  85875.62\n",
            "best: iteration:  181 loss:  343919.94   style_loss:  372590.6   content_loss:  85884.02\n",
            "best: iteration:  182 loss:  341110.94   style_loss:  369468.47   content_loss:  85893.17\n",
            "best: iteration:  183 loss:  338354.78   style_loss:  366405.06   content_loss:  85902.2\n",
            "best: iteration:  184 loss:  335643.78   style_loss:  363391.8   content_loss:  85911.32\n",
            "best: iteration:  185 loss:  332974.0   style_loss:  360424.3   content_loss:  85921.25\n",
            "best: iteration:  186 loss:  330349.72   style_loss:  357507.38   content_loss:  85930.99\n",
            "best: iteration:  187 loss:  327764.1   style_loss:  354633.4   content_loss:  85940.32\n",
            "best: iteration:  188 loss:  325215.97   style_loss:  351801.12   content_loss:  85949.32\n",
            "best: iteration:  189 loss:  322714.62   style_loss:  349020.8   content_loss:  85958.66\n",
            "best: iteration:  190 loss:  320250.47   style_loss:  346281.8   content_loss:  85968.586\n",
            "best: iteration:  191 loss:  317834.28   style_loss:  343596.0   content_loss:  85978.89\n",
            "best: iteration:  192 loss:  315480.47   style_loss:  340979.53   content_loss:  85989.02\n",
            "best: iteration:  193 loss:  313184.94   style_loss:  338427.8   content_loss:  85999.016\n",
            "best: iteration:  194 loss:  310948.56   style_loss:  335942.0   content_loss:  86007.7\n",
            "best: iteration:  195 loss:  308763.9   style_loss:  333513.72   content_loss:  86015.59\n",
            "best: iteration:  196 loss:  306624.62   style_loss:  331135.88   content_loss:  86023.88\n",
            "best: iteration:  197 loss:  304511.03   style_loss:  328786.34   content_loss:  86033.38\n",
            "best: iteration:  198 loss:  302424.28   style_loss:  326466.5   content_loss:  86044.27\n",
            "best: iteration:  199 loss:  300369.7   style_loss:  324182.38   content_loss:  86055.72\n",
            "best: iteration:  0 loss:  2423004700.0   style_loss:  2692225500.0   content_loss:  18036.826\n",
            "best: iteration:  1 loss:  1560018300.0   style_loss:  1733348000.0   content_loss:  51411.953\n",
            "best: iteration:  2 loss:  681228350.0   style_loss:  756909250.0   content_loss:  100660.93\n",
            "best: iteration:  3 loss:  321388300.0   style_loss:  357079940.0   content_loss:  163493.39\n",
            "best: iteration:  7 loss:  262535840.0   style_loss:  291686100.0   content_loss:  183250.78\n",
            "best: iteration:  8 loss:  144123280.0   style_loss:  160118980.0   content_loss:  161957.81\n",
            "best: iteration:  14 loss:  124511580.0   style_loss:  138326100.0   content_loss:  181011.19\n",
            "best: iteration:  18 loss:  121188104.0   style_loss:  134630400.0   content_loss:  207474.55\n",
            "best: iteration:  19 loss:  87080264.0   style_loss:  96733784.0   content_loss:  198631.81\n",
            "best: iteration:  20 loss:  68033224.0   style_loss:  75571490.0   content_loss:  188836.19\n",
            "best: iteration:  21 loss:  67209870.0   style_loss:  74657576.0   content_loss:  180590.27\n",
            "best: iteration:  25 loss:  60196096.0   style_loss:  66864476.0   content_loss:  180657.62\n",
            "best: iteration:  26 loss:  52432228.0   style_loss:  58237300.0   content_loss:  186601.86\n",
            "best: iteration:  27 loss:  51171630.0   style_loss:  56836004.0   content_loss:  192296.39\n",
            "best: iteration:  30 loss:  49110090.0   style_loss:  54545056.0   content_loss:  195396.5\n",
            "best: iteration:  31 loss:  42396484.0   style_loss:  47085896.0   content_loss:  191791.2\n",
            "best: iteration:  32 loss:  38159704.0   style_loss:  42378816.0   content_loss:  187700.78\n",
            "best: iteration:  33 loss:  37486972.0   style_loss:  41631696.0   content_loss:  184423.77\n",
            "best: iteration:  36 loss:  35188930.0   style_loss:  39078160.0   content_loss:  185844.72\n",
            "best: iteration:  37 loss:  32422550.0   style_loss:  36003990.0   content_loss:  189619.2\n",
            "best: iteration:  38 loss:  30883300.0   style_loss:  34293244.0   content_loss:  193816.14\n",
            "best: iteration:  39 loss:  30707392.0   style_loss:  34097388.0   content_loss:  197449.84\n",
            "best: iteration:  40 loss:  30587170.0   style_loss:  33963548.0   content_loss:  199732.44\n",
            "best: iteration:  41 loss:  29409848.0   style_loss:  32655350.0   content_loss:  200342.4\n",
            "best: iteration:  42 loss:  27478272.0   style_loss:  30509242.0   content_loss:  199531.11\n",
            "best: iteration:  43 loss:  25908526.0   style_loss:  28765256.0   content_loss:  197963.19\n",
            "best: iteration:  44 loss:  25237290.0   style_loss:  28019610.0   content_loss:  196442.86\n",
            "best: iteration:  45 loss:  24992324.0   style_loss:  27747512.0   content_loss:  195637.48\n",
            "best: iteration:  46 loss:  24450080.0   style_loss:  27144990.0   content_loss:  195912.27\n",
            "best: iteration:  47 loss:  23467802.0   style_loss:  26053420.0   content_loss:  197258.25\n",
            "best: iteration:  48 loss:  22505856.0   style_loss:  24984360.0   content_loss:  199329.05\n",
            "best: iteration:  49 loss:  21977862.0   style_loss:  24397456.0   content_loss:  201529.39\n",
            "best: iteration:  50 loss:  21750320.0   style_loss:  24144438.0   content_loss:  203247.0\n",
            "best: iteration:  51 loss:  21365000.0   style_loss:  23716212.0   content_loss:  204072.05\n",
            "best: iteration:  52 loss:  20629014.0   style_loss:  22898468.0   content_loss:  203941.05\n",
            "best: iteration:  53 loss:  19802886.0   style_loss:  21980638.0   content_loss:  203117.69\n",
            "best: iteration:  54 loss:  19229132.0   style_loss:  21343252.0   content_loss:  202064.2\n",
            "best: iteration:  55 loss:  18933540.0   style_loss:  21014906.0   content_loss:  201257.36\n",
            "best: iteration:  56 loss:  18663588.0   style_loss:  20714980.0   content_loss:  201041.02\n",
            "best: iteration:  57 loss:  18226572.0   style_loss:  20229356.0   content_loss:  201529.52\n",
            "best: iteration:  58 loss:  17695814.0   style_loss:  19639508.0   content_loss:  202605.56\n",
            "best: iteration:  59 loss:  17279362.0   style_loss:  19176630.0   content_loss:  203952.5\n",
            "best: iteration:  60 loss:  17045830.0   style_loss:  18917016.0   content_loss:  205169.86\n",
            "best: iteration:  61 loss:  16849834.0   style_loss:  18699158.0   content_loss:  205915.66\n",
            "best: iteration:  62 loss:  16529675.0   style_loss:  18343414.0   content_loss:  206034.56\n",
            "best: iteration:  63 loss:  16106641.0   style_loss:  17873422.0   content_loss:  205621.02\n",
            "best: iteration:  64 loss:  15729682.0   style_loss:  17454652.0   content_loss:  204959.2\n",
            "best: iteration:  65 loss:  15471151.0   style_loss:  17167458.0   content_loss:  204393.27\n",
            "best: iteration:  66 loss:  15260096.0   style_loss:  16932974.0   content_loss:  204183.73\n",
            "best: iteration:  67 loss:  15004121.0   style_loss:  16648530.0   content_loss:  204441.0\n",
            "best: iteration:  68 loss:  14703920.0   style_loss:  16314900.0   content_loss:  205095.94\n",
            "best: iteration:  69 loss:  14429168.0   style_loss:  16009526.0   content_loss:  205946.77\n",
            "best: iteration:  70 loss:  14216547.0   style_loss:  15773194.0   content_loss:  206733.95\n",
            "best: iteration:  71 loss:  14028703.0   style_loss:  15564422.0   content_loss:  207237.61\n",
            "best: iteration:  72 loss:  13814105.0   style_loss:  15325967.0   content_loss:  207358.27\n",
            "best: iteration:  73 loss:  13573041.0   style_loss:  15058139.0   content_loss:  207148.19\n",
            "best: iteration:  74 loss:  13345255.0   style_loss:  14805085.0   content_loss:  206777.0\n",
            "best: iteration:  75 loss:  13149932.0   style_loss:  14588096.0   content_loss:  206457.16\n",
            "best: iteration:  76 loss:  12965661.0   style_loss:  14383362.0   content_loss:  206355.64\n",
            "best: iteration:  77 loss:  12768477.0   style_loss:  14164248.0   content_loss:  206532.3\n",
            "best: iteration:  78 loss:  12565631.0   style_loss:  13938820.0   content_loss:  206935.66\n",
            "best: iteration:  79 loss:  12379958.0   style_loss:  13732461.0   content_loss:  207431.94\n",
            "best: iteration:  80 loss:  12214979.0   style_loss:  13549103.0   content_loss:  207861.27\n",
            "best: iteration:  81 loss:  12051356.0   style_loss:  13367273.0   content_loss:  208107.64\n",
            "best: iteration:  82 loss:  11876110.0   style_loss:  13172552.0   content_loss:  208141.52\n",
            "best: iteration:  83 loss:  11698302.0   style_loss:  12975000.0   content_loss:  208021.14\n",
            "best: iteration:  84 loss:  11533672.0   style_loss:  12792097.0   content_loss:  207863.34\n",
            "best: iteration:  85 loss:  11382646.0   style_loss:  12624297.0   content_loss:  207788.36\n",
            "best: iteration:  86 loss:  11232892.0   style_loss:  12457895.0   content_loss:  207865.27\n",
            "best: iteration:  87 loss:  11077932.0   style_loss:  12285692.0   content_loss:  208093.0\n",
            "best: iteration:  88 loss:  10923848.0   style_loss:  12114452.0   content_loss:  208407.86\n",
            "best: iteration:  89 loss:  10778313.0   style_loss:  11952715.0   content_loss:  208711.48\n",
            "best: iteration:  90 loss:  10639467.0   style_loss:  11798416.0   content_loss:  208918.3\n",
            "best: iteration:  91 loss:  10500381.0   style_loss:  11643869.0   content_loss:  208991.27\n",
            "best: iteration:  92 loss:  10359271.0   style_loss:  11487085.0   content_loss:  208951.81\n",
            "best: iteration:  93 loss:  10220874.0   style_loss:  11333319.0   content_loss:  208865.02\n",
            "best: iteration:  94 loss:  10088467.0   style_loss:  11186208.0   content_loss:  208811.56\n",
            "best: iteration:  95 loss:  9959845.0   style_loss:  11043289.0   content_loss:  208846.02\n",
            "best: iteration:  96 loss:  9831674.0   style_loss:  10900863.0   content_loss:  208981.55\n",
            "best: iteration:  97 loss:  9704332.0   style_loss:  10759348.0   content_loss:  209184.4\n",
            "best: iteration:  98 loss:  9580346.0   style_loss:  10621564.0   content_loss:  209391.7\n",
            "best: iteration:  99 loss:  9460071.0   style_loss:  10487907.0   content_loss:  209545.45\n",
            "best: iteration:  100 loss:  9341104.0   style_loss:  10355716.0   content_loss:  209614.64\n",
            "best: iteration:  101 loss:  9222198.0   style_loss:  10223597.0   content_loss:  209606.73\n",
            "best: iteration:  102 loss:  9104829.0   style_loss:  10093194.0   content_loss:  209558.7\n",
            "best: iteration:  103 loss:  8990741.0   style_loss:  9966434.0   content_loss:  209521.56\n",
            "best: iteration:  104 loss:  8879329.0   style_loss:  9842640.0   content_loss:  209534.34\n",
            "best: iteration:  105 loss:  8768973.0   style_loss:  9720014.0   content_loss:  209609.05\n",
            "best: iteration:  106 loss:  8659516.0   style_loss:  9598381.0   content_loss:  209728.4\n",
            "best: iteration:  107 loss:  8552128.0   style_loss:  9479047.0   content_loss:  209857.86\n",
            "best: iteration:  108 loss:  8447191.0   style_loss:  9362439.0   content_loss:  209963.52\n",
            "best: iteration:  109 loss:  8343687.5   style_loss:  9247428.0   content_loss:  210024.94\n",
            "best: iteration:  110 loss:  8240838.5   style_loss:  9133150.0   content_loss:  210045.4\n",
            "best: iteration:  111 loss:  8139126.5   style_loss:  9020136.0   content_loss:  210046.31\n",
            "best: iteration:  112 loss:  8039312.5   style_loss:  8909230.0   content_loss:  210055.89\n",
            "best: iteration:  113 loss:  7941322.5   style_loss:  8800349.0   content_loss:  210094.25\n",
            "best: iteration:  114 loss:  7844572.0   style_loss:  8692840.0   content_loss:  210167.55\n",
            "best: iteration:  115 loss:  7748970.0   style_loss:  8586604.0   content_loss:  210262.64\n",
            "best: iteration:  116 loss:  7654850.0   style_loss:  8482017.0   content_loss:  210358.73\n",
            "best: iteration:  117 loss:  7562298.0   style_loss:  8379172.5   content_loss:  210437.0\n",
            "best: iteration:  118 loss:  7470924.0   style_loss:  8277639.0   content_loss:  210488.5\n",
            "best: iteration:  119 loss:  7380489.0   style_loss:  8177153.5   content_loss:  210516.89\n",
            "best: iteration:  120 loss:  7291276.0   style_loss:  8078025.0   content_loss:  210535.77\n",
            "best: iteration:  121 loss:  7203513.0   style_loss:  7980508.0   content_loss:  210561.6\n",
            "best: iteration:  122 loss:  7117056.0   style_loss:  7884439.5   content_loss:  210603.98\n",
            "best: iteration:  123 loss:  7031619.5   style_loss:  7789503.5   content_loss:  210663.5\n",
            "best: iteration:  124 loss:  6947223.5   style_loss:  7695722.5   content_loss:  210731.3\n",
            "best: iteration:  125 loss:  6864116.0   style_loss:  7603373.5   content_loss:  210796.3\n",
            "best: iteration:  126 loss:  6782191.5   style_loss:  7512341.0   content_loss:  210849.11\n",
            "best: iteration:  127 loss:  6701269.5   style_loss:  7422423.5   content_loss:  210885.69\n",
            "best: iteration:  128 loss:  6621293.5   style_loss:  7333558.0   content_loss:  210910.9\n",
            "best: iteration:  129 loss:  6542450.0   style_loss:  7245952.0   content_loss:  210935.06\n",
            "best: iteration:  130 loss:  6464773.5   style_loss:  7159641.0   content_loss:  210966.66\n",
            "best: iteration:  131 loss:  6388110.0   style_loss:  7074454.0   content_loss:  211010.64\n",
            "best: iteration:  132 loss:  6312396.5   style_loss:  6990322.5   content_loss:  211063.34\n",
            "best: iteration:  133 loss:  6237718.5   style_loss:  6907340.0   content_loss:  211118.27\n",
            "best: iteration:  134 loss:  6164095.5   style_loss:  6825532.0   content_loss:  211168.98\n",
            "best: iteration:  135 loss:  6091440.0   style_loss:  6744799.5   content_loss:  211211.06\n",
            "best: iteration:  136 loss:  6019691.0   style_loss:  6665074.0   content_loss:  211244.2\n",
            "best: iteration:  137 loss:  5948925.0   style_loss:  6586442.5   content_loss:  211271.48\n",
            "best: iteration:  138 loss:  5879199.5   style_loss:  6508966.5   content_loss:  211300.23\n",
            "best: iteration:  139 loss:  5810463.0   style_loss:  6432588.0   content_loss:  211334.64\n",
            "best: iteration:  140 loss:  5742645.0   style_loss:  6357231.0   content_loss:  211375.05\n",
            "best: iteration:  141 loss:  5675751.5   style_loss:  6282899.0   content_loss:  211418.64\n",
            "best: iteration:  142 loss:  5609799.0   style_loss:  6209615.0   content_loss:  211460.4\n",
            "best: iteration:  143 loss:  5544774.5   style_loss:  6137361.0   content_loss:  211496.23\n",
            "best: iteration:  144 loss:  5480614.0   style_loss:  6066068.5   content_loss:  211525.44\n",
            "best: iteration:  145 loss:  5417340.5   style_loss:  5995762.0   content_loss:  211549.23\n",
            "best: iteration:  146 loss:  5354963.0   style_loss:  5926451.5   content_loss:  211571.66\n",
            "best: iteration:  147 loss:  5293440.0   style_loss:  5858089.5   content_loss:  211596.34\n",
            "best: iteration:  148 loss:  5232761.5   style_loss:  5790665.5   content_loss:  211624.6\n",
            "best: iteration:  149 loss:  5172937.0   style_loss:  5724191.0   content_loss:  211655.6\n",
            "best: iteration:  150 loss:  5113944.5   style_loss:  5658639.5   content_loss:  211688.16\n",
            "best: iteration:  151 loss:  5055768.5   style_loss:  5593996.5   content_loss:  211718.98\n",
            "best: iteration:  152 loss:  4998408.5   style_loss:  5530260.0   content_loss:  211746.02\n",
            "best: iteration:  153 loss:  4941873.0   style_loss:  5467440.5   content_loss:  211768.9\n",
            "best: iteration:  154 loss:  4886118.5   style_loss:  5405489.0   content_loss:  211789.84\n",
            "best: iteration:  155 loss:  4831139.5   style_loss:  5344398.5   content_loss:  211811.19\n",
            "best: iteration:  156 loss:  4776944.0   style_loss:  5284178.5   content_loss:  211835.48\n",
            "best: iteration:  157 loss:  4723491.5   style_loss:  5224784.0   content_loss:  211862.16\n",
            "best: iteration:  158 loss:  4670774.5   style_loss:  5166206.0   content_loss:  211890.64\n",
            "best: iteration:  159 loss:  4618820.0   style_loss:  5108475.5   content_loss:  211918.52\n",
            "best: iteration:  160 loss:  4567598.0   style_loss:  5051559.5   content_loss:  211944.8\n",
            "best: iteration:  161 loss:  4517126.0   style_loss:  4995477.0   content_loss:  211968.3\n",
            "best: iteration:  162 loss:  4467376.0   style_loss:  4940197.0   content_loss:  211990.0\n",
            "best: iteration:  163 loss:  4418338.0   style_loss:  4885708.0   content_loss:  212011.19\n",
            "best: iteration:  164 loss:  4370012.5   style_loss:  4832009.5   content_loss:  212034.4\n",
            "best: iteration:  165 loss:  4322383.0   style_loss:  4779085.5   content_loss:  212059.44\n",
            "best: iteration:  166 loss:  4275453.5   style_loss:  4726939.0   content_loss:  212084.89\n",
            "best: iteration:  167 loss:  4229220.5   style_loss:  4675566.5   content_loss:  212108.81\n",
            "best: iteration:  168 loss:  4183669.8   style_loss:  4624952.0   content_loss:  212130.5\n",
            "best: iteration:  169 loss:  4138790.5   style_loss:  4575083.5   content_loss:  212150.34\n",
            "best: iteration:  170 loss:  4094569.8   style_loss:  4525947.5   content_loss:  212169.48\n",
            "best: iteration:  171 loss:  4050988.2   style_loss:  4477521.5   content_loss:  212188.9\n",
            "best: iteration:  172 loss:  4008032.0   style_loss:  4429790.0   content_loss:  212208.95\n",
            "best: iteration:  173 loss:  3965686.2   style_loss:  4382737.0   content_loss:  212229.7\n",
            "best: iteration:  174 loss:  3923947.0   style_loss:  4336357.5   content_loss:  212251.36\n",
            "best: iteration:  175 loss:  3882814.0   style_loss:  4290652.0   content_loss:  212272.5\n",
            "best: iteration:  176 loss:  3842278.5   style_loss:  4245610.5   content_loss:  212292.31\n",
            "best: iteration:  177 loss:  3802336.5   style_loss:  4201228.5   content_loss:  212310.52\n",
            "best: iteration:  178 loss:  3762971.8   style_loss:  4157487.5   content_loss:  212328.56\n",
            "best: iteration:  179 loss:  3724168.5   style_loss:  4114371.0   content_loss:  212346.89\n",
            "best: iteration:  180 loss:  3685924.2   style_loss:  4071875.5   content_loss:  212366.14\n",
            "best: iteration:  181 loss:  3648227.8   style_loss:  4029988.0   content_loss:  212386.81\n",
            "best: iteration:  182 loss:  3611074.0   style_loss:  3988703.5   content_loss:  212408.1\n",
            "best: iteration:  183 loss:  3574456.5   style_loss:  3948015.0   content_loss:  212429.19\n",
            "best: iteration:  184 loss:  3538377.8   style_loss:  3907925.5   content_loss:  212449.9\n",
            "best: iteration:  185 loss:  3502831.2   style_loss:  3868427.0   content_loss:  212469.7\n",
            "best: iteration:  186 loss:  3467800.0   style_loss:  3829501.5   content_loss:  212489.06\n",
            "best: iteration:  187 loss:  3433274.8   style_loss:  3791137.8   content_loss:  212508.19\n",
            "best: iteration:  188 loss:  3399239.8   style_loss:  3753319.0   content_loss:  212527.75\n",
            "best: iteration:  189 loss:  3365709.8   style_loss:  3716061.0   content_loss:  212548.05\n",
            "best: iteration:  190 loss:  3332669.5   style_loss:  3679347.0   content_loss:  212569.05\n",
            "best: iteration:  191 loss:  3300104.0   style_loss:  3643161.2   content_loss:  212590.02\n",
            "best: iteration:  192 loss:  3268020.2   style_loss:  3607510.2   content_loss:  212610.45\n",
            "best: iteration:  193 loss:  3236403.8   style_loss:  3572379.0   content_loss:  212630.6\n",
            "best: iteration:  194 loss:  3205232.2   style_loss:  3537741.2   content_loss:  212650.86\n",
            "best: iteration:  195 loss:  3174496.8   style_loss:  3503588.5   content_loss:  212671.27\n",
            "best: iteration:  196 loss:  3144203.2   style_loss:  3469926.5   content_loss:  212691.98\n",
            "best: iteration:  197 loss:  3114332.5   style_loss:  3436734.8   content_loss:  212712.0\n",
            "best: iteration:  198 loss:  3084904.8   style_loss:  3404035.0   content_loss:  212731.52\n",
            "best: iteration:  199 loss:  3055906.5   style_loss:  3371813.0   content_loss:  212750.19\n",
            "best: iteration:  0 loss:  4276751000.0   style_loss:  4751943700.0   content_loss:  17670.537\n",
            "best: iteration:  1 loss:  3301013500.0   style_loss:  3667787800.0   content_loss:  48394.33\n",
            "best: iteration:  2 loss:  2224233500.0   style_loss:  2471360000.0   content_loss:  92777.91\n",
            "best: iteration:  3 loss:  1462427100.0   style_loss:  1624902300.0   content_loss:  150965.78\n",
            "best: iteration:  4 loss:  1394240000.0   style_loss:  1549132300.0   content_loss:  211721.64\n",
            "best: iteration:  7 loss:  1074913000.0   style_loss:  1194319700.0   content_loss:  253352.64\n",
            "best: iteration:  8 loss:  760124700.0   style_loss:  844556400.0   content_loss:  239986.75\n",
            "best: iteration:  9 loss:  603970700.0   style_loss:  671053200.0   content_loss:  227548.23\n",
            "best: iteration:  10 loss:  567974140.0   style_loss:  631057860.0   content_loss:  220709.45\n",
            "best: iteration:  12 loss:  556095740.0   style_loss:  617858560.0   content_loss:  230337.16\n",
            "best: iteration:  13 loss:  527431420.0   style_loss:  586007600.0   content_loss:  245662.4\n",
            "best: iteration:  14 loss:  506880060.0   style_loss:  563170600.0   content_loss:  264712.2\n",
            "best: iteration:  15 loss:  506502270.0   style_loss:  562748800.0   content_loss:  283161.03\n",
            "best: iteration:  17 loss:  489234530.0   style_loss:  543560300.0   content_loss:  302246.12\n",
            "best: iteration:  18 loss:  449755230.0   style_loss:  499694620.0   content_loss:  301195.0\n",
            "best: iteration:  19 loss:  408462940.0   style_loss:  453814850.0   content_loss:  295902.7\n",
            "best: iteration:  20 loss:  378874980.0   style_loss:  420940060.0   content_loss:  289426.28\n",
            "best: iteration:  21 loss:  360645470.0   style_loss:  400685570.0   content_loss:  284345.78\n",
            "best: iteration:  22 loss:  345733500.0   style_loss:  384117020.0   content_loss:  282321.62\n",
            "best: iteration:  23 loss:  328489000.0   style_loss:  364956260.0   content_loss:  283978.47\n",
            "best: iteration:  24 loss:  309945470.0   style_loss:  344351740.0   content_loss:  288914.78\n",
            "best: iteration:  25 loss:  294823400.0   style_loss:  327548640.0   content_loss:  296042.56\n",
            "best: iteration:  26 loss:  285258750.0   style_loss:  316920420.0   content_loss:  303718.28\n",
            "best: iteration:  27 loss:  277790750.0   style_loss:  308621950.0   content_loss:  310219.3\n",
            "best: iteration:  28 loss:  267302000.0   style_loss:  296967300.0   content_loss:  314378.7\n",
            "best: iteration:  29 loss:  252835540.0   style_loss:  280893250.0   content_loss:  316153.53\n",
            "best: iteration:  30 loss:  237775650.0   style_loss:  264160030.0   content_loss:  316380.94\n",
            "best: iteration:  31 loss:  225319820.0   style_loss:  250320220.0   content_loss:  316350.62\n",
            "best: iteration:  32 loss:  215636460.0   style_loss:  239560830.0   content_loss:  317347.38\n",
            "best: iteration:  33 loss:  207068340.0   style_loss:  230040370.0   content_loss:  320220.44\n",
            "best: iteration:  34 loss:  198563600.0   style_loss:  220590110.0   content_loss:  325177.53\n",
            "best: iteration:  35 loss:  190529200.0   style_loss:  211662240.0   content_loss:  331781.25\n",
            "best: iteration:  36 loss:  183831140.0   style_loss:  204219140.0   content_loss:  339176.88\n",
            "best: iteration:  37 loss:  178300510.0   style_loss:  198073200.0   content_loss:  346274.38\n",
            "best: iteration:  38 loss:  172725200.0   style_loss:  191877780.0   content_loss:  352062.5\n",
            "best: iteration:  39 loss:  166187660.0   style_loss:  184613390.0   content_loss:  356093.5\n",
            "best: iteration:  40 loss:  159058050.0   style_loss:  176691330.0   content_loss:  358503.06\n",
            "best: iteration:  41 loss:  152393700.0   style_loss:  169286350.0   content_loss:  359897.47\n",
            "best: iteration:  42 loss:  146769500.0   style_loss:  163037120.0   content_loss:  361074.4\n",
            "best: iteration:  43 loss:  141981970.0   style_loss:  157717440.0   content_loss:  362701.84\n",
            "best: iteration:  44 loss:  137543520.0   style_loss:  152785570.0   content_loss:  365162.9\n",
            "best: iteration:  45 loss:  133226376.0   style_loss:  147988370.0   content_loss:  368488.12\n",
            "best: iteration:  46 loss:  129129120.0   style_loss:  143435420.0   content_loss:  372433.3\n",
            "best: iteration:  47 loss:  125379704.0   style_loss:  139268930.0   content_loss:  376558.94\n",
            "best: iteration:  48 loss:  121873630.0   style_loss:  135372880.0   content_loss:  380390.9\n",
            "best: iteration:  49 loss:  118376536.0   style_loss:  131486860.0   content_loss:  383577.47\n",
            "best: iteration:  50 loss:  114808296.0   style_loss:  127521890.0   content_loss:  386004.12\n",
            "best: iteration:  51 loss:  111308240.0   style_loss:  123632740.0   content_loss:  387805.88\n",
            "best: iteration:  52 loss:  108054870.0   style_loss:  120017730.0   content_loss:  389258.6\n",
            "best: iteration:  53 loss:  105110056.0   style_loss:  116745544.0   content_loss:  390685.22\n",
            "best: iteration:  54 loss:  102398400.0   style_loss:  113732420.0   content_loss:  392341.0\n",
            "best: iteration:  55 loss:  99820430.0   style_loss:  110867784.0   content_loss:  394336.5\n",
            "best: iteration:  56 loss:  97342370.0   style_loss:  108114110.0   content_loss:  396627.4\n",
            "best: iteration:  57 loss:  94987190.0   style_loss:  105496984.0   content_loss:  399045.3\n",
            "best: iteration:  58 loss:  92760180.0   style_loss:  103022264.0   content_loss:  401373.97\n",
            "best: iteration:  59 loss:  90636504.0   style_loss:  100662400.0   content_loss:  403413.9\n",
            "best: iteration:  60 loss:  88577540.0   style_loss:  98374480.0   content_loss:  405054.4\n",
            "best: iteration:  61 loss:  86577016.0   style_loss:  96151540.0   content_loss:  406305.3\n",
            "best: iteration:  62 loss:  84655200.0   style_loss:  94016080.0   content_loss:  407281.72\n",
            "best: iteration:  63 loss:  82829890.0   style_loss:  91987850.0   content_loss:  408150.03\n",
            "best: iteration:  64 loss:  81095140.0   style_loss:  90060240.0   content_loss:  409080.8\n",
            "best: iteration:  65 loss:  79427800.0   style_loss:  88207540.0   content_loss:  410167.2\n",
            "best: iteration:  66 loss:  77819320.0   style_loss:  86420210.0   content_loss:  411456.5\n",
            "best: iteration:  67 loss:  76272330.0   style_loss:  84701160.0   content_loss:  412898.2\n",
            "best: iteration:  68 loss:  74789030.0   style_loss:  83052880.0   content_loss:  414394.62\n",
            "best: iteration:  69 loss:  73362830.0   style_loss:  81468056.0   content_loss:  415824.53\n",
            "best: iteration:  70 loss:  71984690.0   style_loss:  79936640.0   content_loss:  417096.6\n",
            "best: iteration:  71 loss:  70646020.0   style_loss:  78449110.0   content_loss:  418173.88\n",
            "best: iteration:  72 loss:  69348870.0   style_loss:  77007736.0   content_loss:  419080.97\n",
            "best: iteration:  73 loss:  68099880.0   style_loss:  75619880.0   content_loss:  419880.9\n",
            "best: iteration:  74 loss:  66900012.0   style_loss:  74286610.0   content_loss:  420665.72\n",
            "best: iteration:  75 loss:  65741172.0   style_loss:  72998920.0   content_loss:  421506.12\n",
            "best: iteration:  76 loss:  64619270.0   style_loss:  71752260.0   content_loss:  422422.97\n",
            "best: iteration:  77 loss:  63534536.0   style_loss:  70546900.0   content_loss:  423402.12\n",
            "best: iteration:  78 loss:  62487304.0   style_loss:  69383180.0   content_loss:  424401.8\n",
            "best: iteration:  79 loss:  61476492.0   style_loss:  68259950.0   content_loss:  425369.72\n",
            "best: iteration:  80 loss:  60494336.0   style_loss:  67168570.0   content_loss:  426264.22\n",
            "best: iteration:  81 loss:  59537196.0   style_loss:  66104988.0   content_loss:  427065.1\n",
            "best: iteration:  82 loss:  58605280.0   style_loss:  65069444.0   content_loss:  427796.3\n",
            "best: iteration:  83 loss:  57700564.0   style_loss:  64064130.0   content_loss:  428490.38\n",
            "best: iteration:  84 loss:  56823452.0   style_loss:  63089480.0   content_loss:  429186.28\n",
            "best: iteration:  85 loss:  55971140.0   style_loss:  62142388.0   content_loss:  429916.5\n",
            "best: iteration:  86 loss:  55141268.0   style_loss:  61220220.0   content_loss:  430700.1\n",
            "best: iteration:  87 loss:  54334336.0   style_loss:  60323536.0   content_loss:  431522.97\n",
            "best: iteration:  88 loss:  53550376.0   style_loss:  59452380.0   content_loss:  432351.6\n",
            "best: iteration:  89 loss:  52789250.0   style_loss:  58606596.0   content_loss:  433142.47\n",
            "best: iteration:  90 loss:  52047452.0   style_loss:  57782296.0   content_loss:  433862.3\n",
            "best: iteration:  91 loss:  51322176.0   style_loss:  56976360.0   content_loss:  434508.72\n",
            "best: iteration:  92 loss:  50612720.0   style_loss:  56188016.0   content_loss:  435096.9\n",
            "best: iteration:  93 loss:  49921892.0   style_loss:  55420364.0   content_loss:  435652.3\n",
            "best: iteration:  94 loss:  49250210.0   style_loss:  54673988.0   content_loss:  436209.2\n",
            "best: iteration:  95 loss:  48595012.0   style_loss:  53945930.0   content_loss:  436794.97\n",
            "best: iteration:  96 loss:  47955484.0   style_loss:  53235268.0   content_loss:  437408.7\n",
            "best: iteration:  97 loss:  47329810.0   style_loss:  52540004.0   content_loss:  438032.0\n",
            "best: iteration:  98 loss:  46718456.0   style_loss:  51860660.0   content_loss:  438643.38\n",
            "best: iteration:  99 loss:  46120948.0   style_loss:  51196700.0   content_loss:  439219.12\n",
            "best: iteration:  100 loss:  45535748.0   style_loss:  50546416.0   content_loss:  439742.38\n",
            "best: iteration:  101 loss:  44961920.0   style_loss:  49908784.0   content_loss:  440215.4\n",
            "best: iteration:  102 loss:  44399344.0   style_loss:  49283644.0   content_loss:  440654.28\n",
            "best: iteration:  103 loss:  43848332.0   style_loss:  48671360.0   content_loss:  441085.7\n",
            "best: iteration:  104 loss:  43308280.0   style_loss:  48071256.0   content_loss:  441526.8\n",
            "best: iteration:  105 loss:  42778252.0   style_loss:  47482280.0   content_loss:  441990.22\n",
            "best: iteration:  106 loss:  42258224.0   style_loss:  46904420.0   content_loss:  442471.53\n",
            "best: iteration:  107 loss:  41748416.0   style_loss:  46337910.0   content_loss:  442959.38\n",
            "best: iteration:  108 loss:  41247572.0   style_loss:  45781364.0   content_loss:  443440.62\n",
            "best: iteration:  109 loss:  40756200.0   style_loss:  45235348.0   content_loss:  443901.53\n",
            "best: iteration:  110 loss:  40273228.0   style_loss:  44698668.0   content_loss:  444338.1\n",
            "best: iteration:  111 loss:  39799068.0   style_loss:  44171772.0   content_loss:  444756.2\n",
            "best: iteration:  112 loss:  39333500.0   style_loss:  43654428.0   content_loss:  445162.72\n",
            "best: iteration:  113 loss:  38875932.0   style_loss:  43145976.0   content_loss:  445572.62\n",
            "best: iteration:  114 loss:  38426924.0   style_loss:  42647030.0   content_loss:  445994.62\n",
            "best: iteration:  115 loss:  37986080.0   style_loss:  42157150.0   content_loss:  446431.12\n",
            "best: iteration:  116 loss:  37553228.0   style_loss:  41676156.0   content_loss:  446865.28\n",
            "best: iteration:  117 loss:  37127776.0   style_loss:  41203390.0   content_loss:  447286.62\n",
            "best: iteration:  118 loss:  36709150.0   style_loss:  40738204.0   content_loss:  447690.53\n",
            "best: iteration:  119 loss:  36296790.0   style_loss:  40279984.0   content_loss:  448070.28\n",
            "best: iteration:  120 loss:  35890910.0   style_loss:  39828964.0   content_loss:  448429.2\n",
            "best: iteration:  121 loss:  35491316.0   style_loss:  39384936.0   content_loss:  448769.7\n",
            "best: iteration:  122 loss:  35097836.0   style_loss:  38947696.0   content_loss:  449107.0\n",
            "best: iteration:  123 loss:  34709544.0   style_loss:  38516224.0   content_loss:  449443.2\n",
            "best: iteration:  124 loss:  34326956.0   style_loss:  38091084.0   content_loss:  449785.12\n",
            "best: iteration:  125 loss:  33950280.0   style_loss:  37672520.0   content_loss:  450130.78\n",
            "best: iteration:  126 loss:  33579256.0   style_loss:  37260230.0   content_loss:  450472.47\n",
            "best: iteration:  127 loss:  33214198.0   style_loss:  36854576.0   content_loss:  450801.88\n",
            "best: iteration:  128 loss:  32854614.0   style_loss:  36455000.0   content_loss:  451121.53\n",
            "best: iteration:  129 loss:  32500338.0   style_loss:  36061330.0   content_loss:  451433.1\n",
            "best: iteration:  130 loss:  32150614.0   style_loss:  35672710.0   content_loss:  451742.28\n",
            "best: iteration:  131 loss:  31805486.0   style_loss:  35289210.0   content_loss:  452048.2\n",
            "best: iteration:  132 loss:  31465172.0   style_loss:  34911040.0   content_loss:  452355.72\n",
            "best: iteration:  133 loss:  31129238.0   style_loss:  34537750.0   content_loss:  452667.3\n",
            "best: iteration:  134 loss:  30797962.0   style_loss:  34169628.0   content_loss:  452975.8\n",
            "best: iteration:  135 loss:  30471202.0   style_loss:  33806524.0   content_loss:  453276.22\n",
            "best: iteration:  136 loss:  30148876.0   style_loss:  33448354.0   content_loss:  453564.97\n",
            "best: iteration:  137 loss:  29830938.0   style_loss:  33095058.0   content_loss:  453843.0\n",
            "best: iteration:  138 loss:  29517084.0   style_loss:  32746304.0   content_loss:  454110.97\n",
            "best: iteration:  139 loss:  29207856.0   style_loss:  32402688.0   content_loss:  454376.6\n",
            "best: iteration:  140 loss:  28902614.0   style_loss:  32063500.0   content_loss:  454644.38\n",
            "best: iteration:  141 loss:  28601000.0   style_loss:  31728342.0   content_loss:  454910.9\n",
            "best: iteration:  142 loss:  28303354.0   style_loss:  31397596.0   content_loss:  455175.2\n",
            "best: iteration:  143 loss:  28009576.0   style_loss:  31071148.0   content_loss:  455433.62\n",
            "best: iteration:  144 loss:  27719530.0   style_loss:  30748848.0   content_loss:  455688.5\n",
            "best: iteration:  145 loss:  27433348.0   style_loss:  30430840.0   content_loss:  455941.72\n",
            "best: iteration:  146 loss:  27150704.0   style_loss:  30116764.0   content_loss:  456188.8\n",
            "best: iteration:  147 loss:  26871664.0   style_loss:  29806688.0   content_loss:  456433.1\n",
            "best: iteration:  148 loss:  26595852.0   style_loss:  29500204.0   content_loss:  456674.8\n",
            "best: iteration:  149 loss:  26323378.0   style_loss:  29197428.0   content_loss:  456916.8\n",
            "best: iteration:  150 loss:  26054654.0   style_loss:  28898820.0   content_loss:  457159.12\n",
            "best: iteration:  151 loss:  25789504.0   style_loss:  28604180.0   content_loss:  457397.47\n",
            "best: iteration:  152 loss:  25527950.0   style_loss:  28313542.0   content_loss:  457631.47\n",
            "best: iteration:  153 loss:  25269744.0   style_loss:  28026618.0   content_loss:  457861.88\n",
            "best: iteration:  154 loss:  25015096.0   style_loss:  27743654.0   content_loss:  458086.7\n",
            "best: iteration:  155 loss:  24763864.0   style_loss:  27464482.0   content_loss:  458306.78\n",
            "best: iteration:  156 loss:  24515808.0   style_loss:  27188838.0   content_loss:  458519.88\n",
            "best: iteration:  157 loss:  24270874.0   style_loss:  26916672.0   content_loss:  458727.47\n",
            "best: iteration:  158 loss:  24028734.0   style_loss:  26647600.0   content_loss:  458933.28\n",
            "best: iteration:  159 loss:  23789032.0   style_loss:  26381244.0   content_loss:  459139.72\n",
            "best: iteration:  160 loss:  23552170.0   style_loss:  26118040.0   content_loss:  459344.6\n",
            "best: iteration:  161 loss:  23318352.0   style_loss:  25858218.0   content_loss:  459550.38\n",
            "best: iteration:  162 loss:  23087814.0   style_loss:  25602042.0   content_loss:  459758.2\n",
            "best: iteration:  163 loss:  22860536.0   style_loss:  25349488.0   content_loss:  459967.3\n",
            "best: iteration:  164 loss:  22636266.0   style_loss:  25100276.0   content_loss:  460172.3\n",
            "best: iteration:  165 loss:  22414732.0   style_loss:  24854108.0   content_loss:  460371.3\n",
            "best: iteration:  166 loss:  22195732.0   style_loss:  24610752.0   content_loss:  460565.9\n",
            "best: iteration:  167 loss:  21979778.0   style_loss:  24370780.0   content_loss:  460757.7\n",
            "best: iteration:  168 loss:  21766896.0   style_loss:  24134224.0   content_loss:  460948.6\n",
            "best: iteration:  169 loss:  21556640.0   style_loss:  23900584.0   content_loss:  461139.47\n",
            "best: iteration:  170 loss:  21348752.0   style_loss:  23669578.0   content_loss:  461328.1\n",
            "best: iteration:  171 loss:  21143726.0   style_loss:  23441750.0   content_loss:  461515.8\n",
            "best: iteration:  172 loss:  20941244.0   style_loss:  23216748.0   content_loss:  461699.1\n",
            "best: iteration:  173 loss:  20741410.0   style_loss:  22994694.0   content_loss:  461877.38\n",
            "best: iteration:  174 loss:  20544144.0   style_loss:  22775488.0   content_loss:  462052.1\n",
            "best: iteration:  175 loss:  20349130.0   style_loss:  22558788.0   content_loss:  462221.53\n",
            "best: iteration:  176 loss:  20156254.0   style_loss:  22344460.0   content_loss:  462393.72\n",
            "best: iteration:  177 loss:  19965470.0   style_loss:  22132460.0   content_loss:  462568.62\n",
            "best: iteration:  178 loss:  19776752.0   style_loss:  21922756.0   content_loss:  462743.62\n",
            "best: iteration:  179 loss:  19590090.0   style_loss:  21715332.0   content_loss:  462919.8\n",
            "best: iteration:  180 loss:  19405550.0   style_loss:  21510268.0   content_loss:  463094.62\n",
            "best: iteration:  181 loss:  19223436.0   style_loss:  21307900.0   content_loss:  463265.7\n",
            "best: iteration:  182 loss:  19043340.0   style_loss:  21107776.0   content_loss:  463432.62\n",
            "best: iteration:  183 loss:  18864966.0   style_loss:  20909564.0   content_loss:  463594.7\n",
            "best: iteration:  184 loss:  18688428.0   style_loss:  20713392.0   content_loss:  463754.62\n",
            "best: iteration:  185 loss:  18514234.0   style_loss:  20519824.0   content_loss:  463912.12\n",
            "best: iteration:  186 loss:  18342132.0   style_loss:  20328588.0   content_loss:  464062.0\n",
            "best: iteration:  187 loss:  18171988.0   style_loss:  20139520.0   content_loss:  464205.78\n",
            "best: iteration:  188 loss:  18003878.0   style_loss:  19952716.0   content_loss:  464348.53\n",
            "best: iteration:  189 loss:  17837922.0   style_loss:  19768300.0   content_loss:  464493.78\n",
            "best: iteration:  190 loss:  17673692.0   style_loss:  19585810.0   content_loss:  464642.4\n",
            "best: iteration:  191 loss:  17511456.0   style_loss:  19405530.0   content_loss:  464794.0\n",
            "best: iteration:  192 loss:  17351190.0   style_loss:  19227438.0   content_loss:  464946.12\n",
            "best: iteration:  193 loss:  17192716.0   style_loss:  19051340.0   content_loss:  465095.1\n",
            "best: iteration:  194 loss:  17036276.0   style_loss:  18877504.0   content_loss:  465241.5\n",
            "best: iteration:  195 loss:  16881928.0   style_loss:  18705990.0   content_loss:  465382.4\n",
            "best: iteration:  196 loss:  16729376.0   style_loss:  18536472.0   content_loss:  465517.12\n",
            "best: iteration:  197 loss:  16578789.0   style_loss:  18369138.0   content_loss:  465645.38\n",
            "best: iteration:  198 loss:  16430258.0   style_loss:  18204090.0   content_loss:  465769.9\n",
            "best: iteration:  199 loss:  16284018.0   style_loss:  18041588.0   content_loss:  465891.97\n",
            "best: iteration:  0 loss:  79121144.0   style_loss:  87910520.0   content_loss:  16780.605\n",
            "best: iteration:  1 loss:  56370184.0   style_loss:  62628720.0   content_loss:  43361.504\n",
            "best: iteration:  3 loss:  39193980.0   style_loss:  43543004.0   content_loss:  52719.227\n",
            "best: iteration:  4 loss:  29742408.0   style_loss:  33041416.0   content_loss:  51338.55\n",
            "best: iteration:  5 loss:  26615240.0   style_loss:  29566672.0   content_loss:  52355.066\n",
            "best: iteration:  6 loss:  23627648.0   style_loss:  26246878.0   content_loss:  54587.863\n",
            "best: iteration:  7 loss:  20612444.0   style_loss:  22896454.0   content_loss:  56370.066\n",
            "best: iteration:  8 loss:  17604586.0   style_loss:  19554340.0   content_loss:  56798.863\n",
            "best: iteration:  9 loss:  14374523.0   style_loss:  15965482.0   content_loss:  55896.625\n",
            "best: iteration:  10 loss:  11852241.0   style_loss:  13163092.0   content_loss:  54575.69\n",
            "best: iteration:  11 loss:  10346522.0   style_loss:  11490161.0   content_loss:  53770.04\n",
            "best: iteration:  12 loss:  9311277.0   style_loss:  10339880.0   content_loss:  53848.297\n",
            "best: iteration:  13 loss:  8427162.0   style_loss:  9357453.0   content_loss:  54548.027\n",
            "best: iteration:  14 loss:  7670072.0   style_loss:  8516159.0   content_loss:  55299.223\n",
            "best: iteration:  15 loss:  6950025.0   style_loss:  7716063.0   content_loss:  55687.49\n",
            "best: iteration:  16 loss:  6218096.0   style_loss:  6902809.5   content_loss:  55675.8\n",
            "best: iteration:  17 loss:  5584071.0   style_loss:  6198346.5   content_loss:  55593.51\n",
            "best: iteration:  18 loss:  5071173.0   style_loss:  5628444.0   content_loss:  55731.76\n",
            "best: iteration:  19 loss:  4623022.0   style_loss:  5130447.5   content_loss:  56196.297\n",
            "best: iteration:  20 loss:  4239026.5   style_loss:  4703710.5   content_loss:  56871.266\n",
            "best: iteration:  21 loss:  3908296.5   style_loss:  4336165.0   content_loss:  57479.64\n",
            "best: iteration:  22 loss:  3589318.8   style_loss:  3981708.2   content_loss:  57815.38\n",
            "best: iteration:  23 loss:  3292026.2   style_loss:  3651375.0   content_loss:  57885.938\n",
            "best: iteration:  24 loss:  3032196.8   style_loss:  3362673.8   content_loss:  57906.1\n",
            "best: iteration:  25 loss:  2790028.8   style_loss:  3093579.2   content_loss:  58072.15\n",
            "best: iteration:  26 loss:  2568345.0   style_loss:  2847224.5   content_loss:  58430.9\n",
            "best: iteration:  27 loss:  2378516.5   style_loss:  2636252.0   content_loss:  58893.902\n",
            "best: iteration:  28 loss:  2204575.8   style_loss:  2442940.5   content_loss:  59292.76\n",
            "best: iteration:  29 loss:  2039795.8   style_loss:  2259823.2   content_loss:  59549.1\n",
            "best: iteration:  30 loss:  1885143.2   style_loss:  2087968.6   content_loss:  59716.375\n",
            "best: iteration:  31 loss:  1737678.5   style_loss:  1924096.5   content_loss:  59917.61\n",
            "best: iteration:  32 loss:  1607055.2   style_loss:  1778925.8   content_loss:  60221.84\n",
            "best: iteration:  33 loss:  1495233.6   style_loss:  1654639.0   content_loss:  60586.04\n",
            "best: iteration:  34 loss:  1393134.0   style_loss:  1541158.6   content_loss:  60912.496\n",
            "best: iteration:  35 loss:  1302548.6   style_loss:  1440483.4   content_loss:  61135.83\n",
            "best: iteration:  36 loss:  1221534.1   style_loss:  1350452.9   content_loss:  61266.58\n",
            "best: iteration:  37 loss:  1146609.5   style_loss:  1267191.5   content_loss:  61372.67\n",
            "best: iteration:  38 loss:  1083363.8   style_loss:  1196901.5   content_loss:  61523.703\n",
            "best: iteration:  39 loss:  1028124.25   style_loss:  1135500.8   content_loss:  61736.09\n",
            "best: iteration:  40 loss:  976656.44   style_loss:  1078286.8   content_loss:  61982.76\n",
            "best: iteration:  41 loss:  932402.94   style_loss:  1029089.25   content_loss:  62226.44\n",
            "best: iteration:  42 loss:  889953.75   style_loss:  981900.4   content_loss:  62434.496\n",
            "best: iteration:  43 loss:  848489.1   style_loss:  935809.9   content_loss:  62602.62\n",
            "best: iteration:  44 loss:  813597.94   style_loss:  897025.94   content_loss:  62746.316\n",
            "best: iteration:  45 loss:  781173.06   style_loss:  860982.8   content_loss:  62885.375\n",
            "best: iteration:  46 loss:  750145.1   style_loss:  826490.9   content_loss:  63033.37\n",
            "best: iteration:  47 loss:  722442.0   style_loss:  795692.9   content_loss:  63183.66\n",
            "best: iteration:  48 loss:  695617.5   style_loss:  765873.25   content_loss:  63315.363\n",
            "best: iteration:  49 loss:  671439.9   style_loss:  738997.75   content_loss:  63419.184\n",
            "best: iteration:  50 loss:  649745.7   style_loss:  714882.06   content_loss:  63518.89\n",
            "best: iteration:  51 loss:  628100.56   style_loss:  690816.4   content_loss:  63657.88\n",
            "best: iteration:  52 loss:  608466.06   style_loss:  668979.5   content_loss:  63845.074\n",
            "best: iteration:  53 loss:  590533.44   style_loss:  649033.2   content_loss:  64035.83\n",
            "best: iteration:  54 loss:  573345.0   style_loss:  629920.25   content_loss:  64168.16\n",
            "best: iteration:  55 loss:  557550.44   style_loss:  612363.6   content_loss:  64231.66\n",
            "best: iteration:  56 loss:  542579.4   style_loss:  595723.7   content_loss:  64281.41\n",
            "best: iteration:  57 loss:  528720.4   style_loss:  580314.4   content_loss:  64374.465\n",
            "best: iteration:  58 loss:  516121.03   style_loss:  566301.06   content_loss:  64501.086\n",
            "best: iteration:  59 loss:  503992.62   style_loss:  552814.5   content_loss:  64595.94\n",
            "best: iteration:  60 loss:  492262.44   style_loss:  539777.9   content_loss:  64623.934\n",
            "best: iteration:  61 loss:  481216.12   style_loss:  527503.6   content_loss:  64628.598\n",
            "best: iteration:  62 loss:  470793.38   style_loss:  515917.4   content_loss:  64677.15\n",
            "best: iteration:  63 loss:  460873.5   style_loss:  504884.44   content_loss:  64775.4\n",
            "best: iteration:  64 loss:  451445.3   style_loss:  494399.44   content_loss:  64858.5\n",
            "best: iteration:  65 loss:  442275.62   style_loss:  484208.75   content_loss:  64877.363\n",
            "best: iteration:  66 loss:  433612.94   style_loss:  474585.3   content_loss:  64861.566\n",
            "best: iteration:  67 loss:  425359.56   style_loss:  465413.16   content_loss:  64877.41\n",
            "best: iteration:  68 loss:  417350.06   style_loss:  456506.97   content_loss:  64938.203\n",
            "best: iteration:  69 loss:  409773.3   style_loss:  448082.38   content_loss:  64992.13\n",
            "best: iteration:  70 loss:  402321.1   style_loss:  439801.25   content_loss:  65000.023\n",
            "best: iteration:  71 loss:  395149.03   style_loss:  431833.03   content_loss:  64993.176\n",
            "best: iteration:  72 loss:  388223.47   style_loss:  424134.38   content_loss:  65025.215\n",
            "best: iteration:  73 loss:  381542.56   style_loss:  416703.72   content_loss:  65092.12\n",
            "best: iteration:  74 loss:  375160.88   style_loss:  409607.75   content_loss:  65139.066\n",
            "best: iteration:  75 loss:  368852.47   style_loss:  402598.7   content_loss:  65136.44\n",
            "best: iteration:  76 loss:  362793.5   style_loss:  395868.44   content_loss:  65119.016\n",
            "best: iteration:  77 loss:  356890.94   style_loss:  389308.38   content_loss:  65134.13\n",
            "best: iteration:  78 loss:  351180.44   style_loss:  382958.66   content_loss:  65176.523\n",
            "best: iteration:  79 loss:  345629.06   style_loss:  376787.38   content_loss:  65204.41\n",
            "best: iteration:  80 loss:  340206.84   style_loss:  370762.34   content_loss:  65207.438\n",
            "best: iteration:  81 loss:  334940.38   style_loss:  364909.78   content_loss:  65215.824\n",
            "best: iteration:  82 loss:  329766.03   style_loss:  359156.8   content_loss:  65249.113\n",
            "best: iteration:  83 loss:  324786.03   style_loss:  353619.53   content_loss:  65284.273\n",
            "best: iteration:  84 loss:  319899.62   style_loss:  348189.1   content_loss:  65294.49\n",
            "best: iteration:  85 loss:  315133.34   style_loss:  342893.7   content_loss:  65290.59\n",
            "best: iteration:  86 loss:  310464.2   style_loss:  337704.56   content_loss:  65300.67\n",
            "best: iteration:  87 loss:  305930.94   style_loss:  332664.8   content_loss:  65326.375\n",
            "best: iteration:  88 loss:  301496.2   style_loss:  327735.28   content_loss:  65344.426\n",
            "best: iteration:  89 loss:  297123.7   style_loss:  322876.56   content_loss:  65347.934\n",
            "best: iteration:  90 loss:  292862.56   style_loss:  318141.16   content_loss:  65355.188\n",
            "best: iteration:  91 loss:  288689.78   style_loss:  313502.34   content_loss:  65376.99\n",
            "best: iteration:  92 loss:  284624.16   style_loss:  308982.5   content_loss:  65398.875\n",
            "best: iteration:  93 loss:  280620.2   style_loss:  304532.78   content_loss:  65406.75\n",
            "best: iteration:  94 loss:  276711.62   style_loss:  300189.72   content_loss:  65408.62\n",
            "best: iteration:  95 loss:  272878.44   style_loss:  295929.6   content_loss:  65418.266\n",
            "best: iteration:  96 loss:  269123.47   style_loss:  291755.84   content_loss:  65432.59\n",
            "best: iteration:  97 loss:  265436.06   style_loss:  287657.66   content_loss:  65441.504\n",
            "best: iteration:  98 loss:  261817.84   style_loss:  283636.7   content_loss:  65448.348\n",
            "best: iteration:  99 loss:  258271.6   style_loss:  279694.8   content_loss:  65462.7\n",
            "best: iteration:  100 loss:  254791.56   style_loss:  275826.06   content_loss:  65481.066\n",
            "best: iteration:  101 loss:  251374.56   style_loss:  272028.22   content_loss:  65491.688\n",
            "best: iteration:  102 loss:  248018.34   style_loss:  268298.78   content_loss:  65494.684\n",
            "best: iteration:  103 loss:  244723.23   style_loss:  264636.9   content_loss:  65500.31\n",
            "best: iteration:  104 loss:  241489.38   style_loss:  261042.5   content_loss:  65511.223\n",
            "best: iteration:  105 loss:  238310.0   style_loss:  257508.8   content_loss:  65521.016\n",
            "best: iteration:  106 loss:  235188.19   style_loss:  254039.31   content_loss:  65528.125\n",
            "best: iteration:  107 loss:  232117.78   style_loss:  250626.61   content_loss:  65538.57\n",
            "best: iteration:  108 loss:  229106.03   style_loss:  247278.67   content_loss:  65552.32\n",
            "best: iteration:  109 loss:  226145.34   style_loss:  243987.86   content_loss:  65562.83\n",
            "best: iteration:  110 loss:  223235.98   style_loss:  240754.61   content_loss:  65568.664\n",
            "best: iteration:  111 loss:  220377.17   style_loss:  237577.33   content_loss:  65575.82\n",
            "best: iteration:  112 loss:  217566.66   style_loss:  234453.33   content_loss:  65586.59\n",
            "best: iteration:  113 loss:  214802.44   style_loss:  231380.88   content_loss:  65596.49\n",
            "best: iteration:  114 loss:  212085.77   style_loss:  228361.6   content_loss:  65603.51\n",
            "best: iteration:  115 loss:  209415.28   style_loss:  225393.53   content_loss:  65611.18\n",
            "best: iteration:  116 loss:  206786.7   style_loss:  222471.77   content_loss:  65621.27\n",
            "best: iteration:  117 loss:  204202.12   style_loss:  219598.97   content_loss:  65630.55\n",
            "best: iteration:  118 loss:  201659.06   style_loss:  216772.56   content_loss:  65637.59\n",
            "best: iteration:  119 loss:  199157.23   style_loss:  213991.94   content_loss:  65644.875\n",
            "best: iteration:  120 loss:  196695.98   style_loss:  211256.31   content_loss:  65653.08\n",
            "best: iteration:  121 loss:  194273.81   style_loss:  208564.22   content_loss:  65660.08\n",
            "best: iteration:  122 loss:  191889.86   style_loss:  205914.75   content_loss:  65666.09\n",
            "best: iteration:  123 loss:  189544.16   style_loss:  203307.6   content_loss:  65673.31\n",
            "best: iteration:  124 loss:  187237.27   style_loss:  200743.45   content_loss:  65681.5\n",
            "best: iteration:  125 loss:  184967.3   style_loss:  198220.47   content_loss:  65688.73\n",
            "best: iteration:  126 loss:  182733.22   style_loss:  195737.4   content_loss:  65695.63\n",
            "best: iteration:  127 loss:  180533.62   style_loss:  193292.58   content_loss:  65703.08\n",
            "best: iteration:  128 loss:  178368.75   style_loss:  190886.45   content_loss:  65709.54\n",
            "best: iteration:  129 loss:  176238.56   style_loss:  188518.94   content_loss:  65715.125\n",
            "best: iteration:  130 loss:  174142.97   style_loss:  186189.75   content_loss:  65722.08\n",
            "best: iteration:  131 loss:  172080.5   style_loss:  183897.19   content_loss:  65730.35\n",
            "best: iteration:  132 loss:  170050.16   style_loss:  181640.47   content_loss:  65737.43\n",
            "best: iteration:  133 loss:  168051.44   style_loss:  179418.98   content_loss:  65743.695\n",
            "best: iteration:  134 loss:  166084.78   style_loss:  177232.94   content_loss:  65751.45\n",
            "best: iteration:  135 loss:  164149.97   style_loss:  175082.23   content_loss:  65759.66\n",
            "best: iteration:  136 loss:  162244.72   style_loss:  172964.61   content_loss:  65765.74\n",
            "best: iteration:  137 loss:  160368.8   style_loss:  170879.61   content_loss:  65771.555\n",
            "best: iteration:  138 loss:  158522.02   style_loss:  168826.77   content_loss:  65779.43\n",
            "best: iteration:  139 loss:  156703.14   style_loss:  166804.88   content_loss:  65787.53\n",
            "best: iteration:  140 loss:  154912.64   style_loss:  164814.73   content_loss:  65793.85\n",
            "best: iteration:  141 loss:  153150.27   style_loss:  162855.84   content_loss:  65800.22\n",
            "best: iteration:  142 loss:  151415.17   style_loss:  160927.03   content_loss:  65808.375\n",
            "best: iteration:  143 loss:  149705.77   style_loss:  159026.84   content_loss:  65816.12\n",
            "best: iteration:  144 loss:  148022.38   style_loss:  157155.73   content_loss:  65822.2\n",
            "best: iteration:  145 loss:  146365.53   style_loss:  155314.03   content_loss:  65829.13\n",
            "best: iteration:  146 loss:  144734.72   style_loss:  153501.12   content_loss:  65837.02\n",
            "best: iteration:  147 loss:  143129.36   style_loss:  151716.64   content_loss:  65843.88\n",
            "best: iteration:  148 loss:  141548.81   style_loss:  149959.81   content_loss:  65849.83\n",
            "best: iteration:  149 loss:  139992.16   style_loss:  148229.45   content_loss:  65856.54\n",
            "best: iteration:  150 loss:  138458.7   style_loss:  146524.78   content_loss:  65863.836\n",
            "best: iteration:  151 loss:  136948.75   style_loss:  144846.38   content_loss:  65870.18\n",
            "best: iteration:  152 loss:  135461.69   style_loss:  143193.44   content_loss:  65876.07\n",
            "best: iteration:  153 loss:  133997.6   style_loss:  141565.9   content_loss:  65882.805\n",
            "best: iteration:  154 loss:  132556.77   style_loss:  139964.25   content_loss:  65889.46\n",
            "best: iteration:  155 loss:  131137.94   style_loss:  138387.12   content_loss:  65895.1\n",
            "best: iteration:  156 loss:  129740.9   style_loss:  136834.23   content_loss:  65900.805\n",
            "best: iteration:  157 loss:  128364.67   style_loss:  135304.42   content_loss:  65906.98\n",
            "best: iteration:  158 loss:  127009.05   style_loss:  133797.55   content_loss:  65912.59\n",
            "best: iteration:  159 loss:  125673.86   style_loss:  132313.47   content_loss:  65917.46\n",
            "best: iteration:  160 loss:  124359.484   style_loss:  130852.484   content_loss:  65922.43\n",
            "best: iteration:  161 loss:  123065.44   style_loss:  129414.086   content_loss:  65927.586\n",
            "best: iteration:  162 loss:  121791.42   style_loss:  127998.016   content_loss:  65932.3\n",
            "best: iteration:  163 loss:  120536.17   style_loss:  126602.8   content_loss:  65936.66\n",
            "best: iteration:  164 loss:  119299.91   style_loss:  125228.66   content_loss:  65941.13\n",
            "best: iteration:  165 loss:  118083.49   style_loss:  123876.61   content_loss:  65945.49\n",
            "best: iteration:  166 loss:  116886.195   style_loss:  122545.81   content_loss:  65949.74\n",
            "best: iteration:  167 loss:  115707.23   style_loss:  121235.33   content_loss:  65954.4\n",
            "best: iteration:  168 loss:  114546.516   style_loss:  119945.09   content_loss:  65959.26\n",
            "best: iteration:  169 loss:  113403.69   style_loss:  118674.79   content_loss:  65963.81\n",
            "best: iteration:  170 loss:  112278.61   style_loss:  117424.23   content_loss:  65968.05\n",
            "best: iteration:  171 loss:  111171.25   style_loss:  116193.35   content_loss:  65972.32\n",
            "best: iteration:  172 loss:  110080.93   style_loss:  114981.38   content_loss:  65976.84\n",
            "best: iteration:  173 loss:  109007.61   style_loss:  113788.266   content_loss:  65981.76\n",
            "best: iteration:  174 loss:  107951.0   style_loss:  112613.69   content_loss:  65986.87\n",
            "best: iteration:  175 loss:  106910.55   style_loss:  111457.09   content_loss:  65991.52\n",
            "best: iteration:  176 loss:  105886.37   style_loss:  110318.66   content_loss:  65995.8\n",
            "best: iteration:  177 loss:  104877.51   style_loss:  109197.25   content_loss:  65999.91\n",
            "best: iteration:  178 loss:  103883.625   style_loss:  108092.484   content_loss:  66003.91\n",
            "best: iteration:  179 loss:  102904.71   style_loss:  107004.33   content_loss:  66008.17\n",
            "best: iteration:  180 loss:  101940.59   style_loss:  105932.58   content_loss:  66012.734\n",
            "best: iteration:  181 loss:  100990.82   style_loss:  104876.78   content_loss:  66017.19\n",
            "best: iteration:  182 loss:  100055.836   style_loss:  103837.43   content_loss:  66021.46\n",
            "best: iteration:  183 loss:  99135.125   style_loss:  102813.97   content_loss:  66025.51\n",
            "best: iteration:  184 loss:  98228.48   style_loss:  101806.19   content_loss:  66029.15\n",
            "best: iteration:  185 loss:  97335.81   style_loss:  100813.92   content_loss:  66032.84\n",
            "best: iteration:  186 loss:  96456.78   style_loss:  99836.8   content_loss:  66036.76\n",
            "best: iteration:  187 loss:  95590.77   style_loss:  98874.16   content_loss:  66040.37\n",
            "best: iteration:  188 loss:  94738.016   style_loss:  97926.3   content_loss:  66043.6\n",
            "best: iteration:  189 loss:  93898.516   style_loss:  96993.14   content_loss:  66046.91\n",
            "best: iteration:  190 loss:  93072.03   style_loss:  96074.484   content_loss:  66049.96\n",
            "best: iteration:  191 loss:  92257.89   style_loss:  95169.58   content_loss:  66052.75\n",
            "best: iteration:  192 loss:  91456.1   style_loss:  94278.36   content_loss:  66055.72\n",
            "best: iteration:  193 loss:  90666.914   style_loss:  93401.16   content_loss:  66058.72\n",
            "best: iteration:  194 loss:  89890.164   style_loss:  92537.8   content_loss:  66061.586\n",
            "best: iteration:  195 loss:  89125.84   style_loss:  91688.2   content_loss:  66064.516\n",
            "best: iteration:  196 loss:  88373.47   style_loss:  90851.92   content_loss:  66067.43\n",
            "best: iteration:  197 loss:  87632.875   style_loss:  90028.73   content_loss:  66070.22\n",
            "best: iteration:  198 loss:  86903.805   style_loss:  89218.39   content_loss:  66072.56\n",
            "best: iteration:  199 loss:  86185.56   style_loss:  88420.125   content_loss:  66074.49\n",
            "best: iteration:  0 loss:  2556701700.0   style_loss:  2840778000.0   content_loss:  14531.608\n",
            "best: iteration:  1 loss:  2330412500.0   style_loss:  2589344300.0   content_loss:  28816.268\n",
            "best: iteration:  2 loss:  2072259300.0   style_loss:  2302505200.0   content_loss:  46969.582\n",
            "best: iteration:  3 loss:  1841515100.0   style_loss:  2046120600.0   content_loss:  66957.71\n",
            "best: iteration:  4 loss:  1663382400.0   style_loss:  1848193200.0   content_loss:  86977.63\n",
            "best: iteration:  5 loss:  1542417800.0   style_loss:  1713785900.0   content_loss:  104852.08\n",
            "best: iteration:  6 loss:  1463169700.0   style_loss:  1625731200.0   content_loss:  117719.62\n",
            "best: iteration:  7 loss:  1402317600.0   style_loss:  1558116900.0   content_loss:  124643.66\n",
            "best: iteration:  8 loss:  1343562800.0   style_loss:  1492833400.0   content_loss:  126630.02\n",
            "best: iteration:  9 loss:  1283414800.0   style_loss:  1426002600.0   content_loss:  125588.695\n",
            "best: iteration:  10 loss:  1225892600.0   style_loss:  1362089200.0   content_loss:  123248.49\n",
            "best: iteration:  11 loss:  1175015700.0   style_loss:  1305559700.0   content_loss:  120811.66\n",
            "best: iteration:  12 loss:  1132130600.0   style_loss:  1257909600.0   content_loss:  118814.33\n",
            "best: iteration:  13 loss:  1095824100.0   style_loss:  1217569300.0   content_loss:  117460.58\n",
            "best: iteration:  14 loss:  1064583800.0   style_loss:  1182857900.0   content_loss:  116634.6\n",
            "best: iteration:  15 loss:  1036401660.0   style_loss:  1151544600.0   content_loss:  116136.98\n",
            "best: iteration:  16 loss:  1010675300.0   style_loss:  1122959900.0   content_loss:  115874.09\n",
            "best: iteration:  17 loss:  986597100.0   style_loss:  1096206200.0   content_loss:  115706.42\n",
            "best: iteration:  18 loss:  963759200.0   style_loss:  1070830800.0   content_loss:  115512.68\n",
            "best: iteration:  19 loss:  941892100.0   style_loss:  1046534000.0   content_loss:  115290.15\n",
            "best: iteration:  20 loss:  920909300.0   style_loss:  1023219800.0   content_loss:  114994.7\n",
            "best: iteration:  21 loss:  900751900.0   style_loss:  1000822800.0   content_loss:  114653.58\n",
            "best: iteration:  22 loss:  881574900.0   style_loss:  979514940.0   content_loss:  114270.38\n",
            "best: iteration:  23 loss:  862946700.0   style_loss:  958817000.0   content_loss:  113865.37\n",
            "best: iteration:  24 loss:  844821800.0   style_loss:  938678400.0   content_loss:  113442.28\n",
            "best: iteration:  25 loss:  827462460.0   style_loss:  919390140.0   content_loss:  113023.16\n",
            "best: iteration:  26 loss:  810847040.0   style_loss:  900928600.0   content_loss:  112644.43\n",
            "best: iteration:  27 loss:  794938800.0   style_loss:  883252800.0   content_loss:  112329.62\n",
            "best: iteration:  28 loss:  779450200.0   style_loss:  866043300.0   content_loss:  112122.3\n",
            "best: iteration:  29 loss:  764505200.0   style_loss:  849437800.0   content_loss:  111977.84\n",
            "best: iteration:  30 loss:  749859000.0   style_loss:  833164300.0   content_loss:  111925.07\n",
            "best: iteration:  31 loss:  735308000.0   style_loss:  816996540.0   content_loss:  111952.77\n",
            "best: iteration:  32 loss:  721383400.0   style_loss:  801524700.0   content_loss:  112032.7\n",
            "best: iteration:  33 loss:  707659000.0   style_loss:  786275300.0   content_loss:  112189.695\n",
            "best: iteration:  34 loss:  694229800.0   style_loss:  771353900.0   content_loss:  112397.8\n",
            "best: iteration:  35 loss:  680795100.0   style_loss:  756426430.0   content_loss:  112643.53\n",
            "best: iteration:  36 loss:  667728450.0   style_loss:  741908030.0   content_loss:  112892.47\n",
            "best: iteration:  37 loss:  654727740.0   style_loss:  727462700.0   content_loss:  113136.35\n",
            "best: iteration:  38 loss:  641915970.0   style_loss:  713227400.0   content_loss:  113401.83\n",
            "best: iteration:  39 loss:  629336600.0   style_loss:  699250240.0   content_loss:  113661.875\n",
            "best: iteration:  40 loss:  616839550.0   style_loss:  685364600.0   content_loss:  113938.45\n",
            "best: iteration:  41 loss:  604404030.0   style_loss:  671547400.0   content_loss:  114225.42\n",
            "best: iteration:  42 loss:  592188600.0   style_loss:  657974660.0   content_loss:  114541.26\n",
            "best: iteration:  43 loss:  579683700.0   style_loss:  644080300.0   content_loss:  114843.57\n",
            "best: iteration:  44 loss:  567449660.0   style_loss:  630486850.0   content_loss:  115208.34\n",
            "best: iteration:  45 loss:  555318600.0   style_loss:  617007740.0   content_loss:  115536.05\n",
            "best: iteration:  46 loss:  543405900.0   style_loss:  603771460.0   content_loss:  115833.98\n",
            "best: iteration:  47 loss:  531331040.0   style_loss:  590355000.0   content_loss:  116187.055\n",
            "best: iteration:  48 loss:  519813500.0   style_loss:  577557600.0   content_loss:  116550.125\n",
            "best: iteration:  49 loss:  508102080.0   style_loss:  564544830.0   content_loss:  116921.07\n",
            "best: iteration:  50 loss:  496298300.0   style_loss:  551429500.0   content_loss:  117266.945\n",
            "best: iteration:  51 loss:  484763230.0   style_loss:  538612740.0   content_loss:  117602.4\n",
            "best: iteration:  52 loss:  473064930.0   style_loss:  525614660.0   content_loss:  117903.27\n",
            "best: iteration:  53 loss:  461621340.0   style_loss:  512899520.0   content_loss:  118215.4\n",
            "best: iteration:  54 loss:  449746180.0   style_loss:  499704860.0   content_loss:  118525.02\n",
            "best: iteration:  55 loss:  437964300.0   style_loss:  486613820.0   content_loss:  118833.0\n",
            "best: iteration:  56 loss:  426212260.0   style_loss:  473555970.0   content_loss:  119091.23\n",
            "best: iteration:  57 loss:  414513250.0   style_loss:  460557020.0   content_loss:  119345.91\n",
            "best: iteration:  58 loss:  402488320.0   style_loss:  447195940.0   content_loss:  119647.23\n",
            "best: iteration:  59 loss:  390462850.0   style_loss:  433834270.0   content_loss:  119961.18\n",
            "best: iteration:  60 loss:  378200030.0   style_loss:  420208900.0   content_loss:  120260.4\n",
            "best: iteration:  61 loss:  366439800.0   style_loss:  407141980.0   content_loss:  120466.13\n",
            "best: iteration:  62 loss:  354541900.0   style_loss:  393922050.0   content_loss:  120689.43\n",
            "best: iteration:  63 loss:  342766750.0   style_loss:  380838530.0   content_loss:  120898.76\n",
            "best: iteration:  64 loss:  330815520.0   style_loss:  367559330.0   content_loss:  121084.22\n",
            "best: iteration:  65 loss:  318778940.0   style_loss:  354185380.0   content_loss:  121215.13\n",
            "best: iteration:  66 loss:  306424060.0   style_loss:  340457730.0   content_loss:  121319.055\n",
            "best: iteration:  67 loss:  294561900.0   style_loss:  327277540.0   content_loss:  121425.66\n",
            "best: iteration:  68 loss:  282311000.0   style_loss:  313665400.0   content_loss:  121554.02\n",
            "best: iteration:  69 loss:  270069700.0   style_loss:  300063940.0   content_loss:  121710.17\n",
            "best: iteration:  70 loss:  258052600.0   style_loss:  286711600.0   content_loss:  121874.18\n",
            "best: iteration:  71 loss:  246234460.0   style_loss:  273580300.0   content_loss:  122063.42\n",
            "best: iteration:  72 loss:  234466960.0   style_loss:  260505250.0   content_loss:  122166.055\n",
            "best: iteration:  73 loss:  222919090.0   style_loss:  247674290.0   content_loss:  122177.55\n",
            "best: iteration:  74 loss:  211771460.0   style_loss:  235288060.0   content_loss:  122219.01\n",
            "best: iteration:  75 loss:  200528220.0   style_loss:  222795570.0   content_loss:  122301.625\n",
            "best: iteration:  76 loss:  190050510.0   style_loss:  211153650.0   content_loss:  122339.68\n",
            "best: iteration:  77 loss:  179568200.0   style_loss:  199506620.0   content_loss:  122431.82\n",
            "best: iteration:  78 loss:  169452020.0   style_loss:  188266400.0   content_loss:  122539.47\n",
            "best: iteration:  79 loss:  159773620.0   style_loss:  177512600.0   content_loss:  122565.52\n",
            "best: iteration:  80 loss:  150443360.0   style_loss:  167145660.0   content_loss:  122653.5\n",
            "best: iteration:  81 loss:  141252420.0   style_loss:  156933500.0   content_loss:  122712.25\n",
            "best: iteration:  82 loss:  132529530.0   style_loss:  147241400.0   content_loss:  122792.66\n",
            "best: iteration:  83 loss:  124383480.0   style_loss:  138190220.0   content_loss:  122831.49\n",
            "best: iteration:  84 loss:  116546310.0   style_loss:  129482250.0   content_loss:  122923.63\n",
            "best: iteration:  85 loss:  109021210.0   style_loss:  121121000.0   content_loss:  123040.01\n",
            "best: iteration:  86 loss:  101866520.0   style_loss:  113171336.0   content_loss:  123182.26\n",
            "best: iteration:  87 loss:  95214810.0   style_loss:  105780536.0   content_loss:  123244.2\n",
            "best: iteration:  88 loss:  88869630.0   style_loss:  98730340.0   content_loss:  123312.72\n",
            "best: iteration:  89 loss:  83033400.0   style_loss:  92245620.0   content_loss:  123426.375\n",
            "best: iteration:  90 loss:  77420110.0   style_loss:  86008620.0   content_loss:  123556.18\n",
            "best: iteration:  91 loss:  72431620.0   style_loss:  80465840.0   content_loss:  123582.87\n",
            "best: iteration:  92 loss:  67621580.0   style_loss:  75121350.0   content_loss:  123666.66\n",
            "best: iteration:  93 loss:  63155040.0   style_loss:  70158510.0   content_loss:  123819.375\n",
            "best: iteration:  94 loss:  59111536.0   style_loss:  65665710.0   content_loss:  123906.12\n",
            "best: iteration:  95 loss:  55376932.0   style_loss:  61516136.0   content_loss:  124080.38\n",
            "best: iteration:  96 loss:  51869820.0   style_loss:  57619336.0   content_loss:  124215.445\n",
            "best: iteration:  97 loss:  48678280.0   style_loss:  54073160.0   content_loss:  124356.25\n",
            "best: iteration:  98 loss:  45661910.0   style_loss:  50721616.0   content_loss:  124565.09\n",
            "best: iteration:  99 loss:  42924456.0   style_loss:  47679988.0   content_loss:  124720.02\n",
            "best: iteration:  100 loss:  40488376.0   style_loss:  44973212.0   content_loss:  124862.09\n",
            "best: iteration:  101 loss:  38191852.0   style_loss:  42421504.0   content_loss:  124998.51\n",
            "best: iteration:  102 loss:  36147130.0   style_loss:  40149570.0   content_loss:  125159.37\n",
            "best: iteration:  103 loss:  34309050.0   style_loss:  38107240.0   content_loss:  125318.92\n",
            "best: iteration:  104 loss:  32680756.0   style_loss:  36298012.0   content_loss:  125416.83\n",
            "best: iteration:  105 loss:  31093030.0   style_loss:  34533864.0   content_loss:  125539.15\n",
            "best: iteration:  106 loss:  29529674.0   style_loss:  32796792.0   content_loss:  125648.84\n",
            "best: iteration:  107 loss:  28122758.0   style_loss:  31233542.0   content_loss:  125720.98\n",
            "best: iteration:  108 loss:  26869306.0   style_loss:  29840812.0   content_loss:  125766.8\n",
            "best: iteration:  109 loss:  25703858.0   style_loss:  28545858.0   content_loss:  125851.87\n",
            "best: iteration:  110 loss:  24610708.0   style_loss:  27331244.0   content_loss:  125902.82\n",
            "best: iteration:  111 loss:  23580554.0   style_loss:  26186620.0   content_loss:  125965.0\n",
            "best: iteration:  112 loss:  22551220.0   style_loss:  25042908.0   content_loss:  126043.33\n",
            "best: iteration:  113 loss:  21629992.0   style_loss:  24019318.0   content_loss:  126065.02\n",
            "best: iteration:  114 loss:  20777956.0   style_loss:  23072604.0   content_loss:  126128.8\n",
            "best: iteration:  115 loss:  19991294.0   style_loss:  22198536.0   content_loss:  126136.03\n",
            "best: iteration:  116 loss:  19259216.0   style_loss:  21385110.0   content_loss:  126176.23\n",
            "best: iteration:  117 loss:  18572946.0   style_loss:  20622584.0   content_loss:  126202.125\n",
            "best: iteration:  118 loss:  17932110.0   style_loss:  19910546.0   content_loss:  126204.6\n",
            "best: iteration:  119 loss:  17331620.0   style_loss:  19243332.0   content_loss:  126222.72\n",
            "best: iteration:  120 loss:  16769956.0   style_loss:  18619258.0   content_loss:  126236.42\n",
            "best: iteration:  121 loss:  16230879.0   style_loss:  18020282.0   content_loss:  126269.08\n",
            "best: iteration:  122 loss:  15703585.0   style_loss:  17434394.0   content_loss:  126308.85\n",
            "best: iteration:  123 loss:  15214302.0   style_loss:  16890748.0   content_loss:  126287.58\n",
            "best: iteration:  124 loss:  14750598.0   style_loss:  16375524.0   content_loss:  126262.695\n",
            "best: iteration:  125 loss:  14310701.0   style_loss:  15886754.0   content_loss:  126241.25\n",
            "best: iteration:  126 loss:  13892500.0   style_loss:  15422085.0   content_loss:  126240.055\n",
            "best: iteration:  127 loss:  13496633.0   style_loss:  14982234.0   content_loss:  126224.35\n",
            "best: iteration:  128 loss:  13112610.0   style_loss:  14555546.0   content_loss:  126187.375\n",
            "best: iteration:  129 loss:  12738318.0   style_loss:  14139670.0   content_loss:  126153.445\n",
            "best: iteration:  130 loss:  12395523.0   style_loss:  13758794.0   content_loss:  126093.63\n",
            "best: iteration:  131 loss:  12066501.0   style_loss:  13393219.0   content_loss:  126052.72\n",
            "best: iteration:  132 loss:  11745228.0   style_loss:  13036248.0   content_loss:  126045.26\n",
            "best: iteration:  133 loss:  11452563.0   style_loss:  12711069.0   content_loss:  126012.445\n",
            "best: iteration:  134 loss:  11174034.0   style_loss:  12401591.0   content_loss:  126005.63\n",
            "best: iteration:  135 loss:  10907773.0   style_loss:  12105747.0   content_loss:  126012.07\n",
            "best: iteration:  136 loss:  10651273.0   style_loss:  11820749.0   content_loss:  125999.98\n",
            "best: iteration:  137 loss:  10403956.0   style_loss:  11545954.0   content_loss:  125984.45\n",
            "best: iteration:  138 loss:  10172279.0   style_loss:  11288536.0   content_loss:  125970.88\n",
            "best: iteration:  139 loss:  9957486.0   style_loss:  11049876.0   content_loss:  125967.75\n",
            "best: iteration:  140 loss:  9750803.0   style_loss:  10820230.0   content_loss:  125964.78\n",
            "best: iteration:  141 loss:  9542715.0   style_loss:  10589020.0   content_loss:  125971.24\n",
            "best: iteration:  142 loss:  9344845.0   style_loss:  10369164.0   content_loss:  125969.1\n",
            "best: iteration:  143 loss:  9154630.0   style_loss:  10157814.0   content_loss:  125976.76\n",
            "best: iteration:  144 loss:  8972895.0   style_loss:  9955885.0   content_loss:  125985.45\n",
            "best: iteration:  145 loss:  8802232.0   style_loss:  9766258.0   content_loss:  125995.445\n",
            "best: iteration:  146 loss:  8643168.0   style_loss:  9589518.0   content_loss:  126013.34\n",
            "best: iteration:  147 loss:  8486495.0   style_loss:  9415434.0   content_loss:  126046.5\n",
            "best: iteration:  148 loss:  8334618.0   style_loss:  9246679.0   content_loss:  126068.73\n",
            "best: iteration:  149 loss:  8186194.5   style_loss:  9081761.0   content_loss:  126099.73\n",
            "best: iteration:  150 loss:  8045430.5   style_loss:  8925352.0   content_loss:  126129.695\n",
            "best: iteration:  151 loss:  7912753.0   style_loss:  8777931.0   content_loss:  126155.43\n",
            "best: iteration:  152 loss:  7783213.5   style_loss:  8633996.0   content_loss:  126175.25\n",
            "best: iteration:  153 loss:  7658855.5   style_loss:  8495819.0   content_loss:  126185.73\n",
            "best: iteration:  154 loss:  7537904.0   style_loss:  8361427.0   content_loss:  126194.16\n",
            "best: iteration:  155 loss:  7420943.5   style_loss:  8231471.0   content_loss:  126199.6\n",
            "best: iteration:  156 loss:  7305537.0   style_loss:  8103241.0   content_loss:  126206.37\n",
            "best: iteration:  157 loss:  7195313.0   style_loss:  7980769.5   content_loss:  126202.875\n",
            "best: iteration:  158 loss:  7096260.5   style_loss:  7870712.0   content_loss:  126199.85\n",
            "best: iteration:  159 loss:  7008902.0   style_loss:  7773645.0   content_loss:  126213.38\n",
            "best: iteration:  160 loss:  6924216.5   style_loss:  7679547.0   content_loss:  126240.09\n",
            "best: iteration:  161 loss:  6839077.0   style_loss:  7584945.0   content_loss:  126271.55\n",
            "best: iteration:  162 loss:  6755244.0   style_loss:  7491793.5   content_loss:  126302.22\n",
            "best: iteration:  163 loss:  6672266.5   style_loss:  7399593.5   content_loss:  126319.02\n",
            "best: iteration:  164 loss:  6589417.0   style_loss:  7307537.5   content_loss:  126334.6\n",
            "best: iteration:  165 loss:  6512798.5   style_loss:  7222406.0   content_loss:  126335.68\n",
            "best: iteration:  166 loss:  6440629.5   style_loss:  7142216.5   content_loss:  126345.27\n",
            "best: iteration:  167 loss:  6370925.0   style_loss:  7064765.0   content_loss:  126364.41\n",
            "best: iteration:  168 loss:  6302615.5   style_loss:  6988863.0   content_loss:  126389.91\n",
            "best: iteration:  169 loss:  6235510.5   style_loss:  6914298.5   content_loss:  126419.84\n",
            "best: iteration:  170 loss:  6167836.5   style_loss:  6839102.0   content_loss:  126448.945\n",
            "best: iteration:  171 loss:  6102551.5   style_loss:  6766561.0   content_loss:  126471.18\n",
            "best: iteration:  172 loss:  6038135.5   style_loss:  6694984.0   content_loss:  126500.87\n",
            "best: iteration:  173 loss:  5976830.0   style_loss:  6626864.0   content_loss:  126527.75\n",
            "best: iteration:  174 loss:  5921169.5   style_loss:  6565015.5   content_loss:  126553.03\n",
            "best: iteration:  175 loss:  5865971.0   style_loss:  6503681.0   content_loss:  126585.1\n",
            "best: iteration:  176 loss:  5809661.5   style_loss:  6441112.0   content_loss:  126611.13\n",
            "best: iteration:  177 loss:  5753252.5   style_loss:  6378432.0   content_loss:  126639.26\n",
            "best: iteration:  178 loss:  5697835.5   style_loss:  6316854.5   content_loss:  126666.695\n",
            "best: iteration:  179 loss:  5644814.0   style_loss:  6257938.0   content_loss:  126701.08\n",
            "best: iteration:  180 loss:  5594594.5   style_loss:  6202137.5   content_loss:  126708.57\n",
            "best: iteration:  181 loss:  5545050.5   style_loss:  6147089.0   content_loss:  126712.3\n",
            "best: iteration:  182 loss:  5495427.0   style_loss:  6091950.0   content_loss:  126720.65\n",
            "best: iteration:  183 loss:  5446959.0   style_loss:  6038095.0   content_loss:  126733.23\n",
            "best: iteration:  184 loss:  5400924.0   style_loss:  5986944.5   content_loss:  126746.5\n",
            "best: iteration:  185 loss:  5353632.0   style_loss:  5934395.0   content_loss:  126768.13\n",
            "best: iteration:  186 loss:  5307757.5   style_loss:  5883420.5   content_loss:  126786.95\n",
            "best: iteration:  187 loss:  5258323.0   style_loss:  5828490.0   content_loss:  126818.32\n",
            "best: iteration:  188 loss:  5211374.5   style_loss:  5776323.0   content_loss:  126841.4\n",
            "best: iteration:  189 loss:  5165950.5   style_loss:  5725849.5   content_loss:  126861.305\n",
            "best: iteration:  190 loss:  5124640.0   style_loss:  5679948.5   content_loss:  126861.34\n",
            "best: iteration:  191 loss:  5083169.5   style_loss:  5633868.5   content_loss:  126872.51\n",
            "best: iteration:  192 loss:  5044385.0   style_loss:  5590773.0   content_loss:  126892.63\n",
            "best: iteration:  193 loss:  5003825.0   style_loss:  5545704.0   content_loss:  126918.0\n",
            "best: iteration:  194 loss:  4965127.0   style_loss:  5502704.0   content_loss:  126938.17\n",
            "best: iteration:  195 loss:  4926900.0   style_loss:  5460227.5   content_loss:  126955.72\n",
            "best: iteration:  196 loss:  4890620.5   style_loss:  5419915.0   content_loss:  126965.48\n",
            "best: iteration:  197 loss:  4852966.0   style_loss:  5378075.5   content_loss:  126981.87\n",
            "best: iteration:  198 loss:  4816866.0   style_loss:  5337963.0   content_loss:  126990.125\n",
            "best: iteration:  199 loss:  4782248.5   style_loss:  5299498.0   content_loss:  127003.53\n",
            "best: iteration:  0 loss:  186409550.0   style_loss:  207120160.0   content_loss:  14007.915\n",
            "best: iteration:  1 loss:  151067170.0   style_loss:  167849260.0   content_loss:  28373.783\n",
            "best: iteration:  2 loss:  131615580.0   style_loss:  146235280.0   content_loss:  38296.074\n",
            "best: iteration:  3 loss:  120662950.0   style_loss:  134065130.0   content_loss:  43388.145\n",
            "best: iteration:  4 loss:  113156664.0   style_loss:  125724600.0   content_loss:  45201.434\n",
            "best: iteration:  5 loss:  106239470.0   style_loss:  118038800.0   content_loss:  45509.902\n",
            "best: iteration:  6 loss:  99875520.0   style_loss:  110967750.0   content_loss:  45404.92\n",
            "best: iteration:  7 loss:  94144880.0   style_loss:  104600400.0   content_loss:  45209.465\n",
            "best: iteration:  8 loss:  88856890.0   style_loss:  98724880.0   content_loss:  44986.945\n",
            "best: iteration:  9 loss:  84005300.0   style_loss:  93334264.0   content_loss:  44676.63\n",
            "best: iteration:  10 loss:  79549220.0   style_loss:  88383096.0   content_loss:  44315.332\n",
            "best: iteration:  11 loss:  75422110.0   style_loss:  83797470.0   content_loss:  43993.89\n",
            "best: iteration:  12 loss:  71621860.0   style_loss:  79574960.0   content_loss:  43806.11\n",
            "best: iteration:  13 loss:  68102040.0   style_loss:  75664070.0   content_loss:  43764.395\n",
            "best: iteration:  14 loss:  64879090.0   style_loss:  72083000.0   content_loss:  43869.83\n",
            "best: iteration:  15 loss:  61797096.0   style_loss:  68658536.0   content_loss:  44097.43\n",
            "best: iteration:  16 loss:  58789572.0   style_loss:  65316816.0   content_loss:  44353.73\n",
            "best: iteration:  17 loss:  55861470.0   style_loss:  62063344.0   content_loss:  44658.016\n",
            "best: iteration:  18 loss:  53024730.0   style_loss:  58911372.0   content_loss:  44963.85\n",
            "best: iteration:  19 loss:  50230668.0   style_loss:  55806828.0   content_loss:  45239.81\n",
            "best: iteration:  20 loss:  47419708.0   style_loss:  52683510.0   content_loss:  45517.664\n",
            "best: iteration:  21 loss:  44648830.0   style_loss:  49604724.0   content_loss:  45796.61\n",
            "best: iteration:  22 loss:  41909044.0   style_loss:  46560492.0   content_loss:  46037.48\n",
            "best: iteration:  23 loss:  39176812.0   style_loss:  43524650.0   content_loss:  46274.316\n",
            "best: iteration:  24 loss:  36475756.0   style_loss:  40523452.0   content_loss:  46505.02\n",
            "best: iteration:  25 loss:  33804310.0   style_loss:  37555156.0   content_loss:  46724.16\n",
            "best: iteration:  26 loss:  31224098.0   style_loss:  34688230.0   content_loss:  46903.77\n",
            "best: iteration:  27 loss:  28700912.0   style_loss:  31884672.0   content_loss:  47072.33\n",
            "best: iteration:  28 loss:  26200948.0   style_loss:  29106920.0   content_loss:  47207.99\n",
            "best: iteration:  29 loss:  23765646.0   style_loss:  26401018.0   content_loss:  47305.168\n",
            "best: iteration:  30 loss:  21435108.0   style_loss:  23811524.0   content_loss:  47360.316\n",
            "best: iteration:  31 loss:  19224762.0   style_loss:  21355580.0   content_loss:  47426.02\n",
            "best: iteration:  32 loss:  17080558.0   style_loss:  18973120.0   content_loss:  47500.38\n",
            "best: iteration:  33 loss:  15078443.0   style_loss:  16748542.0   content_loss:  47548.836\n",
            "best: iteration:  34 loss:  13239031.0   style_loss:  14704748.0   content_loss:  47585.715\n",
            "best: iteration:  35 loss:  11600673.0   style_loss:  12884348.0   content_loss:  47601.66\n",
            "best: iteration:  36 loss:  10098501.0   style_loss:  11215256.0   content_loss:  47706.023\n",
            "best: iteration:  37 loss:  8736812.0   style_loss:  9702251.0   content_loss:  47864.25\n",
            "best: iteration:  38 loss:  7516033.5   style_loss:  8345812.0   content_loss:  48024.39\n",
            "best: iteration:  39 loss:  6454749.5   style_loss:  7166592.0   content_loss:  48169.06\n",
            "best: iteration:  40 loss:  5535140.0   style_loss:  6144787.0   content_loss:  48319.59\n",
            "best: iteration:  41 loss:  4763105.5   style_loss:  5286950.5   content_loss:  48497.99\n",
            "best: iteration:  42 loss:  4115648.2   style_loss:  4567535.0   content_loss:  48671.363\n",
            "best: iteration:  43 loss:  3581930.5   style_loss:  3974495.0   content_loss:  48849.223\n",
            "best: iteration:  44 loss:  3133375.2   style_loss:  3476078.8   content_loss:  49043.56\n",
            "best: iteration:  45 loss:  2763541.2   style_loss:  3065134.5   content_loss:  49200.14\n",
            "best: iteration:  46 loss:  2464268.8   style_loss:  2732593.5   content_loss:  49347.64\n",
            "best: iteration:  47 loss:  2224850.0   style_loss:  2466553.5   content_loss:  49521.387\n",
            "best: iteration:  48 loss:  2032466.8   style_loss:  2252774.5   content_loss:  49700.4\n",
            "best: iteration:  49 loss:  1876815.6   style_loss:  2079810.2   content_loss:  49865.477\n",
            "best: iteration:  50 loss:  1751532.4   style_loss:  1940589.9   content_loss:  50014.75\n",
            "best: iteration:  51 loss:  1651456.6   style_loss:  1829382.8   content_loss:  50120.863\n",
            "best: iteration:  52 loss:  1566017.1   style_loss:  1734443.1   content_loss:  50183.277\n",
            "best: iteration:  53 loss:  1488507.6   style_loss:  1648315.1   content_loss:  50240.41\n",
            "best: iteration:  54 loss:  1416874.1   style_loss:  1568715.5   content_loss:  50302.027\n",
            "best: iteration:  55 loss:  1350569.4   style_loss:  1495036.9   content_loss:  50363.33\n",
            "best: iteration:  56 loss:  1287569.0   style_loss:  1425030.6   content_loss:  50415.387\n",
            "best: iteration:  57 loss:  1225870.5   style_loss:  1356471.8   content_loss:  50459.51\n",
            "best: iteration:  58 loss:  1164558.0   style_loss:  1288340.6   content_loss:  50514.64\n",
            "best: iteration:  59 loss:  1103904.6   style_loss:  1220941.0   content_loss:  50577.64\n",
            "best: iteration:  60 loss:  1044886.94   style_loss:  1155359.2   content_loss:  50637.523\n",
            "best: iteration:  61 loss:  987209.1   style_loss:  1091266.2   content_loss:  50694.95\n",
            "best: iteration:  62 loss:  931170.8   style_loss:  1028994.9   content_loss:  50753.586\n",
            "best: iteration:  63 loss:  876927.94   style_loss:  968718.5   content_loss:  50812.934\n",
            "best: iteration:  64 loss:  824629.44   style_loss:  910603.1   content_loss:  50867.176\n",
            "best: iteration:  65 loss:  774411.0   style_loss:  854799.94   content_loss:  50911.516\n",
            "best: iteration:  66 loss:  726805.2   style_loss:  801900.6   content_loss:  50946.203\n",
            "best: iteration:  67 loss:  681959.1   style_loss:  752068.2   content_loss:  50978.086\n",
            "best: iteration:  68 loss:  640030.25   style_loss:  705476.9   content_loss:  51010.477\n",
            "best: iteration:  69 loss:  600889.3   style_loss:  661984.2   content_loss:  51036.34\n",
            "best: iteration:  70 loss:  564555.06   style_loss:  621610.1   content_loss:  51059.777\n",
            "best: iteration:  71 loss:  531110.5   style_loss:  584446.56   content_loss:  51086.176\n",
            "best: iteration:  72 loss:  500559.4   style_loss:  550497.4   content_loss:  51117.902\n",
            "best: iteration:  73 loss:  472726.84   style_loss:  519568.53   content_loss:  51152.227\n",
            "best: iteration:  74 loss:  447468.84   style_loss:  491500.3   content_loss:  51185.566\n",
            "best: iteration:  75 loss:  424675.22   style_loss:  466170.3   content_loss:  51219.5\n",
            "best: iteration:  76 loss:  404170.12   style_loss:  443383.0   content_loss:  51254.75\n",
            "best: iteration:  77 loss:  385822.25   style_loss:  422992.62   content_loss:  51289.06\n",
            "best: iteration:  78 loss:  369396.28   style_loss:  404738.1   content_loss:  51319.89\n",
            "best: iteration:  79 loss:  354658.84   style_loss:  388359.78   content_loss:  51350.63\n",
            "best: iteration:  80 loss:  341408.06   style_loss:  373632.97   content_loss:  51384.184\n",
            "best: iteration:  81 loss:  329518.12   style_loss:  360418.0   content_loss:  51419.684\n",
            "best: iteration:  82 loss:  318812.78   style_loss:  348519.3   content_loss:  51454.12\n",
            "best: iteration:  83 loss:  309141.22   style_loss:  337769.22   content_loss:  51489.465\n",
            "best: iteration:  84 loss:  300364.84   style_loss:  328013.5   content_loss:  51526.824\n",
            "best: iteration:  85 loss:  292373.34   style_loss:  319129.75   content_loss:  51565.625\n",
            "best: iteration:  86 loss:  285066.22   style_loss:  311006.6   content_loss:  51602.547\n",
            "best: iteration:  87 loss:  278345.78   style_loss:  303535.66   content_loss:  51636.99\n",
            "best: iteration:  88 loss:  272100.97   style_loss:  296592.94   content_loss:  51673.324\n",
            "best: iteration:  89 loss:  266249.8   style_loss:  290087.25   content_loss:  51713.35\n",
            "best: iteration:  90 loss:  260746.03   style_loss:  283967.47   content_loss:  51753.1\n",
            "best: iteration:  91 loss:  255542.78   style_loss:  278181.94   content_loss:  51790.484\n",
            "best: iteration:  92 loss:  250607.97   style_loss:  272694.75   content_loss:  51826.973\n",
            "best: iteration:  93 loss:  245923.36   style_loss:  267485.38   content_loss:  51865.01\n",
            "best: iteration:  94 loss:  241463.36   style_loss:  262525.38   content_loss:  51905.273\n",
            "best: iteration:  95 loss:  237217.34   style_loss:  257803.16   content_loss:  51945.08\n",
            "best: iteration:  96 loss:  233170.36   style_loss:  253302.44   content_loss:  51981.75\n",
            "best: iteration:  97 loss:  229296.45   style_loss:  248994.48   content_loss:  52014.223\n",
            "best: iteration:  98 loss:  225575.14   style_loss:  244856.36   content_loss:  52044.254\n",
            "best: iteration:  99 loss:  222009.3   style_loss:  240891.12   content_loss:  52072.99\n",
            "best: iteration:  100 loss:  218580.4   style_loss:  237078.1   content_loss:  52101.215\n",
            "best: iteration:  101 loss:  215287.4   style_loss:  233416.19   content_loss:  52128.55\n",
            "best: iteration:  102 loss:  212120.81   style_loss:  229894.69   content_loss:  52155.746\n",
            "best: iteration:  103 loss:  209077.23   style_loss:  226510.0   content_loss:  52182.65\n",
            "best: iteration:  104 loss:  206140.5   style_loss:  223244.14   content_loss:  52207.785\n",
            "best: iteration:  105 loss:  203315.78   style_loss:  220102.97   content_loss:  52231.125\n",
            "best: iteration:  106 loss:  200597.89   style_loss:  217080.56   content_loss:  52254.004\n",
            "best: iteration:  107 loss:  197981.22   style_loss:  214170.62   content_loss:  52276.33\n",
            "best: iteration:  108 loss:  195463.44   style_loss:  211370.75   content_loss:  52297.684\n",
            "best: iteration:  109 loss:  193043.44   style_loss:  208679.62   content_loss:  52317.91\n",
            "best: iteration:  110 loss:  190714.03   style_loss:  206089.3   content_loss:  52336.51\n",
            "best: iteration:  111 loss:  188468.12   style_loss:  203591.92   content_loss:  52354.016\n",
            "best: iteration:  112 loss:  186306.06   style_loss:  201187.72   content_loss:  52371.047\n",
            "best: iteration:  113 loss:  184222.11   style_loss:  198870.4   content_loss:  52387.496\n",
            "best: iteration:  114 loss:  182206.62   style_loss:  196629.22   content_loss:  52403.164\n",
            "best: iteration:  115 loss:  180258.67   style_loss:  194463.16   content_loss:  52418.348\n",
            "best: iteration:  116 loss:  178375.39   style_loss:  192368.95   content_loss:  52433.434\n",
            "best: iteration:  117 loss:  176553.22   style_loss:  190342.7   content_loss:  52448.01\n",
            "best: iteration:  118 loss:  174786.19   style_loss:  188377.78   content_loss:  52461.777\n",
            "best: iteration:  119 loss:  173070.55   style_loss:  186470.11   content_loss:  52474.473\n",
            "best: iteration:  120 loss:  171403.98   style_loss:  184617.08   content_loss:  52486.324\n",
            "best: iteration:  121 loss:  169784.33   style_loss:  182816.2   content_loss:  52497.434\n",
            "best: iteration:  122 loss:  168210.45   style_loss:  181066.28   content_loss:  52507.94\n",
            "best: iteration:  123 loss:  166680.6   style_loss:  179365.28   content_loss:  52518.363\n",
            "best: iteration:  124 loss:  165191.08   style_loss:  177709.06   content_loss:  52529.19\n",
            "best: iteration:  125 loss:  163736.67   style_loss:  176091.78   content_loss:  52540.59\n",
            "best: iteration:  126 loss:  162315.95   style_loss:  174511.95   content_loss:  52552.26\n",
            "best: iteration:  127 loss:  160929.31   style_loss:  172969.95   content_loss:  52563.715\n",
            "best: iteration:  128 loss:  159576.2   style_loss:  171465.31   content_loss:  52574.184\n",
            "best: iteration:  129 loss:  158254.77   style_loss:  169995.9   content_loss:  52584.3\n",
            "best: iteration:  130 loss:  156962.88   style_loss:  168559.44   content_loss:  52594.1\n",
            "best: iteration:  131 loss:  155701.52   style_loss:  167156.84   content_loss:  52603.598\n",
            "best: iteration:  132 loss:  154468.4   style_loss:  165785.69   content_loss:  52613.004\n",
            "best: iteration:  133 loss:  153263.47   style_loss:  164445.75   content_loss:  52622.777\n",
            "best: iteration:  134 loss:  152083.81   style_loss:  163133.9   content_loss:  52632.91\n",
            "best: iteration:  135 loss:  150928.31   style_loss:  161848.9   content_loss:  52642.95\n",
            "best: iteration:  136 loss:  149797.17   style_loss:  160591.03   content_loss:  52652.703\n",
            "best: iteration:  137 loss:  148688.75   style_loss:  159358.36   content_loss:  52662.152\n",
            "best: iteration:  138 loss:  147601.62   style_loss:  158149.48   content_loss:  52670.965\n",
            "best: iteration:  139 loss:  146533.9   style_loss:  156962.23   content_loss:  52679.086\n",
            "best: iteration:  140 loss:  145486.11   style_loss:  155797.16   content_loss:  52686.74\n",
            "best: iteration:  141 loss:  144457.94   style_loss:  154653.88   content_loss:  52694.375\n",
            "best: iteration:  142 loss:  143449.0   style_loss:  153532.03   content_loss:  52701.89\n",
            "best: iteration:  143 loss:  142459.67   style_loss:  152431.92   content_loss:  52709.473\n",
            "best: iteration:  144 loss:  141485.98   style_loss:  151349.2   content_loss:  52717.01\n",
            "best: iteration:  145 loss:  140528.86   style_loss:  150284.92   content_loss:  52724.49\n",
            "best: iteration:  146 loss:  139587.11   style_loss:  149237.69   content_loss:  52731.902\n",
            "best: iteration:  147 loss:  138660.12   style_loss:  148206.92   content_loss:  52739.023\n",
            "best: iteration:  148 loss:  137747.9   style_loss:  147192.58   content_loss:  52745.953\n",
            "best: iteration:  149 loss:  136850.53   style_loss:  146194.67   content_loss:  52753.285\n",
            "best: iteration:  150 loss:  135967.31   style_loss:  145212.44   content_loss:  52761.25\n",
            "best: iteration:  151 loss:  135097.9   style_loss:  144245.53   content_loss:  52769.523\n",
            "best: iteration:  152 loss:  134242.75   style_loss:  143294.4   content_loss:  52777.816\n",
            "best: iteration:  153 loss:  133401.34   style_loss:  142358.61   content_loss:  52786.0\n",
            "best: iteration:  154 loss:  132571.22   style_loss:  141435.38   content_loss:  52793.902\n",
            "best: iteration:  155 loss:  131753.39   style_loss:  140525.78   content_loss:  52801.81\n",
            "best: iteration:  156 loss:  130948.086   style_loss:  139630.14   content_loss:  52809.63\n",
            "best: iteration:  157 loss:  130154.85   style_loss:  138747.92   content_loss:  52817.4\n",
            "best: iteration:  158 loss:  129373.42   style_loss:  137878.8   content_loss:  52825.066\n",
            "best: iteration:  159 loss:  128603.82   style_loss:  137022.81   content_loss:  52832.81\n",
            "best: iteration:  160 loss:  127845.65   style_loss:  136179.56   content_loss:  52840.66\n",
            "best: iteration:  161 loss:  127098.33   style_loss:  135348.3   content_loss:  52848.69\n",
            "best: iteration:  162 loss:  126361.06   style_loss:  134528.22   content_loss:  52856.547\n",
            "best: iteration:  163 loss:  125634.2   style_loss:  133719.72   content_loss:  52864.44\n",
            "best: iteration:  164 loss:  124917.06   style_loss:  132922.03   content_loss:  52872.465\n",
            "best: iteration:  165 loss:  124209.31   style_loss:  132134.77   content_loss:  52880.2\n",
            "best: iteration:  166 loss:  123510.914   style_loss:  131357.98   content_loss:  52887.31\n",
            "best: iteration:  167 loss:  122821.766   style_loss:  130591.45   content_loss:  52894.496\n",
            "best: iteration:  168 loss:  122141.47   style_loss:  129834.75   content_loss:  52901.965\n",
            "best: iteration:  169 loss:  121470.39   style_loss:  129088.28   content_loss:  52909.46\n",
            "best: iteration:  170 loss:  120808.016   style_loss:  128351.484   content_loss:  52916.7\n",
            "best: iteration:  171 loss:  120153.98   style_loss:  127623.94   content_loss:  52924.33\n",
            "best: iteration:  172 loss:  119508.84   style_loss:  126906.28   content_loss:  52931.934\n",
            "best: iteration:  173 loss:  118871.47   style_loss:  126197.3   content_loss:  52939.137\n",
            "best: iteration:  174 loss:  118241.89   style_loss:  125496.97   content_loss:  52946.234\n",
            "best: iteration:  175 loss:  117620.695   style_loss:  124805.95   content_loss:  52953.402\n",
            "best: iteration:  176 loss:  117007.984   style_loss:  124124.37   content_loss:  52960.535\n",
            "best: iteration:  177 loss:  116402.84   style_loss:  123451.195   content_loss:  52967.637\n",
            "best: iteration:  178 loss:  115804.56   style_loss:  122785.664   content_loss:  52974.684\n",
            "best: iteration:  179 loss:  115214.29   style_loss:  122129.01   content_loss:  52981.88\n",
            "best: iteration:  180 loss:  114630.25   style_loss:  121479.31   content_loss:  52988.79\n",
            "best: iteration:  181 loss:  114052.97   style_loss:  120837.16   content_loss:  52995.312\n",
            "best: iteration:  182 loss:  113482.34   style_loss:  120202.42   content_loss:  53001.535\n",
            "best: iteration:  183 loss:  112918.24   style_loss:  119574.95   content_loss:  53007.84\n",
            "best: iteration:  184 loss:  112360.75   style_loss:  118954.8   content_loss:  53014.363\n",
            "best: iteration:  185 loss:  111809.08   style_loss:  118341.06   content_loss:  53021.234\n",
            "best: iteration:  186 loss:  111264.44   style_loss:  117735.14   content_loss:  53028.047\n",
            "best: iteration:  187 loss:  110725.586   style_loss:  117135.69   content_loss:  53034.723\n",
            "best: iteration:  188 loss:  110192.4   style_loss:  116542.54   content_loss:  53041.152\n",
            "best: iteration:  189 loss:  109665.516   style_loss:  115956.39   content_loss:  53047.598\n",
            "best: iteration:  190 loss:  109144.86   style_loss:  115377.17   content_loss:  53054.074\n",
            "best: iteration:  191 loss:  108629.65   style_loss:  114804.03   content_loss:  53060.36\n",
            "best: iteration:  192 loss:  108120.63   style_loss:  114237.76   content_loss:  53066.625\n",
            "best: iteration:  193 loss:  107616.75   style_loss:  113677.17   content_loss:  53072.984\n",
            "best: iteration:  194 loss:  107118.31   style_loss:  113122.67   content_loss:  53079.17\n",
            "best: iteration:  195 loss:  106625.016   style_loss:  112573.89   content_loss:  53085.184\n",
            "best: iteration:  196 loss:  106138.016   style_loss:  112032.11   content_loss:  53091.227\n",
            "best: iteration:  197 loss:  105656.195   style_loss:  111496.086   content_loss:  53097.215\n",
            "best: iteration:  198 loss:  105179.11   style_loss:  110965.32   content_loss:  53103.17\n",
            "best: iteration:  199 loss:  104706.375   style_loss:  110439.375   content_loss:  53109.336\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eZA6akDbdbQu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "best, best_loss, img = run_style_transfer('/content/pickup2.png', '/content/sketch.jpg', num_iterations = 200, content_weight = 0.1, style_weight = 0.9)\n",
        "img = Image.fromarray(img)\n",
        "img.save('/content/pickupsketch2.jpeg')\n",
        "\n",
        "best, best_loss, img = run_style_transfer('/content/truck2.png', '/content/sketch.jpg', num_iterations = 200, content_weight = 0.1, style_weight = 0.9)\n",
        "img = Image.fromarray(img)\n",
        "img.save('/content/trucksketch2.jpeg')\n",
        "\n",
        "best, best_loss, img = run_style_transfer('/content/pickup2.png', '/content/lisafrank.jpg', num_iterations = 200, content_weight = 0.1, style_weight = 0.9)\n",
        "img = Image.fromarray(img)\n",
        "img.save('/content/pickuplisafrank2.jpeg')\n",
        "\n",
        "best, best_loss, img = run_style_transfer('/content/pickup2.png', '/content/pop_art.jpeg', num_iterations = 200, content_weight = 0.1, style_weight = 0.9)\n",
        "img = Image.fromarray(img)\n",
        "img.save('/content/pickuppopart2.jpeg')\n",
        "\n",
        "best, best_loss, img = run_style_transfer('/content/pickup2.png', '/content/starry_night.jpeg', num_iterations = 200, content_weight = 0.1, style_weight = 0.9)\n",
        "img = Image.fromarray(img)\n",
        "img.save('/content/pickupstarrynight2.jpeg')\n",
        "\n",
        "best, best_loss, img = run_style_transfer('/content/pickup2.png', '/content/linedrawing.png', num_iterations = 200, content_weight = 0.1, style_weight = 0.9)\n",
        "img = Image.fromarray(img)\n",
        "img.save('/content/pickuplinedrawing2.jpeg')\n",
        "\n",
        "best, best_loss, img = run_style_transfer('/content/pickup2.png', '/content/pencil.jpg', num_iterations = 200, content_weight = 0.1, style_weight = 0.9)\n",
        "img = Image.fromarray(img)\n",
        "img.save('/content/pickuppencil2.jpeg')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RNDR19ptdo7P",
        "colab_type": "code",
        "outputId": "e9202d47-a9e3-4b9d-f7be-6874b04774e7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 16680
        }
      },
      "source": [
        "\n",
        "best, best_loss, img = run_style_transfer('/content/truck2.png', '/content/lisafrank.jpg', num_iterations = 200, content_weight = 0.1, style_weight = 0.9)\n",
        "img = Image.fromarray(img)\n",
        "img.save('/content/trucklisafrank2.jpeg')\n",
        "\n",
        "best, best_loss, img = run_style_transfer('/content/truck2.png', '/content/pop_art.jpeg', num_iterations = 200, content_weight = 0.1, style_weight = 0.9)\n",
        "img = Image.fromarray(img)\n",
        "img.save('/content/truckpopart2.jpeg')\n",
        "\n",
        "best, best_loss, img = run_style_transfer('/content/truck2.png', '/content/starry_night.jpeg', num_iterations = 200, content_weight = 0.1, style_weight = 0.9)\n",
        "img = Image.fromarray(img)\n",
        "img.save('/content/truckstarrynight2.jpeg')\n",
        "\n",
        "best, best_loss, img = run_style_transfer('/content/truck2.png', '/content/linedrawing.png', num_iterations = 200, content_weight = 0.1, style_weight = 0.9)\n",
        "img = Image.fromarray(img)\n",
        "img.save('/content/trucklinedrawing2.jpeg')\n",
        "\n",
        "best, best_loss, img = run_style_transfer('/content/truck2.png', '/content/pencil.jpg', num_iterations = 200, content_weight = 0.1, style_weight = 0.9)\n",
        "img = Image.fromarray(img)\n",
        "img.save('/content/truckpencil2.jpeg')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "best: iteration:  0 loss:  1967006800.0   style_loss:  2185561000.0   content_loss:  19133.48\n",
            "best: iteration:  1 loss:  1093010700.0   style_loss:  1214450300.0   content_loss:  54681.74\n",
            "best: iteration:  2 loss:  401212930.0   style_loss:  445780350.0   content_loss:  106296.47\n",
            "best: iteration:  6 loss:  313963040.0   style_loss:  348830140.0   content_loss:  159158.75\n",
            "best: iteration:  7 loss:  156198060.0   style_loss:  173537870.0   content_loss:  139875.06\n",
            "best: iteration:  8 loss:  152772200.0   style_loss:  169733000.0   content_loss:  124933.17\n",
            "best: iteration:  13 loss:  124444860.0   style_loss:  138254770.0   content_loss:  155723.31\n",
            "best: iteration:  17 loss:  113405370.0   style_loss:  125986580.0   content_loss:  174541.72\n",
            "best: iteration:  18 loss:  84079920.0   style_loss:  93403720.0   content_loss:  165781.33\n",
            "best: iteration:  19 loss:  72934040.0   style_loss:  81020360.0   content_loss:  157221.89\n",
            "best: iteration:  23 loss:  69114790.0   style_loss:  76777290.0   content_loss:  152357.53\n",
            "best: iteration:  24 loss:  60100376.0   style_loss:  66760664.0   content_loss:  157804.39\n",
            "best: iteration:  25 loss:  56964370.0   style_loss:  63275564.0   content_loss:  163598.95\n",
            "best: iteration:  28 loss:  55209764.0   style_loss:  61325416.0   content_loss:  168901.34\n",
            "best: iteration:  29 loss:  48454496.0   style_loss:  53819892.0   content_loss:  165960.45\n",
            "best: iteration:  30 loss:  43959268.0   style_loss:  48825588.0   content_loss:  162414.89\n",
            "best: iteration:  31 loss:  43031096.0   style_loss:  47794596.0   content_loss:  159581.25\n",
            "best: iteration:  33 loss:  42339960.0   style_loss:  47026716.0   content_loss:  159150.52\n",
            "best: iteration:  34 loss:  39751416.0   style_loss:  44150270.0   content_loss:  161710.12\n",
            "best: iteration:  35 loss:  37199884.0   style_loss:  41314828.0   content_loss:  165399.61\n",
            "best: iteration:  36 loss:  36048670.0   style_loss:  40035276.0   content_loss:  169253.39\n",
            "best: iteration:  37 loss:  35864492.0   style_loss:  39830296.0   content_loss:  172274.2\n",
            "best: iteration:  38 loss:  35137828.0   style_loss:  39022720.0   content_loss:  173806.31\n",
            "best: iteration:  39 loss:  33276426.0   style_loss:  36954500.0   content_loss:  173757.27\n",
            "best: iteration:  40 loss:  31195084.0   style_loss:  34642028.0   content_loss:  172603.89\n",
            "best: iteration:  41 loss:  29947308.0   style_loss:  33255776.0   content_loss:  171105.19\n",
            "best: iteration:  42 loss:  29493080.0   style_loss:  32751196.0   content_loss:  170031.88\n",
            "best: iteration:  43 loss:  29017482.0   style_loss:  32222770.0   content_loss:  169900.86\n",
            "best: iteration:  44 loss:  28045232.0   style_loss:  31142386.0   content_loss:  170851.9\n",
            "best: iteration:  45 loss:  26897788.0   style_loss:  29867250.0   content_loss:  172642.75\n",
            "best: iteration:  46 loss:  26131492.0   style_loss:  29015576.0   content_loss:  174749.48\n",
            "best: iteration:  47 loss:  25779020.0   style_loss:  28623740.0   content_loss:  176539.53\n",
            "best: iteration:  48 loss:  25359234.0   style_loss:  28157200.0   content_loss:  177536.94\n",
            "best: iteration:  49 loss:  24557778.0   style_loss:  27266688.0   content_loss:  177600.27\n",
            "best: iteration:  50 loss:  23611658.0   style_loss:  26215514.0   content_loss:  176950.02\n",
            "best: iteration:  51 loss:  22924248.0   style_loss:  25451828.0   content_loss:  176049.52\n",
            "best: iteration:  52 loss:  22543398.0   style_loss:  25028734.0   content_loss:  175384.48\n",
            "best: iteration:  53 loss:  22185112.0   style_loss:  24630648.0   content_loss:  175304.84\n",
            "best: iteration:  54 loss:  21651724.0   style_loss:  24037926.0   content_loss:  175910.33\n",
            "best: iteration:  55 loss:  21058908.0   style_loss:  23379116.0   content_loss:  177040.67\n",
            "best: iteration:  56 loss:  20627460.0   style_loss:  22899584.0   content_loss:  178340.62\n",
            "best: iteration:  57 loss:  20365314.0   style_loss:  22608194.0   content_loss:  179401.47\n",
            "best: iteration:  58 loss:  20069924.0   style_loss:  22279926.0   content_loss:  179913.12\n",
            "best: iteration:  59 loss:  19622088.0   style_loss:  21782342.0   content_loss:  179805.62\n",
            "best: iteration:  60 loss:  19134464.0   style_loss:  21240596.0   content_loss:  179272.22\n",
            "best: iteration:  61 loss:  18762974.0   style_loss:  20827898.0   content_loss:  178655.19\n",
            "best: iteration:  62 loss:  18497052.0   style_loss:  20532472.0   content_loss:  178289.53\n",
            "best: iteration:  63 loss:  18215620.0   style_loss:  20219758.0   content_loss:  178371.39\n",
            "best: iteration:  64 loss:  17870550.0   style_loss:  19836290.0   content_loss:  178907.28\n",
            "best: iteration:  65 loss:  17531926.0   style_loss:  19459950.0   content_loss:  179727.42\n",
            "best: iteration:  66 loss:  17266824.0   style_loss:  19165298.0   content_loss:  180565.25\n",
            "best: iteration:  67 loss:  17046180.0   style_loss:  18920072.0   content_loss:  181158.22\n",
            "best: iteration:  68 loss:  16799758.0   style_loss:  18646248.0   content_loss:  181364.38\n",
            "best: iteration:  69 loss:  16517468.0   style_loss:  18332608.0   content_loss:  181209.75\n",
            "best: iteration:  70 loss:  16248071.0   style_loss:  18033316.0   content_loss:  180866.86\n",
            "best: iteration:  71 loss:  16018132.0   style_loss:  17777862.0   content_loss:  180566.27\n",
            "best: iteration:  72 loss:  15800170.0   style_loss:  17535690.0   content_loss:  180493.94\n",
            "best: iteration:  73 loss:  15566296.0   style_loss:  17275806.0   content_loss:  180714.2\n",
            "best: iteration:  74 loss:  15330836.0   style_loss:  17014134.0   content_loss:  181159.05\n",
            "best: iteration:  75 loss:  15120867.0   style_loss:  16780778.0   content_loss:  181670.95\n",
            "best: iteration:  76 loss:  14931452.0   style_loss:  16570272.0   content_loss:  182080.73\n",
            "best: iteration:  77 loss:  14736296.0   style_loss:  16353409.0   content_loss:  182279.78\n",
            "best: iteration:  78 loss:  14528927.0   style_loss:  16123002.0   content_loss:  182264.08\n",
            "best: iteration:  79 loss:  14328432.0   style_loss:  15900244.0   content_loss:  182127.06\n",
            "best: iteration:  80 loss:  14146959.0   style_loss:  15698620.0   content_loss:  182007.33\n",
            "best: iteration:  81 loss:  13973765.0   style_loss:  15506181.0   content_loss:  182019.33\n",
            "best: iteration:  82 loss:  13795144.0   style_loss:  15307694.0   content_loss:  182200.89\n",
            "best: iteration:  83 loss:  13614579.0   style_loss:  15107032.0   content_loss:  182507.22\n",
            "best: iteration:  84 loss:  13443253.0   style_loss:  14916633.0   content_loss:  182839.66\n",
            "best: iteration:  85 loss:  13281542.0   style_loss:  14736926.0   content_loss:  183093.86\n",
            "best: iteration:  86 loss:  13120451.0   style_loss:  14557923.0   content_loss:  183209.2\n",
            "best: iteration:  87 loss:  12957146.0   style_loss:  14376474.0   content_loss:  183196.25\n",
            "best: iteration:  88 loss:  12797362.0   style_loss:  14198945.0   content_loss:  183124.31\n",
            "best: iteration:  89 loss:  12644841.0   style_loss:  14029482.0   content_loss:  183083.88\n",
            "best: iteration:  90 loss:  12496188.0   style_loss:  13864305.0   content_loss:  183139.33\n",
            "best: iteration:  91 loss:  12347845.0   style_loss:  13699462.0   content_loss:  183302.42\n",
            "best: iteration:  92 loss:  12201394.0   style_loss:  13536713.0   content_loss:  183531.22\n",
            "best: iteration:  93 loss:  12059359.0   style_loss:  13378872.0   content_loss:  183753.31\n",
            "best: iteration:  94 loss:  11920524.0   style_loss:  13224593.0   content_loss:  183906.72\n",
            "best: iteration:  95 loss:  11782105.0   style_loss:  13070788.0   content_loss:  183963.98\n",
            "best: iteration:  96 loss:  11644400.0   style_loss:  12917784.0   content_loss:  183946.78\n",
            "best: iteration:  97 loss:  11509742.0   style_loss:  12768168.0   content_loss:  183908.02\n",
            "best: iteration:  98 loss:  11378508.0   style_loss:  12622354.0   content_loss:  183903.34\n",
            "best: iteration:  99 loss:  11249089.0   style_loss:  12478547.0   content_loss:  183965.73\n",
            "best: iteration:  100 loss:  11120892.0   style_loss:  12336092.0   content_loss:  184091.33\n",
            "best: iteration:  101 loss:  10994832.0   style_loss:  12196009.0   content_loss:  184244.58\n",
            "best: iteration:  102 loss:  10871339.0   style_loss:  12058779.0   content_loss:  184381.86\n",
            "best: iteration:  103 loss:  10749605.0   style_loss:  11923509.0   content_loss:  184473.61\n",
            "best: iteration:  104 loss:  10628914.0   style_loss:  11789403.0   content_loss:  184516.67\n",
            "best: iteration:  105 loss:  10509562.0   style_loss:  11656788.0   content_loss:  184533.22\n",
            "best: iteration:  106 loss:  10392086.0   style_loss:  11526256.0   content_loss:  184557.55\n",
            "best: iteration:  107 loss:  10276292.0   style_loss:  11397589.0   content_loss:  184616.22\n",
            "best: iteration:  108 loss:  10161976.0   style_loss:  11270561.0   content_loss:  184713.53\n",
            "best: iteration:  109 loss:  10049168.0   style_loss:  11145206.0   content_loss:  184834.38\n",
            "best: iteration:  110 loss:  9937914.0   style_loss:  11021577.0   content_loss:  184951.89\n",
            "best: iteration:  111 loss:  9828074.0   style_loss:  10899521.0   content_loss:  185045.95\n",
            "best: iteration:  112 loss:  9719449.0   style_loss:  10778820.0   content_loss:  185110.11\n",
            "best: iteration:  113 loss:  9612063.0   style_loss:  10659498.0   content_loss:  185153.11\n",
            "best: iteration:  114 loss:  9506026.0   style_loss:  10541675.0   content_loss:  185194.78\n",
            "best: iteration:  115 loss:  9401340.0   style_loss:  10425350.0   content_loss:  185252.47\n",
            "best: iteration:  116 loss:  9297883.0   style_loss:  10310389.0   content_loss:  185332.05\n",
            "best: iteration:  117 loss:  9195630.0   style_loss:  10196764.0   content_loss:  185426.78\n",
            "best: iteration:  118 loss:  9094626.0   style_loss:  10084527.0   content_loss:  185522.33\n",
            "best: iteration:  119 loss:  8994835.0   style_loss:  9973638.0   content_loss:  185605.11\n",
            "best: iteration:  120 loss:  8896187.0   style_loss:  9864022.0   content_loss:  185670.0\n",
            "best: iteration:  121 loss:  8798668.0   style_loss:  9755663.0   content_loss:  185721.39\n",
            "best: iteration:  122 loss:  8702255.0   style_loss:  9648531.0   content_loss:  185770.42\n",
            "best: iteration:  123 loss:  8606911.0   style_loss:  9542587.0   content_loss:  185827.14\n",
            "best: iteration:  124 loss:  8512655.0   style_loss:  9437850.0   content_loss:  185895.42\n",
            "best: iteration:  125 loss:  8419479.0   style_loss:  9334314.0   content_loss:  185972.38\n",
            "best: iteration:  126 loss:  8327306.5   style_loss:  9231891.0   content_loss:  186049.05\n",
            "best: iteration:  127 loss:  8236131.0   style_loss:  9130577.0   content_loss:  186117.8\n",
            "best: iteration:  128 loss:  8145954.0   style_loss:  9030374.0   content_loss:  186176.31\n",
            "best: iteration:  129 loss:  8056764.5   style_loss:  8931269.0   content_loss:  186226.67\n",
            "best: iteration:  130 loss:  7968574.0   style_loss:  8833274.0   content_loss:  186275.52\n",
            "best: iteration:  131 loss:  7881355.0   style_loss:  8736358.0   content_loss:  186328.16\n",
            "best: iteration:  132 loss:  7795130.5   style_loss:  8640547.0   content_loss:  186386.53\n",
            "best: iteration:  133 loss:  7709884.5   style_loss:  8545822.0   content_loss:  186448.62\n",
            "best: iteration:  134 loss:  7625595.5   style_loss:  8452161.0   content_loss:  186509.47\n",
            "best: iteration:  135 loss:  7542229.0   style_loss:  8359525.0   content_loss:  186565.48\n",
            "best: iteration:  136 loss:  7459766.5   style_loss:  8267894.5   content_loss:  186615.92\n",
            "best: iteration:  137 loss:  7378188.5   style_loss:  8177247.0   content_loss:  186663.02\n",
            "best: iteration:  138 loss:  7297481.0   style_loss:  8087567.0   content_loss:  186709.84\n",
            "best: iteration:  139 loss:  7217637.0   style_loss:  7998845.5   content_loss:  186758.98\n",
            "best: iteration:  140 loss:  7138680.0   style_loss:  7911110.0   content_loss:  186811.78\n",
            "best: iteration:  141 loss:  7060591.0   style_loss:  7824338.5   content_loss:  186866.81\n",
            "best: iteration:  142 loss:  6983324.5   style_loss:  7738481.0   content_loss:  186921.11\n",
            "best: iteration:  143 loss:  6906882.5   style_loss:  7653539.0   content_loss:  186973.14\n",
            "best: iteration:  144 loss:  6831254.0   style_loss:  7569502.0   content_loss:  187023.11\n",
            "best: iteration:  145 loss:  6756474.0   style_loss:  7486407.5   content_loss:  187072.89\n",
            "best: iteration:  146 loss:  6682519.5   style_loss:  7404230.0   content_loss:  187123.45\n",
            "best: iteration:  147 loss:  6609355.0   style_loss:  7322931.0   content_loss:  187175.39\n",
            "best: iteration:  148 loss:  6536981.0   style_loss:  7242509.0   content_loss:  187228.0\n",
            "best: iteration:  149 loss:  6465444.0   style_loss:  7163018.0   content_loss:  187280.53\n",
            "best: iteration:  150 loss:  6394699.5   style_loss:  7084407.5   content_loss:  187331.8\n",
            "best: iteration:  151 loss:  6324723.5   style_loss:  7006650.5   content_loss:  187381.2\n",
            "best: iteration:  152 loss:  6255513.0   style_loss:  6929744.5   content_loss:  187430.14\n",
            "best: iteration:  153 loss:  6187055.0   style_loss:  6853674.5   content_loss:  187479.25\n",
            "best: iteration:  154 loss:  6119347.0   style_loss:  6778438.0   content_loss:  187528.22\n",
            "best: iteration:  155 loss:  6052369.0   style_loss:  6704013.0   content_loss:  187577.11\n",
            "best: iteration:  156 loss:  5986120.5   style_loss:  6630398.0   content_loss:  187626.48\n",
            "best: iteration:  157 loss:  5920567.5   style_loss:  6557556.0   content_loss:  187676.11\n",
            "best: iteration:  158 loss:  5855725.5   style_loss:  6485503.5   content_loss:  187725.47\n",
            "best: iteration:  159 loss:  5791654.5   style_loss:  6414308.0   content_loss:  187774.38\n",
            "best: iteration:  160 loss:  5728324.0   style_loss:  6343935.5   content_loss:  187821.89\n",
            "best: iteration:  161 loss:  5665703.5   style_loss:  6274352.0   content_loss:  187869.2\n",
            "best: iteration:  162 loss:  5603793.5   style_loss:  6205558.0   content_loss:  187916.22\n",
            "best: iteration:  163 loss:  5542607.5   style_loss:  6137568.0   content_loss:  187962.61\n",
            "best: iteration:  164 loss:  5482144.5   style_loss:  6070382.0   content_loss:  188008.89\n",
            "best: iteration:  165 loss:  5422377.5   style_loss:  6003969.0   content_loss:  188054.81\n",
            "best: iteration:  166 loss:  5363329.5   style_loss:  5938355.0   content_loss:  188099.75\n",
            "best: iteration:  167 loss:  5304986.0   style_loss:  5873524.0   content_loss:  188143.62\n",
            "best: iteration:  168 loss:  5247335.0   style_loss:  5809463.0   content_loss:  188186.25\n",
            "best: iteration:  169 loss:  5190365.5   style_loss:  5746158.5   content_loss:  188228.66\n",
            "best: iteration:  170 loss:  5134081.5   style_loss:  5683616.0   content_loss:  188269.67\n",
            "best: iteration:  171 loss:  5078459.0   style_loss:  5621809.0   content_loss:  188310.55\n",
            "best: iteration:  172 loss:  5023511.5   style_loss:  5560752.0   content_loss:  188351.62\n",
            "best: iteration:  173 loss:  4969211.5   style_loss:  5500413.5   content_loss:  188392.73\n",
            "best: iteration:  174 loss:  4915551.0   style_loss:  5440786.0   content_loss:  188434.14\n",
            "best: iteration:  175 loss:  4862528.5   style_loss:  5381868.0   content_loss:  188474.95\n",
            "best: iteration:  176 loss:  4810134.0   style_loss:  5323647.5   content_loss:  188515.4\n",
            "best: iteration:  177 loss:  4758366.5   style_loss:  5266123.5   content_loss:  188555.05\n",
            "best: iteration:  178 loss:  4707243.0   style_loss:  5209315.0   content_loss:  188594.67\n",
            "best: iteration:  179 loss:  4656744.5   style_loss:  5153201.5   content_loss:  188633.78\n",
            "best: iteration:  180 loss:  4606883.5   style_loss:  5097795.5   content_loss:  188672.8\n",
            "best: iteration:  181 loss:  4557636.0   style_loss:  5043072.5   content_loss:  188711.53\n",
            "best: iteration:  182 loss:  4509013.0   style_loss:  4989042.5   content_loss:  188750.19\n",
            "best: iteration:  183 loss:  4460992.5   style_loss:  4935682.0   content_loss:  188789.53\n",
            "best: iteration:  184 loss:  4413575.0   style_loss:  4882991.5   content_loss:  188829.42\n",
            "best: iteration:  185 loss:  4366762.0   style_loss:  4830972.5   content_loss:  188869.55\n",
            "best: iteration:  186 loss:  4320517.5   style_loss:  4779585.0   content_loss:  188909.08\n",
            "best: iteration:  187 loss:  4274846.5   style_loss:  4728835.0   content_loss:  188948.67\n",
            "best: iteration:  188 loss:  4229741.0   style_loss:  4678713.5   content_loss:  188988.25\n",
            "best: iteration:  189 loss:  4185234.5   style_loss:  4629257.5   content_loss:  189027.42\n",
            "best: iteration:  190 loss:  4141316.5   style_loss:  4580455.5   content_loss:  189066.48\n",
            "best: iteration:  191 loss:  4097967.8   style_loss:  4532286.0   content_loss:  189105.25\n",
            "best: iteration:  192 loss:  4055196.5   style_loss:  4484758.0   content_loss:  189143.88\n",
            "best: iteration:  193 loss:  4013000.8   style_loss:  4437869.5   content_loss:  189182.33\n",
            "best: iteration:  194 loss:  3971360.5   style_loss:  4391598.5   content_loss:  189220.61\n",
            "best: iteration:  195 loss:  3930268.0   style_loss:  4345936.0   content_loss:  189258.55\n",
            "best: iteration:  196 loss:  3889714.8   style_loss:  4300872.5   content_loss:  189296.16\n",
            "best: iteration:  197 loss:  3849671.0   style_loss:  4256375.5   content_loss:  189333.48\n",
            "best: iteration:  198 loss:  3810141.5   style_loss:  4212449.5   content_loss:  189370.81\n",
            "best: iteration:  199 loss:  3771135.5   style_loss:  4169105.5   content_loss:  189408.38\n",
            "best: iteration:  0 loss:  3476643600.0   style_loss:  3862935300.0   content_loss:  18397.3\n",
            "best: iteration:  1 loss:  2460409000.0   style_loss:  2733782300.0   content_loss:  51411.812\n",
            "best: iteration:  2 loss:  1513130900.0   style_loss:  1681245600.0   content_loss:  98992.305\n",
            "best: iteration:  3 loss:  1134265000.0   style_loss:  1260277000.0   content_loss:  157083.45\n",
            "best: iteration:  6 loss:  1038656960.0   style_loss:  1154039200.0   content_loss:  217396.38\n",
            "best: iteration:  7 loss:  717414200.0   style_loss:  797104200.0   content_loss:  205029.98\n",
            "best: iteration:  8 loss:  548113900.0   style_loss:  608994100.0   content_loss:  192452.34\n",
            "best: iteration:  9 loss:  509906980.0   style_loss:  566542800.0   content_loss:  185082.28\n",
            "best: iteration:  11 loss:  505309860.0   style_loss:  561433900.0   content_loss:  193426.11\n",
            "best: iteration:  12 loss:  479779500.0   style_loss:  533065200.0   content_loss:  207925.86\n",
            "best: iteration:  13 loss:  464339550.0   style_loss:  515907740.0   content_loss:  225780.75\n",
            "best: iteration:  16 loss:  448272960.0   style_loss:  498052700.0   content_loss:  255489.27\n",
            "best: iteration:  17 loss:  407814800.0   style_loss:  453099520.0   content_loss:  252064.6\n",
            "best: iteration:  18 loss:  371437730.0   style_loss:  412681340.0   content_loss:  245493.22\n",
            "best: iteration:  19 loss:  349227420.0   style_loss:  388003900.0   content_loss:  238949.81\n",
            "best: iteration:  20 loss:  335690140.0   style_loss:  372962980.0   content_loss:  234814.72\n",
            "best: iteration:  21 loss:  321583870.0   style_loss:  357289400.0   content_loss:  234309.11\n",
            "best: iteration:  22 loss:  304418500.0   style_loss:  338216420.0   content_loss:  237525.8\n",
            "best: iteration:  23 loss:  288688830.0   style_loss:  320738340.0   content_loss:  243598.25\n",
            "best: iteration:  24 loss:  278681760.0   style_loss:  309618530.0   content_loss:  250837.72\n",
            "best: iteration:  25 loss:  272120540.0   style_loss:  302327580.0   content_loss:  257391.34\n",
            "best: iteration:  26 loss:  263035460.0   style_loss:  292232540.0   content_loss:  261769.47\n",
            "best: iteration:  27 loss:  249468370.0   style_loss:  277157800.0   content_loss:  263647.03\n",
            "best: iteration:  28 loss:  235014080.0   style_loss:  261097440.0   content_loss:  263805.47\n",
            "best: iteration:  29 loss:  223364770.0   style_loss:  248153780.0   content_loss:  263622.94\n",
            "best: iteration:  30 loss:  214566450.0   style_loss:  238377780.0   content_loss:  264465.78\n",
            "best: iteration:  31 loss:  206512900.0   style_loss:  229429090.0   content_loss:  267227.75\n",
            "best: iteration:  32 loss:  198173120.0   style_loss:  220162130.0   content_loss:  272112.38\n",
            "best: iteration:  33 loss:  190426300.0   style_loss:  211553820.0   content_loss:  278660.75\n",
            "best: iteration:  34 loss:  184374180.0   style_loss:  204828430.0   content_loss:  285877.78\n",
            "best: iteration:  35 loss:  179497440.0   style_loss:  199409090.0   content_loss:  292569.78\n",
            "best: iteration:  36 loss:  174042140.0   style_loss:  193347090.0   content_loss:  297775.78\n",
            "best: iteration:  37 loss:  167274020.0   style_loss:  185826560.0   content_loss:  301167.9\n",
            "best: iteration:  38 loss:  160199120.0   style_loss:  177965360.0   content_loss:  303092.47\n",
            "best: iteration:  39 loss:  154079330.0   style_loss:  171165440.0   content_loss:  304338.3\n",
            "best: iteration:  40 loss:  149099200.0   style_loss:  165631800.0   content_loss:  305739.06\n",
            "best: iteration:  41 loss:  144633940.0   style_loss:  160670160.0   content_loss:  307928.25\n",
            "best: iteration:  42 loss:  140225840.0   style_loss:  155771940.0   content_loss:  311111.62\n",
            "best: iteration:  43 loss:  135955340.0   style_loss:  151026480.0   content_loss:  315122.53\n",
            "best: iteration:  44 loss:  132091570.0   style_loss:  146732910.0   content_loss:  319502.7\n",
            "best: iteration:  45 loss:  128582970.0   style_loss:  142834000.0   content_loss:  323691.72\n",
            "best: iteration:  46 loss:  125081280.0   style_loss:  138942850.0   content_loss:  327212.12\n",
            "best: iteration:  47 loss:  121385100.0   style_loss:  134835680.0   content_loss:  329882.66\n",
            "best: iteration:  48 loss:  117672830.0   style_loss:  130710720.0   content_loss:  331876.72\n",
            "best: iteration:  49 loss:  114233310.0   style_loss:  126888850.0   content_loss:  333536.62\n",
            "best: iteration:  50 loss:  111152424.0   style_loss:  123465440.0   content_loss:  335284.75\n",
            "best: iteration:  51 loss:  108303920.0   style_loss:  120300200.0   content_loss:  337405.12\n",
            "best: iteration:  52 loss:  105565350.0   style_loss:  117257064.0   content_loss:  339961.38\n",
            "best: iteration:  53 loss:  102935384.0   style_loss:  114334560.0   content_loss:  342826.12\n",
            "best: iteration:  54 loss:  100457660.0   style_loss:  111581220.0   content_loss:  345720.44\n",
            "best: iteration:  55 loss:  98116584.0   style_loss:  108979730.0   content_loss:  348352.16\n",
            "best: iteration:  56 loss:  95847550.0   style_loss:  106458344.0   content_loss:  350507.75\n",
            "best: iteration:  57 loss:  93612690.0   style_loss:  103974980.0   content_loss:  352146.16\n",
            "best: iteration:  58 loss:  91444640.0   style_loss:  101565896.0   content_loss:  353366.1\n",
            "best: iteration:  59 loss:  89397010.0   style_loss:  99290630.0   content_loss:  354395.56\n",
            "best: iteration:  60 loss:  87469130.0   style_loss:  97148424.0   content_loss:  355484.5\n",
            "best: iteration:  61 loss:  85622620.0   style_loss:  95096610.0   content_loss:  356794.28\n",
            "best: iteration:  62 loss:  83838070.0   style_loss:  93113590.0   content_loss:  358370.94\n",
            "best: iteration:  63 loss:  82121720.0   style_loss:  91206344.0   content_loss:  360131.16\n",
            "best: iteration:  64 loss:  80481530.0   style_loss:  89383710.0   content_loss:  361910.03\n",
            "best: iteration:  65 loss:  78898770.0   style_loss:  87624910.0   content_loss:  363534.3\n",
            "best: iteration:  66 loss:  77355544.0   style_loss:  85910060.0   content_loss:  364888.12\n",
            "best: iteration:  67 loss:  75850690.0   style_loss:  84237880.0   content_loss:  365972.1\n",
            "best: iteration:  68 loss:  74399360.0   style_loss:  82625190.0   content_loss:  366875.62\n",
            "best: iteration:  69 loss:  73009944.0   style_loss:  81081300.0   content_loss:  367725.2\n",
            "best: iteration:  70 loss:  71671260.0   style_loss:  79593780.0   content_loss:  368627.5\n",
            "best: iteration:  71 loss:  70371860.0   style_loss:  78149880.0   content_loss:  369651.97\n",
            "best: iteration:  72 loss:  69116460.0   style_loss:  76754870.0   content_loss:  370791.34\n",
            "best: iteration:  73 loss:  67911310.0   style_loss:  75415680.0   content_loss:  371968.44\n",
            "best: iteration:  74 loss:  66750188.0   style_loss:  74125420.0   content_loss:  373090.7\n",
            "best: iteration:  75 loss:  65620436.0   style_loss:  72870030.0   content_loss:  374084.28\n",
            "best: iteration:  76 loss:  64517876.0   style_loss:  71644870.0   content_loss:  374932.8\n",
            "best: iteration:  77 loss:  63444476.0   style_loss:  70452120.0   content_loss:  375675.16\n",
            "best: iteration:  78 loss:  62405228.0   style_loss:  69297330.0   content_loss:  376377.03\n",
            "best: iteration:  79 loss:  61397364.0   style_loss:  68177390.0   content_loss:  377112.03\n",
            "best: iteration:  80 loss:  60418660.0   style_loss:  67089856.0   content_loss:  377916.1\n",
            "best: iteration:  81 loss:  59467520.0   style_loss:  66032936.0   content_loss:  378787.6\n",
            "best: iteration:  82 loss:  58542410.0   style_loss:  65004936.0   content_loss:  379682.38\n",
            "best: iteration:  83 loss:  57643016.0   style_loss:  64005510.0   content_loss:  380542.12\n",
            "best: iteration:  84 loss:  56765340.0   style_loss:  63030230.0   content_loss:  381323.9\n",
            "best: iteration:  85 loss:  55908036.0   style_loss:  62077596.0   content_loss:  382013.25\n",
            "best: iteration:  86 loss:  55070784.0   style_loss:  61147244.0   content_loss:  382637.78\n",
            "best: iteration:  87 loss:  54256224.0   style_loss:  60242110.0   content_loss:  383250.03\n",
            "best: iteration:  88 loss:  53463948.0   style_loss:  59361736.0   content_loss:  383888.44\n",
            "best: iteration:  89 loss:  52691988.0   style_loss:  58503930.0   content_loss:  384577.3\n",
            "best: iteration:  90 loss:  51939076.0   style_loss:  57667270.0   content_loss:  385307.2\n",
            "best: iteration:  91 loss:  51204836.0   style_loss:  56851372.0   content_loss:  386047.06\n",
            "best: iteration:  92 loss:  50487540.0   style_loss:  56054296.0   content_loss:  386756.94\n",
            "best: iteration:  93 loss:  49785136.0   style_loss:  55273776.0   content_loss:  387405.1\n",
            "best: iteration:  94 loss:  49098296.0   style_loss:  54510550.0   content_loss:  387982.84\n",
            "best: iteration:  95 loss:  48426856.0   style_loss:  53764452.0   content_loss:  388512.12\n",
            "best: iteration:  96 loss:  47769856.0   style_loss:  53034390.0   content_loss:  389024.75\n",
            "best: iteration:  97 loss:  47126890.0   style_loss:  52319930.0   content_loss:  389556.94\n",
            "best: iteration:  98 loss:  46497424.0   style_loss:  51620460.0   content_loss:  390121.78\n",
            "best: iteration:  99 loss:  45880610.0   style_loss:  50935040.0   content_loss:  390713.62\n",
            "best: iteration:  100 loss:  45276260.0   style_loss:  50263476.0   content_loss:  391311.6\n",
            "best: iteration:  101 loss:  44685308.0   style_loss:  49606800.0   content_loss:  391885.25\n",
            "best: iteration:  102 loss:  44106064.0   style_loss:  48963140.0   content_loss:  392413.3\n",
            "best: iteration:  103 loss:  43538308.0   style_loss:  48332244.0   content_loss:  392894.78\n",
            "best: iteration:  104 loss:  42982084.0   style_loss:  47714164.0   content_loss:  393342.7\n",
            "best: iteration:  105 loss:  42436850.0   style_loss:  47108300.0   content_loss:  393786.16\n",
            "best: iteration:  106 loss:  41902180.0   style_loss:  46514176.0   content_loss:  394241.3\n",
            "best: iteration:  107 loss:  41377196.0   style_loss:  45930804.0   content_loss:  394714.66\n",
            "best: iteration:  108 loss:  40863010.0   style_loss:  45359430.0   content_loss:  395205.62\n",
            "best: iteration:  109 loss:  40359050.0   style_loss:  44799424.0   content_loss:  395690.66\n",
            "best: iteration:  110 loss:  39864560.0   style_loss:  44249940.0   content_loss:  396151.25\n",
            "best: iteration:  111 loss:  39378590.0   style_loss:  43709930.0   content_loss:  396574.22\n",
            "best: iteration:  112 loss:  38901204.0   style_loss:  43179456.0   content_loss:  396965.75\n",
            "best: iteration:  113 loss:  38432324.0   style_loss:  42658430.0   content_loss:  397342.53\n",
            "best: iteration:  114 loss:  37972252.0   style_loss:  42147200.0   content_loss:  397718.78\n",
            "best: iteration:  115 loss:  37520428.0   style_loss:  41645130.0   content_loss:  398106.03\n",
            "best: iteration:  116 loss:  37076490.0   style_loss:  41151820.0   content_loss:  398501.97\n",
            "best: iteration:  117 loss:  36639936.0   style_loss:  40666720.0   content_loss:  398898.22\n",
            "best: iteration:  118 loss:  36210524.0   style_loss:  40189550.0   content_loss:  399289.16\n",
            "best: iteration:  119 loss:  35787780.0   style_loss:  39719790.0   content_loss:  399664.16\n",
            "best: iteration:  120 loss:  35372092.0   style_loss:  39257876.0   content_loss:  400023.72\n",
            "best: iteration:  121 loss:  34963164.0   style_loss:  38803476.0   content_loss:  400369.5\n",
            "best: iteration:  122 loss:  34560300.0   style_loss:  38355810.0   content_loss:  400710.94\n",
            "best: iteration:  123 loss:  34163416.0   style_loss:  37914790.0   content_loss:  401053.34\n",
            "best: iteration:  124 loss:  33772460.0   style_loss:  37480356.0   content_loss:  401404.12\n",
            "best: iteration:  125 loss:  33386738.0   style_loss:  37051736.0   content_loss:  401760.5\n",
            "best: iteration:  126 loss:  33006066.0   style_loss:  36628730.0   content_loss:  402118.56\n",
            "best: iteration:  127 loss:  32630512.0   style_loss:  36211410.0   content_loss:  402465.16\n",
            "best: iteration:  128 loss:  32260550.0   style_loss:  35800300.0   content_loss:  402798.0\n",
            "best: iteration:  129 loss:  31895830.0   style_loss:  35395020.0   content_loss:  403120.16\n",
            "best: iteration:  130 loss:  31536632.0   style_loss:  34995876.0   content_loss:  403441.47\n",
            "best: iteration:  131 loss:  31182938.0   style_loss:  34602850.0   content_loss:  403759.3\n",
            "best: iteration:  132 loss:  30834706.0   style_loss:  34215890.0   content_loss:  404072.5\n",
            "best: iteration:  133 loss:  30492156.0   style_loss:  33835244.0   content_loss:  404375.78\n",
            "best: iteration:  134 loss:  30155020.0   style_loss:  33460614.0   content_loss:  404671.03\n",
            "best: iteration:  135 loss:  29822630.0   style_loss:  33091260.0   content_loss:  404956.3\n",
            "best: iteration:  136 loss:  29494632.0   style_loss:  32726788.0   content_loss:  405232.16\n",
            "best: iteration:  137 loss:  29170870.0   style_loss:  32367024.0   content_loss:  405497.72\n",
            "best: iteration:  138 loss:  28851936.0   style_loss:  32012622.0   content_loss:  405757.6\n",
            "best: iteration:  139 loss:  28537464.0   style_loss:  31663180.0   content_loss:  406016.03\n",
            "best: iteration:  140 loss:  28227434.0   style_loss:  31318674.0   content_loss:  406278.22\n",
            "best: iteration:  141 loss:  27921696.0   style_loss:  30978936.0   content_loss:  406541.03\n",
            "best: iteration:  142 loss:  27620238.0   style_loss:  30643954.0   content_loss:  406804.53\n",
            "best: iteration:  143 loss:  27322838.0   style_loss:  30313480.0   content_loss:  407064.78\n",
            "best: iteration:  144 loss:  27029196.0   style_loss:  29987182.0   content_loss:  407321.5\n",
            "best: iteration:  145 loss:  26739414.0   style_loss:  29665174.0   content_loss:  407572.62\n",
            "best: iteration:  146 loss:  26453678.0   style_loss:  29347662.0   content_loss:  407821.78\n",
            "best: iteration:  147 loss:  26171942.0   style_loss:  29034596.0   content_loss:  408068.3\n",
            "best: iteration:  148 loss:  25893628.0   style_loss:  28725332.0   content_loss:  408309.56\n",
            "best: iteration:  149 loss:  25619242.0   style_loss:  28420432.0   content_loss:  408548.0\n",
            "best: iteration:  150 loss:  25348788.0   style_loss:  28119900.0   content_loss:  408781.88\n",
            "best: iteration:  151 loss:  25082456.0   style_loss:  27823952.0   content_loss:  409008.7\n",
            "best: iteration:  152 loss:  24820014.0   style_loss:  27532322.0   content_loss:  409232.94\n",
            "best: iteration:  153 loss:  24561502.0   style_loss:  27245064.0   content_loss:  409456.56\n",
            "best: iteration:  154 loss:  24306858.0   style_loss:  26962100.0   content_loss:  409680.16\n",
            "best: iteration:  155 loss:  24056160.0   style_loss:  26683522.0   content_loss:  409904.56\n",
            "best: iteration:  156 loss:  23809366.0   style_loss:  26409282.0   content_loss:  410123.75\n",
            "best: iteration:  157 loss:  23566106.0   style_loss:  26138970.0   content_loss:  410338.28\n",
            "best: iteration:  158 loss:  23326348.0   style_loss:  25872550.0   content_loss:  410547.72\n",
            "best: iteration:  159 loss:  23090144.0   style_loss:  25610078.0   content_loss:  410749.78\n",
            "best: iteration:  160 loss:  22857158.0   style_loss:  25351182.0   content_loss:  410944.78\n",
            "best: iteration:  161 loss:  22627220.0   style_loss:  25095674.0   content_loss:  411131.78\n",
            "best: iteration:  162 loss:  22400436.0   style_loss:  24843672.0   content_loss:  411313.97\n",
            "best: iteration:  163 loss:  22176628.0   style_loss:  24594976.0   content_loss:  411491.44\n",
            "best: iteration:  164 loss:  21955640.0   style_loss:  24349416.0   content_loss:  411667.47\n",
            "best: iteration:  165 loss:  21737822.0   style_loss:  24107376.0   content_loss:  411842.5\n",
            "best: iteration:  166 loss:  21522982.0   style_loss:  23868644.0   content_loss:  412012.78\n",
            "best: iteration:  167 loss:  21311026.0   style_loss:  23633120.0   content_loss:  412179.47\n",
            "best: iteration:  168 loss:  21102036.0   style_loss:  23400892.0   content_loss:  412347.44\n",
            "best: iteration:  169 loss:  20896060.0   style_loss:  23172010.0   content_loss:  412516.7\n",
            "best: iteration:  170 loss:  20692942.0   style_loss:  22946306.0   content_loss:  412687.2\n",
            "best: iteration:  171 loss:  20492494.0   style_loss:  22723564.0   content_loss:  412860.75\n",
            "best: iteration:  172 loss:  20294674.0   style_loss:  22503744.0   content_loss:  413033.6\n",
            "best: iteration:  173 loss:  20099238.0   style_loss:  22286576.0   content_loss:  413205.03\n",
            "best: iteration:  174 loss:  19906232.0   style_loss:  22072104.0   content_loss:  413373.75\n",
            "best: iteration:  175 loss:  19716030.0   style_loss:  21860752.0   content_loss:  413539.25\n",
            "best: iteration:  176 loss:  19528482.0   style_loss:  21652348.0   content_loss:  413702.84\n",
            "best: iteration:  177 loss:  19343464.0   style_loss:  21446754.0   content_loss:  413862.0\n",
            "best: iteration:  178 loss:  19161152.0   style_loss:  21244168.0   content_loss:  414015.72\n",
            "best: iteration:  179 loss:  18981128.0   style_loss:  21044124.0   content_loss:  414166.4\n",
            "best: iteration:  180 loss:  18803372.0   style_loss:  20846600.0   content_loss:  414316.97\n",
            "best: iteration:  181 loss:  18627884.0   style_loss:  20651598.0   content_loss:  414468.1\n",
            "best: iteration:  182 loss:  18454584.0   style_loss:  20459024.0   content_loss:  414619.75\n",
            "best: iteration:  183 loss:  18283502.0   style_loss:  20268916.0   content_loss:  414770.28\n",
            "best: iteration:  184 loss:  18114596.0   style_loss:  20081228.0   content_loss:  414921.97\n",
            "best: iteration:  185 loss:  17947824.0   style_loss:  19895908.0   content_loss:  415072.56\n",
            "best: iteration:  186 loss:  17783004.0   style_loss:  19712758.0   content_loss:  415221.97\n",
            "best: iteration:  187 loss:  17620130.0   style_loss:  19531772.0   content_loss:  415369.47\n",
            "best: iteration:  188 loss:  17459148.0   style_loss:  19352884.0   content_loss:  415515.6\n",
            "best: iteration:  189 loss:  17300282.0   style_loss:  19176352.0   content_loss:  415660.25\n",
            "best: iteration:  190 loss:  17143476.0   style_loss:  19002108.0   content_loss:  415804.1\n",
            "best: iteration:  191 loss:  16988576.0   style_loss:  18829980.0   content_loss:  415945.88\n",
            "best: iteration:  192 loss:  16835676.0   style_loss:  18660076.0   content_loss:  416088.1\n",
            "best: iteration:  193 loss:  16684739.0   style_loss:  18492352.0   content_loss:  416229.75\n",
            "best: iteration:  194 loss:  16535677.0   style_loss:  18326712.0   content_loss:  416372.0\n",
            "best: iteration:  195 loss:  16388322.0   style_loss:  18162968.0   content_loss:  416512.16\n",
            "best: iteration:  196 loss:  16242856.0   style_loss:  18001324.0   content_loss:  416649.34\n",
            "best: iteration:  197 loss:  16099224.0   style_loss:  17841718.0   content_loss:  416782.12\n",
            "best: iteration:  198 loss:  15957568.0   style_loss:  17684308.0   content_loss:  416909.38\n",
            "best: iteration:  199 loss:  15817768.0   style_loss:  17528960.0   content_loss:  417037.75\n",
            "best: iteration:  0 loss:  52113996.0   style_loss:  57902420.0   content_loss:  18185.496\n",
            "best: iteration:  1 loss:  51540820.0   style_loss:  57263028.0   content_loss:  40960.01\n",
            "best: iteration:  2 loss:  35879972.0   style_loss:  39861756.0   content_loss:  43922.754\n",
            "best: iteration:  3 loss:  23278682.0   style_loss:  25860332.0   content_loss:  43836.234\n",
            "best: iteration:  4 loss:  20779490.0   style_loss:  23083290.0   content_loss:  45300.78\n",
            "best: iteration:  5 loss:  19053846.0   style_loss:  21165608.0   content_loss:  47995.152\n",
            "best: iteration:  6 loss:  16517803.0   style_loss:  18347522.0   content_loss:  50336.812\n",
            "best: iteration:  7 loss:  13834537.0   style_loss:  15366024.0   content_loss:  51155.65\n",
            "best: iteration:  8 loss:  10841786.0   style_loss:  12040839.0   content_loss:  50313.812\n",
            "best: iteration:  9 loss:  8420011.0   style_loss:  9350141.0   content_loss:  48842.883\n",
            "best: iteration:  10 loss:  7062842.0   style_loss:  7842279.5   content_loss:  47903.29\n",
            "best: iteration:  11 loss:  6231436.0   style_loss:  6918496.0   content_loss:  47898.945\n",
            "best: iteration:  12 loss:  5593654.5   style_loss:  6209781.0   content_loss:  48514.215\n",
            "best: iteration:  13 loss:  5056035.0   style_loss:  5612355.0   content_loss:  49155.01\n",
            "best: iteration:  14 loss:  4511023.0   style_loss:  5006751.5   content_loss:  49469.215\n",
            "best: iteration:  15 loss:  4029338.2   style_loss:  4471532.5   content_loss:  49590.277\n",
            "best: iteration:  16 loss:  3691056.8   style_loss:  4095640.0   content_loss:  49808.062\n",
            "best: iteration:  17 loss:  3430895.8   style_loss:  3806520.2   content_loss:  50275.863\n",
            "best: iteration:  18 loss:  3211522.0   style_loss:  3562701.2   content_loss:  50910.254\n",
            "best: iteration:  19 loss:  3010640.8   style_loss:  3339437.2   content_loss:  51472.395\n",
            "best: iteration:  20 loss:  2791434.0   style_loss:  3095841.5   content_loss:  51766.68\n",
            "best: iteration:  21 loss:  2588939.2   style_loss:  2870840.8   content_loss:  51828.145\n",
            "best: iteration:  22 loss:  2425079.5   style_loss:  2688773.2   content_loss:  51837.43\n",
            "best: iteration:  23 loss:  2269301.5   style_loss:  2515671.5   content_loss:  51972.656\n",
            "best: iteration:  24 loss:  2121072.8   style_loss:  2350938.8   content_loss:  52279.79\n",
            "best: iteration:  25 loss:  1984446.6   style_loss:  2199088.2   content_loss:  52672.035\n",
            "best: iteration:  26 loss:  1853459.6   style_loss:  2053508.2   content_loss:  53022.51\n",
            "best: iteration:  27 loss:  1737683.4   style_loss:  1924839.0   content_loss:  53283.92\n",
            "best: iteration:  28 loss:  1630655.5   style_loss:  1805896.5   content_loss:  53487.887\n",
            "best: iteration:  29 loss:  1526292.8   style_loss:  1689914.1   content_loss:  53701.57\n",
            "best: iteration:  30 loss:  1435071.2   style_loss:  1588528.8   content_loss:  53953.984\n",
            "best: iteration:  31 loss:  1353038.8   style_loss:  1497353.4   content_loss:  54208.04\n",
            "best: iteration:  32 loss:  1277923.9   style_loss:  1413869.8   content_loss:  54410.734\n",
            "best: iteration:  33 loss:  1213828.6   style_loss:  1342637.1   content_loss:  54551.9\n",
            "best: iteration:  34 loss:  1153813.1   style_loss:  1275941.5   content_loss:  54657.863\n",
            "best: iteration:  35 loss:  1099370.4   style_loss:  1215437.1   content_loss:  54769.594\n",
            "best: iteration:  36 loss:  1053474.2   style_loss:  1164426.1   content_loss:  54907.03\n",
            "best: iteration:  37 loss:  1010411.5   style_loss:  1116561.5   content_loss:  55061.984\n",
            "best: iteration:  38 loss:  973115.94   style_loss:  1075104.5   content_loss:  55219.32\n",
            "best: iteration:  39 loss:  940498.5   style_loss:  1038846.94   content_loss:  55362.664\n",
            "best: iteration:  40 loss:  906114.44   style_loss:  1000628.75   content_loss:  55485.92\n",
            "best: iteration:  41 loss:  873763.25   style_loss:  964671.0   content_loss:  55593.45\n",
            "best: iteration:  42 loss:  844218.9   style_loss:  931832.4   content_loss:  55697.586\n",
            "best: iteration:  43 loss:  816717.56   style_loss:  901262.6   content_loss:  55812.473\n",
            "best: iteration:  44 loss:  791996.0   style_loss:  873780.9   content_loss:  55932.746\n",
            "best: iteration:  45 loss:  766434.44   style_loss:  845367.9   content_loss:  56033.88\n",
            "best: iteration:  46 loss:  741727.4   style_loss:  817908.3   content_loss:  56099.062\n",
            "best: iteration:  47 loss:  720022.94   style_loss:  793787.5   content_loss:  56141.895\n",
            "best: iteration:  48 loss:  699008.9   style_loss:  770432.06   content_loss:  56200.367\n",
            "best: iteration:  49 loss:  679061.4   style_loss:  748257.3   content_loss:  56298.297\n",
            "best: iteration:  50 loss:  659949.8   style_loss:  727009.5   content_loss:  56412.23\n",
            "best: iteration:  51 loss:  641687.44   style_loss:  706709.0   content_loss:  56493.63\n",
            "best: iteration:  52 loss:  624943.9   style_loss:  688101.06   content_loss:  56529.688\n",
            "best: iteration:  53 loss:  608830.1   style_loss:  670193.6   content_loss:  56558.867\n",
            "best: iteration:  54 loss:  593537.56   style_loss:  653195.0   content_loss:  56620.656\n",
            "best: iteration:  55 loss:  579193.06   style_loss:  637247.56   content_loss:  56702.777\n",
            "best: iteration:  56 loss:  565551.4   style_loss:  622084.25   content_loss:  56755.434\n",
            "best: iteration:  57 loss:  552551.56   style_loss:  607639.4   content_loss:  56761.414\n",
            "best: iteration:  58 loss:  539980.3   style_loss:  593671.6   content_loss:  56758.664\n",
            "best: iteration:  59 loss:  527817.56   style_loss:  580153.56   content_loss:  56793.67\n",
            "best: iteration:  60 loss:  516276.34   style_loss:  567322.7   content_loss:  56859.49\n",
            "best: iteration:  61 loss:  505320.66   style_loss:  555144.75   content_loss:  56903.95\n",
            "best: iteration:  62 loss:  494595.78   style_loss:  543228.0   content_loss:  56906.027\n",
            "best: iteration:  63 loss:  484233.12   style_loss:  531713.9   content_loss:  56906.57\n",
            "best: iteration:  64 loss:  474232.72   style_loss:  520597.72   content_loss:  56947.855\n",
            "best: iteration:  65 loss:  464762.47   style_loss:  510068.0   content_loss:  57012.83\n",
            "best: iteration:  66 loss:  455672.38   style_loss:  499963.75   content_loss:  57049.938\n",
            "best: iteration:  67 loss:  446721.22   style_loss:  490018.38   content_loss:  57046.95\n",
            "best: iteration:  68 loss:  438111.6   style_loss:  480452.06   content_loss:  57047.55\n",
            "best: iteration:  69 loss:  429724.72   style_loss:  471129.06   content_loss:  57085.5\n",
            "best: iteration:  70 loss:  421702.8   style_loss:  462209.84   content_loss:  57139.562\n",
            "best: iteration:  71 loss:  413847.75   style_loss:  453478.88   content_loss:  57167.918\n",
            "best: iteration:  72 loss:  406203.6   style_loss:  444984.7   content_loss:  57173.77\n",
            "best: iteration:  73 loss:  398867.2   style_loss:  436830.78   content_loss:  57195.12\n",
            "best: iteration:  74 loss:  391742.44   style_loss:  428909.22   content_loss:  57241.6\n",
            "best: iteration:  75 loss:  384847.2   style_loss:  421243.4   content_loss:  57281.25\n",
            "best: iteration:  76 loss:  378031.3   style_loss:  413669.1   content_loss:  57291.4\n",
            "best: iteration:  77 loss:  371478.47   style_loss:  406387.78   content_loss:  57294.555\n",
            "best: iteration:  78 loss:  365095.1   style_loss:  399292.06   content_loss:  57322.613\n",
            "best: iteration:  79 loss:  358865.44   style_loss:  392365.03   content_loss:  57369.094\n",
            "best: iteration:  80 loss:  352767.53   style_loss:  385585.66   content_loss:  57404.42\n",
            "best: iteration:  81 loss:  346844.53   style_loss:  379002.3   content_loss:  57424.785\n",
            "best: iteration:  82 loss:  341103.12   style_loss:  372620.0   content_loss:  57451.367\n",
            "best: iteration:  83 loss:  335464.34   style_loss:  366350.5   content_loss:  57489.117\n",
            "best: iteration:  84 loss:  329982.3   style_loss:  360256.25   content_loss:  57516.895\n",
            "best: iteration:  85 loss:  324612.4   style_loss:  354288.88   content_loss:  57524.254\n",
            "best: iteration:  86 loss:  319385.03   style_loss:  348479.94   content_loss:  57531.062\n",
            "best: iteration:  87 loss:  314260.03   style_loss:  342782.56   content_loss:  57557.164\n",
            "best: iteration:  88 loss:  309257.34   style_loss:  337220.03   content_loss:  57593.24\n",
            "best: iteration:  89 loss:  304360.38   style_loss:  331776.0   content_loss:  57619.68\n",
            "best: iteration:  90 loss:  299577.47   style_loss:  326459.8   content_loss:  57636.613\n",
            "best: iteration:  91 loss:  294903.0   style_loss:  321263.84   content_loss:  57655.53\n",
            "best: iteration:  92 loss:  290320.12   style_loss:  316169.56   content_loss:  57675.33\n",
            "best: iteration:  93 loss:  285833.1   style_loss:  311182.66   content_loss:  57687.164\n",
            "best: iteration:  94 loss:  281440.34   style_loss:  306300.88   content_loss:  57695.76\n",
            "best: iteration:  95 loss:  277137.3   style_loss:  301517.62   content_loss:  57714.53\n",
            "best: iteration:  96 loss:  272915.94   style_loss:  296823.97   content_loss:  57743.62\n",
            "best: iteration:  97 loss:  268775.22   style_loss:  292220.28   content_loss:  57769.562\n",
            "best: iteration:  98 loss:  264719.25   style_loss:  287711.78   content_loss:  57786.547\n",
            "best: iteration:  99 loss:  260740.31   style_loss:  283289.0   content_loss:  57802.168\n",
            "best: iteration:  100 loss:  256841.22   style_loss:  278954.56   content_loss:  57821.277\n",
            "best: iteration:  101 loss:  253013.52   style_loss:  274699.53   content_loss:  57839.438\n",
            "best: iteration:  102 loss:  249260.3   style_loss:  270527.62   content_loss:  57854.316\n",
            "best: iteration:  103 loss:  245574.33   style_loss:  266430.22   content_loss:  57871.38\n",
            "best: iteration:  104 loss:  241959.48   style_loss:  262411.38   content_loss:  57892.43\n",
            "best: iteration:  105 loss:  238410.42   style_loss:  258465.75   content_loss:  57912.48\n",
            "best: iteration:  106 loss:  234925.73   style_loss:  254592.0   content_loss:  57929.367\n",
            "best: iteration:  107 loss:  231501.69   style_loss:  250785.61   content_loss:  57946.336\n",
            "best: iteration:  108 loss:  228142.23   style_loss:  247050.84   content_loss:  57964.88\n",
            "best: iteration:  109 loss:  224841.52   style_loss:  243381.39   content_loss:  57982.67\n",
            "best: iteration:  110 loss:  221597.42   style_loss:  239775.06   content_loss:  57998.777\n",
            "best: iteration:  111 loss:  218408.16   style_loss:  236229.56   content_loss:  58015.68\n",
            "best: iteration:  112 loss:  215275.34   style_loss:  232746.61   content_loss:  58034.04\n",
            "best: iteration:  113 loss:  212193.78   style_loss:  229320.61   content_loss:  58052.344\n",
            "best: iteration:  114 loss:  209165.39   style_loss:  225953.7   content_loss:  58070.617\n",
            "best: iteration:  115 loss:  206187.33   style_loss:  222642.7   content_loss:  58089.03\n",
            "best: iteration:  116 loss:  203259.77   style_loss:  219387.94   content_loss:  58106.254\n",
            "best: iteration:  117 loss:  200379.72   style_loss:  216186.14   content_loss:  58122.0\n",
            "best: iteration:  118 loss:  197548.31   style_loss:  213038.34   content_loss:  58138.062\n",
            "best: iteration:  119 loss:  194763.36   style_loss:  209942.11   content_loss:  58154.72\n",
            "best: iteration:  120 loss:  192025.73   style_loss:  206898.6   content_loss:  58170.062\n",
            "best: iteration:  121 loss:  189331.14   style_loss:  203903.02   content_loss:  58184.438\n",
            "best: iteration:  122 loss:  186681.9   style_loss:  200957.66   content_loss:  58200.164\n",
            "best: iteration:  123 loss:  184075.53   style_loss:  198059.95   content_loss:  58215.832\n",
            "best: iteration:  124 loss:  181511.62   style_loss:  195209.66   content_loss:  58229.363\n",
            "best: iteration:  125 loss:  178989.12   style_loss:  192405.4   content_loss:  58242.633\n",
            "best: iteration:  126 loss:  176506.94   style_loss:  189645.72   content_loss:  58258.03\n",
            "best: iteration:  127 loss:  174065.05   style_loss:  186930.77   content_loss:  58273.57\n",
            "best: iteration:  128 loss:  171662.06   style_loss:  184259.31   content_loss:  58286.844\n",
            "best: iteration:  129 loss:  169297.14   style_loss:  181630.16   content_loss:  58300.062\n",
            "best: iteration:  130 loss:  166969.52   style_loss:  179042.22   content_loss:  58315.094\n",
            "best: iteration:  131 loss:  164678.23   style_loss:  176494.78   content_loss:  58329.33\n",
            "best: iteration:  132 loss:  162421.72   style_loss:  173986.22   content_loss:  58341.297\n",
            "best: iteration:  133 loss:  160200.86   style_loss:  171517.17   content_loss:  58354.01\n",
            "best: iteration:  134 loss:  158014.86   style_loss:  169086.67   content_loss:  58368.582\n",
            "best: iteration:  135 loss:  155862.89   style_loss:  166694.08   content_loss:  58382.164\n",
            "best: iteration:  136 loss:  153744.78   style_loss:  164339.28   content_loss:  58394.37\n",
            "best: iteration:  137 loss:  151660.16   style_loss:  162021.53   content_loss:  58407.75\n",
            "best: iteration:  138 loss:  149608.81   style_loss:  159740.72   content_loss:  58421.74\n",
            "best: iteration:  139 loss:  147590.22   style_loss:  157496.47   content_loss:  58434.08\n",
            "best: iteration:  140 loss:  145604.22   style_loss:  155288.44   content_loss:  58446.21\n",
            "best: iteration:  141 loss:  143649.9   style_loss:  153115.47   content_loss:  58459.82\n",
            "best: iteration:  142 loss:  141726.56   style_loss:  150976.94   content_loss:  58473.22\n",
            "best: iteration:  143 loss:  139833.44   style_loss:  148872.16   content_loss:  58484.93\n",
            "best: iteration:  144 loss:  137970.81   style_loss:  146801.22   content_loss:  58497.234\n",
            "best: iteration:  145 loss:  136138.28   style_loss:  144763.56   content_loss:  58510.85\n",
            "best: iteration:  146 loss:  134334.77   style_loss:  142758.22   content_loss:  58523.746\n",
            "best: iteration:  147 loss:  132560.23   style_loss:  140785.16   content_loss:  58535.895\n",
            "best: iteration:  148 loss:  130814.414   style_loss:  138843.97   content_loss:  58548.45\n",
            "best: iteration:  149 loss:  129097.195   style_loss:  136934.6   content_loss:  58560.62\n",
            "best: iteration:  150 loss:  127408.086   style_loss:  135056.58   content_loss:  58571.72\n",
            "best: iteration:  151 loss:  125746.73   style_loss:  133209.34   content_loss:  58583.17\n",
            "best: iteration:  152 loss:  124112.58   style_loss:  131392.27   content_loss:  58595.395\n",
            "best: iteration:  153 loss:  122505.25   style_loss:  129605.05   content_loss:  58607.113\n",
            "best: iteration:  154 loss:  120925.17   style_loss:  127848.17   content_loss:  58618.24\n",
            "best: iteration:  155 loss:  119372.09   style_loss:  126121.22   content_loss:  58629.996\n",
            "best: iteration:  156 loss:  117844.61   style_loss:  124422.7   content_loss:  58641.79\n",
            "best: iteration:  157 loss:  116343.375   style_loss:  122753.4   content_loss:  58653.23\n",
            "best: iteration:  158 loss:  114867.74   style_loss:  121112.5   content_loss:  58664.92\n",
            "best: iteration:  159 loss:  113417.52   style_loss:  119499.81   content_loss:  58676.938\n",
            "best: iteration:  160 loss:  111991.84   style_loss:  117914.44   content_loss:  58688.51\n",
            "best: iteration:  161 loss:  110589.89   style_loss:  116355.46   content_loss:  58699.78\n",
            "best: iteration:  162 loss:  109212.04   style_loss:  114823.27   content_loss:  58710.945\n",
            "best: iteration:  163 loss:  107857.914   style_loss:  113317.51   content_loss:  58721.586\n",
            "best: iteration:  164 loss:  106527.46   style_loss:  111838.11   content_loss:  58731.63\n",
            "best: iteration:  165 loss:  105220.55   style_loss:  110384.87   content_loss:  58741.703\n",
            "best: iteration:  166 loss:  103936.305   style_loss:  108956.79   content_loss:  58751.96\n",
            "best: iteration:  167 loss:  102675.055   style_loss:  107554.25   content_loss:  58762.344\n",
            "best: iteration:  168 loss:  101435.94   style_loss:  106176.33   content_loss:  58772.414\n",
            "best: iteration:  169 loss:  100218.73   style_loss:  104822.836   content_loss:  58781.82\n",
            "best: iteration:  170 loss:  99022.63   style_loss:  103492.83   content_loss:  58790.938\n",
            "best: iteration:  171 loss:  97847.53   style_loss:  102186.14   content_loss:  58800.047\n",
            "best: iteration:  172 loss:  96693.3   style_loss:  100902.67   content_loss:  58808.973\n",
            "best: iteration:  173 loss:  95559.2   style_loss:  99641.58   content_loss:  58817.863\n",
            "best: iteration:  174 loss:  94445.09   style_loss:  98402.69   content_loss:  58826.83\n",
            "best: iteration:  175 loss:  93350.7   style_loss:  97185.72   content_loss:  58835.58\n",
            "best: iteration:  176 loss:  92275.44   style_loss:  95990.05   content_loss:  58844.0\n",
            "best: iteration:  177 loss:  91219.734   style_loss:  94816.08   content_loss:  58852.67\n",
            "best: iteration:  178 loss:  90183.19   style_loss:  93663.34   content_loss:  58861.78\n",
            "best: iteration:  179 loss:  89165.484   style_loss:  92531.55   content_loss:  58870.973\n",
            "best: iteration:  180 loss:  88166.3   style_loss:  91420.33   content_loss:  58879.99\n",
            "best: iteration:  181 loss:  87184.836   style_loss:  90328.8   content_loss:  58889.254\n",
            "best: iteration:  182 loss:  86220.91   style_loss:  89256.69   content_loss:  58898.883\n",
            "best: iteration:  183 loss:  85273.85   style_loss:  88203.336   content_loss:  58908.504\n",
            "best: iteration:  184 loss:  84343.55   style_loss:  87168.61   content_loss:  58917.95\n",
            "best: iteration:  185 loss:  83430.125   style_loss:  86152.67   content_loss:  58927.215\n",
            "best: iteration:  186 loss:  82533.0   style_loss:  85154.86   content_loss:  58936.26\n",
            "best: iteration:  187 loss:  81651.67   style_loss:  84174.62   content_loss:  58945.184\n",
            "best: iteration:  188 loss:  80786.19   style_loss:  83211.984   content_loss:  58954.086\n",
            "best: iteration:  189 loss:  79936.28   style_loss:  82266.625   content_loss:  58963.234\n",
            "best: iteration:  190 loss:  79101.65   style_loss:  81338.25   content_loss:  58972.277\n",
            "best: iteration:  191 loss:  78281.9   style_loss:  80426.445   content_loss:  58981.0\n",
            "best: iteration:  192 loss:  77477.18   style_loss:  79531.34   content_loss:  58989.652\n",
            "best: iteration:  193 loss:  76687.34   style_loss:  78652.78   content_loss:  58998.406\n",
            "best: iteration:  194 loss:  75911.72   style_loss:  77790.01   content_loss:  59007.12\n",
            "best: iteration:  195 loss:  75149.97   style_loss:  76942.66   content_loss:  59015.805\n",
            "best: iteration:  196 loss:  74401.96   style_loss:  76110.58   content_loss:  59024.45\n",
            "best: iteration:  197 loss:  73667.98   style_loss:  75294.12   content_loss:  59032.723\n",
            "best: iteration:  198 loss:  72946.95   style_loss:  74492.08   content_loss:  59040.88\n",
            "best: iteration:  199 loss:  72239.13   style_loss:  73704.69   content_loss:  59049.137\n",
            "best: iteration:  0 loss:  2140017700.0   style_loss:  2377795800.0   content_loss:  14050.762\n",
            "best: iteration:  1 loss:  1923270300.0   style_loss:  2136964000.0   content_loss:  27310.023\n",
            "best: iteration:  2 loss:  1682722200.0   style_loss:  1869686400.0   content_loss:  44514.4\n",
            "best: iteration:  3 loss:  1485700400.0   style_loss:  1650771200.0   content_loss:  63014.863\n",
            "best: iteration:  4 loss:  1355394200.0   style_loss:  1505984600.0   content_loss:  80543.625\n",
            "best: iteration:  5 loss:  1284668000.0   style_loss:  1427398500.0   content_loss:  93972.44\n",
            "best: iteration:  6 loss:  1243521200.0   style_loss:  1381679000.0   content_loss:  101249.27\n",
            "best: iteration:  7 loss:  1205682600.0   style_loss:  1339635800.0   content_loss:  103152.875\n",
            "best: iteration:  8 loss:  1161680500.0   style_loss:  1290744800.0   content_loss:  101876.29\n",
            "best: iteration:  9 loss:  1113572900.0   style_loss:  1237292200.0   content_loss:  99224.04\n",
            "best: iteration:  10 loss:  1068022700.0   style_loss:  1186681200.0   content_loss:  96567.14\n",
            "best: iteration:  11 loss:  1029622900.0   style_loss:  1144015000.0   content_loss:  94615.76\n",
            "best: iteration:  12 loss:  997355840.0   style_loss:  1108162800.0   content_loss:  93477.98\n",
            "best: iteration:  13 loss:  969175700.0   style_loss:  1076851600.0   content_loss:  92992.46\n",
            "best: iteration:  14 loss:  943072300.0   style_loss:  1047847900.0   content_loss:  93029.3\n",
            "best: iteration:  15 loss:  917638800.0   style_loss:  1019588300.0   content_loss:  93428.86\n",
            "best: iteration:  16 loss:  893260350.0   style_loss:  992501060.0   content_loss:  94016.59\n",
            "best: iteration:  17 loss:  869425500.0   style_loss:  966017800.0   content_loss:  94699.04\n",
            "best: iteration:  18 loss:  847203800.0   style_loss:  941327000.0   content_loss:  95367.266\n",
            "best: iteration:  19 loss:  825955260.0   style_loss:  917717440.0   content_loss:  95962.57\n",
            "best: iteration:  20 loss:  805335100.0   style_loss:  894806100.0   content_loss:  96392.76\n",
            "best: iteration:  21 loss:  785572400.0   style_loss:  872847550.0   content_loss:  96590.6\n",
            "best: iteration:  22 loss:  766662300.0   style_loss:  851836200.0   content_loss:  96597.1\n",
            "best: iteration:  23 loss:  748559500.0   style_loss:  831722050.0   content_loss:  96537.266\n",
            "best: iteration:  24 loss:  730653800.0   style_loss:  811826900.0   content_loss:  96469.16\n",
            "best: iteration:  25 loss:  713631000.0   style_loss:  792912600.0   content_loss:  96504.51\n",
            "best: iteration:  26 loss:  697199500.0   style_loss:  774655360.0   content_loss:  96662.66\n",
            "best: iteration:  27 loss:  681388100.0   style_loss:  757087100.0   content_loss:  96977.195\n",
            "best: iteration:  28 loss:  666309760.0   style_loss:  740333400.0   content_loss:  97449.67\n",
            "best: iteration:  29 loss:  651635260.0   style_loss:  724028350.0   content_loss:  97974.945\n",
            "best: iteration:  30 loss:  637203100.0   style_loss:  707992450.0   content_loss:  98527.1\n",
            "best: iteration:  31 loss:  623224500.0   style_loss:  692460700.0   content_loss:  99042.77\n",
            "best: iteration:  32 loss:  609458000.0   style_loss:  677164540.0   content_loss:  99487.125\n",
            "best: iteration:  33 loss:  596026900.0   style_loss:  662241000.0   content_loss:  99876.93\n",
            "best: iteration:  34 loss:  582880450.0   style_loss:  647633800.0   content_loss:  100212.664\n",
            "best: iteration:  35 loss:  570201340.0   style_loss:  633545900.0   content_loss:  100515.66\n",
            "best: iteration:  36 loss:  557661400.0   style_loss:  619612540.0   content_loss:  100850.58\n",
            "best: iteration:  37 loss:  545217340.0   style_loss:  605785860.0   content_loss:  101244.04\n",
            "best: iteration:  38 loss:  533139650.0   style_loss:  592366100.0   content_loss:  101651.14\n",
            "best: iteration:  39 loss:  521200220.0   style_loss:  579100000.0   content_loss:  102070.305\n",
            "best: iteration:  40 loss:  509601280.0   style_loss:  566212300.0   content_loss:  102499.625\n",
            "best: iteration:  41 loss:  498003360.0   style_loss:  553325630.0   content_loss:  102917.44\n",
            "best: iteration:  42 loss:  486771170.0   style_loss:  540845400.0   content_loss:  103297.57\n",
            "best: iteration:  43 loss:  475588200.0   style_loss:  528419800.0   content_loss:  103674.7\n",
            "best: iteration:  44 loss:  464682050.0   style_loss:  516301860.0   content_loss:  104046.98\n",
            "best: iteration:  45 loss:  453879170.0   style_loss:  504298600.0   content_loss:  104370.57\n",
            "best: iteration:  46 loss:  443307500.0   style_loss:  492552260.0   content_loss:  104645.93\n",
            "best: iteration:  47 loss:  432965150.0   style_loss:  481060740.0   content_loss:  104914.695\n",
            "best: iteration:  48 loss:  422554240.0   style_loss:  469493020.0   content_loss:  105259.19\n",
            "best: iteration:  49 loss:  412480130.0   style_loss:  458299520.0   content_loss:  105603.14\n",
            "best: iteration:  50 loss:  402186340.0   style_loss:  446861950.0   content_loss:  105971.305\n",
            "best: iteration:  51 loss:  392274750.0   style_loss:  435849060.0   content_loss:  106327.76\n",
            "best: iteration:  52 loss:  382322600.0   style_loss:  424791040.0   content_loss:  106640.164\n",
            "best: iteration:  53 loss:  372721540.0   style_loss:  414123170.0   content_loss:  106946.27\n",
            "best: iteration:  54 loss:  363055100.0   style_loss:  403382660.0   content_loss:  107191.02\n",
            "best: iteration:  55 loss:  353527700.0   style_loss:  392796640.0   content_loss:  107418.42\n",
            "best: iteration:  56 loss:  343866720.0   style_loss:  382062200.0   content_loss:  107670.57\n",
            "best: iteration:  57 loss:  334492130.0   style_loss:  371645950.0   content_loss:  107925.234\n",
            "best: iteration:  58 loss:  325570300.0   style_loss:  361732770.0   content_loss:  108182.1\n",
            "best: iteration:  59 loss:  316644030.0   style_loss:  351814660.0   content_loss:  108394.76\n",
            "best: iteration:  60 loss:  307896540.0   style_loss:  342095230.0   content_loss:  108577.41\n",
            "best: iteration:  61 loss:  298850780.0   style_loss:  332044350.0   content_loss:  108806.84\n",
            "best: iteration:  62 loss:  290446200.0   style_loss:  322705900.0   content_loss:  108991.37\n",
            "best: iteration:  63 loss:  281582270.0   style_loss:  312857100.0   content_loss:  109258.03\n",
            "best: iteration:  64 loss:  273203840.0   style_loss:  303547680.0   content_loss:  109437.77\n",
            "best: iteration:  65 loss:  264915100.0   style_loss:  294337950.0   content_loss:  109678.29\n",
            "best: iteration:  66 loss:  256497460.0   style_loss:  284984960.0   content_loss:  109918.08\n",
            "best: iteration:  67 loss:  248312940.0   style_loss:  275891040.0   content_loss:  110156.08\n",
            "best: iteration:  68 loss:  240088320.0   style_loss:  266752540.0   content_loss:  110352.52\n",
            "best: iteration:  69 loss:  232062700.0   style_loss:  257835170.0   content_loss:  110541.36\n",
            "best: iteration:  70 loss:  224088540.0   style_loss:  248974980.0   content_loss:  110741.63\n",
            "best: iteration:  71 loss:  216437810.0   style_loss:  240474140.0   content_loss:  110956.74\n",
            "best: iteration:  72 loss:  209097420.0   style_loss:  232318130.0   content_loss:  111128.664\n",
            "best: iteration:  73 loss:  201847420.0   style_loss:  224262560.0   content_loss:  111278.6\n",
            "best: iteration:  74 loss:  194777360.0   style_loss:  216406930.0   content_loss:  111432.695\n",
            "best: iteration:  75 loss:  187665070.0   style_loss:  208504370.0   content_loss:  111545.7\n",
            "best: iteration:  76 loss:  180831570.0   style_loss:  200911570.0   content_loss:  111617.445\n",
            "best: iteration:  77 loss:  173829340.0   style_loss:  193131310.0   content_loss:  111742.055\n",
            "best: iteration:  78 loss:  167224530.0   style_loss:  185792600.0   content_loss:  111867.0\n",
            "best: iteration:  79 loss:  160802300.0   style_loss:  178656780.0   content_loss:  111974.09\n",
            "best: iteration:  80 loss:  154722370.0   style_loss:  171901280.0   content_loss:  112147.06\n",
            "best: iteration:  81 loss:  148641660.0   style_loss:  165144930.0   content_loss:  112283.734\n",
            "best: iteration:  82 loss:  142762830.0   style_loss:  158612880.0   content_loss:  112436.445\n",
            "best: iteration:  83 loss:  137052060.0   style_loss:  152267550.0   content_loss:  112617.52\n",
            "best: iteration:  84 loss:  131499250.0   style_loss:  146097740.0   content_loss:  112798.9\n",
            "best: iteration:  85 loss:  126223100.0   style_loss:  140235340.0   content_loss:  112922.06\n",
            "best: iteration:  86 loss:  121139010.0   style_loss:  134586340.0   content_loss:  113155.57\n",
            "best: iteration:  87 loss:  116289910.0   style_loss:  129198420.0   content_loss:  113418.1\n",
            "best: iteration:  88 loss:  111503150.0   style_loss:  123879780.0   content_loss:  113608.56\n",
            "best: iteration:  89 loss:  106816980.0   style_loss:  118672890.0   content_loss:  113790.13\n",
            "best: iteration:  90 loss:  102344344.0   style_loss:  113703270.0   content_loss:  113974.48\n",
            "best: iteration:  91 loss:  97977416.0   style_loss:  108851110.0   content_loss:  114139.69\n",
            "best: iteration:  92 loss:  93779880.0   style_loss:  104187170.0   content_loss:  114354.14\n",
            "best: iteration:  93 loss:  89927080.0   style_loss:  99906250.0   content_loss:  114533.21\n",
            "best: iteration:  94 loss:  86263490.0   style_loss:  95835570.0   content_loss:  114776.94\n",
            "best: iteration:  95 loss:  82875336.0   style_loss:  92070936.0   content_loss:  114929.64\n",
            "best: iteration:  96 loss:  79597200.0   style_loss:  88428540.0   content_loss:  115140.58\n",
            "best: iteration:  97 loss:  76528030.0   style_loss:  85018330.0   content_loss:  115357.055\n",
            "best: iteration:  98 loss:  73548240.0   style_loss:  81707420.0   content_loss:  115592.08\n",
            "best: iteration:  99 loss:  70681250.0   style_loss:  78521850.0   content_loss:  115817.09\n",
            "best: iteration:  100 loss:  68045810.0   style_loss:  75593570.0   content_loss:  115977.84\n",
            "best: iteration:  101 loss:  65626252.0   style_loss:  72905150.0   content_loss:  116177.695\n",
            "best: iteration:  102 loss:  63258530.0   style_loss:  70274330.0   content_loss:  116367.125\n",
            "best: iteration:  103 loss:  61092050.0   style_loss:  67867100.0   content_loss:  116546.14\n",
            "best: iteration:  104 loss:  58895144.0   style_loss:  65426076.0   content_loss:  116759.3\n",
            "best: iteration:  105 loss:  56918348.0   style_loss:  63229616.0   content_loss:  116963.0\n",
            "best: iteration:  106 loss:  55054228.0   style_loss:  61158348.0   content_loss:  117166.836\n",
            "best: iteration:  107 loss:  53272264.0   style_loss:  59178364.0   content_loss:  117362.66\n",
            "best: iteration:  108 loss:  51620524.0   style_loss:  57343076.0   content_loss:  117561.29\n",
            "best: iteration:  109 loss:  49951144.0   style_loss:  55488190.0   content_loss:  117730.43\n",
            "best: iteration:  110 loss:  48422932.0   style_loss:  53790160.0   content_loss:  117899.64\n",
            "best: iteration:  111 loss:  46926200.0   style_loss:  52127104.0   content_loss:  118060.555\n",
            "best: iteration:  112 loss:  45567080.0   style_loss:  50616950.0   content_loss:  118226.79\n",
            "best: iteration:  113 loss:  44257960.0   style_loss:  49162350.0   content_loss:  118424.53\n",
            "best: iteration:  114 loss:  43007710.0   style_loss:  47773176.0   content_loss:  118575.07\n",
            "best: iteration:  115 loss:  41818600.0   style_loss:  46451920.0   content_loss:  118731.23\n",
            "best: iteration:  116 loss:  40691310.0   style_loss:  45199356.0   content_loss:  118912.54\n",
            "best: iteration:  117 loss:  39607180.0   style_loss:  43994748.0   content_loss:  119086.055\n",
            "best: iteration:  118 loss:  38555628.0   style_loss:  42826336.0   content_loss:  119293.98\n",
            "best: iteration:  119 loss:  37560716.0   style_loss:  41720856.0   content_loss:  119468.0\n",
            "best: iteration:  120 loss:  36594270.0   style_loss:  40647010.0   content_loss:  119645.375\n",
            "best: iteration:  121 loss:  35665200.0   style_loss:  39614692.0   content_loss:  119781.5\n",
            "best: iteration:  122 loss:  34742510.0   style_loss:  38589470.0   content_loss:  119898.49\n",
            "best: iteration:  123 loss:  33844940.0   style_loss:  37592156.0   content_loss:  120010.06\n",
            "best: iteration:  124 loss:  33017138.0   style_loss:  36672364.0   content_loss:  120114.8\n",
            "best: iteration:  125 loss:  32249002.0   style_loss:  35818864.0   content_loss:  120260.695\n",
            "best: iteration:  126 loss:  31522538.0   style_loss:  35011668.0   content_loss:  120380.33\n",
            "best: iteration:  127 loss:  30782232.0   style_loss:  34189092.0   content_loss:  120500.0\n",
            "best: iteration:  128 loss:  30086406.0   style_loss:  33415940.0   content_loss:  120599.09\n",
            "best: iteration:  129 loss:  29376006.0   style_loss:  32626596.0   content_loss:  120707.734\n",
            "best: iteration:  130 loss:  28739488.0   style_loss:  31919344.0   content_loss:  120806.8\n",
            "best: iteration:  131 loss:  28129262.0   style_loss:  31241302.0   content_loss:  120894.53\n",
            "best: iteration:  132 loss:  27532424.0   style_loss:  30578142.0   content_loss:  120965.52\n",
            "best: iteration:  133 loss:  26954202.0   style_loss:  29935662.0   content_loss:  121068.39\n",
            "best: iteration:  134 loss:  26360568.0   style_loss:  29276054.0   content_loss:  121197.31\n",
            "best: iteration:  135 loss:  25859264.0   style_loss:  28719038.0   content_loss:  121305.81\n",
            "best: iteration:  136 loss:  25392806.0   style_loss:  28200736.0   content_loss:  121442.17\n",
            "best: iteration:  137 loss:  24920566.0   style_loss:  27676014.0   content_loss:  121541.43\n",
            "best: iteration:  138 loss:  24464636.0   style_loss:  27169414.0   content_loss:  121630.31\n",
            "best: iteration:  139 loss:  23999462.0   style_loss:  26652540.0   content_loss:  121753.336\n",
            "best: iteration:  140 loss:  23580578.0   style_loss:  26187108.0   content_loss:  121817.945\n",
            "best: iteration:  141 loss:  23172154.0   style_loss:  25733294.0   content_loss:  121904.664\n",
            "best: iteration:  142 loss:  22763022.0   style_loss:  25278692.0   content_loss:  122001.57\n",
            "best: iteration:  143 loss:  22377812.0   style_loss:  24850672.0   content_loss:  122072.266\n",
            "best: iteration:  144 loss:  22002242.0   style_loss:  24433368.0   content_loss:  122120.87\n",
            "best: iteration:  145 loss:  21636964.0   style_loss:  24027496.0   content_loss:  122187.234\n",
            "best: iteration:  146 loss:  21277766.0   style_loss:  23628378.0   content_loss:  122266.836\n",
            "best: iteration:  147 loss:  20941322.0   style_loss:  23254544.0   content_loss:  122318.74\n",
            "best: iteration:  148 loss:  20607970.0   style_loss:  22884148.0   content_loss:  122389.92\n",
            "best: iteration:  149 loss:  20281582.0   style_loss:  22521484.0   content_loss:  122469.66\n",
            "best: iteration:  150 loss:  19974458.0   style_loss:  22180230.0   content_loss:  122518.97\n",
            "best: iteration:  151 loss:  19682760.0   style_loss:  21856116.0   content_loss:  122565.76\n",
            "best: iteration:  152 loss:  19399976.0   style_loss:  21541904.0   content_loss:  122614.66\n",
            "best: iteration:  153 loss:  19121720.0   style_loss:  21232732.0   content_loss:  122625.92\n",
            "best: iteration:  154 loss:  18846302.0   style_loss:  20926708.0   content_loss:  122662.51\n",
            "best: iteration:  155 loss:  18558476.0   style_loss:  20606894.0   content_loss:  122716.7\n",
            "best: iteration:  156 loss:  18279266.0   style_loss:  20296656.0   content_loss:  122754.97\n",
            "best: iteration:  157 loss:  18008378.0   style_loss:  19995666.0   content_loss:  122804.734\n",
            "best: iteration:  158 loss:  17785902.0   style_loss:  19748466.0   content_loss:  122838.89\n",
            "best: iteration:  159 loss:  17561152.0   style_loss:  19498736.0   content_loss:  122899.766\n",
            "best: iteration:  160 loss:  17332994.0   style_loss:  19245222.0   content_loss:  122937.69\n",
            "best: iteration:  161 loss:  17091688.0   style_loss:  18977100.0   content_loss:  122982.08\n",
            "best: iteration:  162 loss:  16860180.0   style_loss:  18719868.0   content_loss:  122997.664\n",
            "best: iteration:  163 loss:  16621226.0   style_loss:  18454360.0   content_loss:  123022.445\n",
            "best: iteration:  164 loss:  16402686.0   style_loss:  18211538.0   content_loss:  123020.23\n",
            "best: iteration:  165 loss:  16195318.0   style_loss:  17981124.0   content_loss:  123066.2\n",
            "best: iteration:  166 loss:  16020001.0   style_loss:  17786324.0   content_loss:  123104.96\n",
            "best: iteration:  167 loss:  15850915.0   style_loss:  17598446.0   content_loss:  123135.37\n",
            "best: iteration:  168 loss:  15676374.0   style_loss:  17404508.0   content_loss:  123171.57\n",
            "best: iteration:  169 loss:  15494921.0   style_loss:  17202894.0   content_loss:  123171.57\n",
            "best: iteration:  170 loss:  15300907.0   style_loss:  16987318.0   content_loss:  123210.734\n",
            "best: iteration:  171 loss:  15118245.0   style_loss:  16784358.0   content_loss:  123225.66\n",
            "best: iteration:  172 loss:  14958325.0   style_loss:  16606665.0   content_loss:  123268.336\n",
            "best: iteration:  173 loss:  14820843.0   style_loss:  16453905.0   content_loss:  123293.836\n",
            "best: iteration:  174 loss:  14690252.0   style_loss:  16308800.0   content_loss:  123316.08\n",
            "best: iteration:  175 loss:  14563877.0   style_loss:  16168382.0   content_loss:  123341.3\n",
            "best: iteration:  176 loss:  14424593.0   style_loss:  16013618.0   content_loss:  123373.44\n",
            "best: iteration:  177 loss:  14285156.0   style_loss:  15858687.0   content_loss:  123382.64\n",
            "best: iteration:  178 loss:  14135748.0   style_loss:  15692674.0   content_loss:  123423.24\n",
            "best: iteration:  179 loss:  13998705.0   style_loss:  15540402.0   content_loss:  123443.39\n",
            "best: iteration:  180 loss:  13883134.0   style_loss:  15411986.0   content_loss:  123469.07\n",
            "best: iteration:  181 loss:  13765548.0   style_loss:  15281331.0   content_loss:  123502.97\n",
            "best: iteration:  182 loss:  13648145.0   style_loss:  15150880.0   content_loss:  123529.4\n",
            "best: iteration:  183 loss:  13526013.0   style_loss:  15015174.0   content_loss:  123573.9\n",
            "best: iteration:  184 loss:  13410458.0   style_loss:  14886776.0   content_loss:  123603.805\n",
            "best: iteration:  185 loss:  13297579.0   style_loss:  14761352.0   content_loss:  123631.125\n",
            "best: iteration:  186 loss:  13191422.0   style_loss:  14643396.0   content_loss:  123655.19\n",
            "best: iteration:  187 loss:  13087615.0   style_loss:  14528053.0   content_loss:  123683.9\n",
            "best: iteration:  188 loss:  12981254.0   style_loss:  14409870.0   content_loss:  123707.07\n",
            "best: iteration:  189 loss:  12876738.0   style_loss:  14293740.0   content_loss:  123720.23\n",
            "best: iteration:  190 loss:  12768910.0   style_loss:  14173929.0   content_loss:  123737.734\n",
            "best: iteration:  191 loss:  12669090.0   style_loss:  14063016.0   content_loss:  123759.58\n",
            "best: iteration:  192 loss:  12563421.0   style_loss:  13945602.0   content_loss:  123795.04\n",
            "best: iteration:  193 loss:  12468780.0   style_loss:  13840443.0   content_loss:  123821.81\n",
            "best: iteration:  194 loss:  12375585.0   style_loss:  13736889.0   content_loss:  123849.37\n",
            "best: iteration:  195 loss:  12285859.0   style_loss:  13637190.0   content_loss:  123877.125\n",
            "best: iteration:  196 loss:  12189242.0   style_loss:  13529835.0   content_loss:  123912.48\n",
            "best: iteration:  197 loss:  12094229.0   style_loss:  13424261.0   content_loss:  123936.61\n",
            "best: iteration:  198 loss:  11997350.0   style_loss:  13316616.0   content_loss:  123963.164\n",
            "best: iteration:  199 loss:  11909572.0   style_loss:  13219080.0   content_loss:  124001.7\n",
            "best: iteration:  0 loss:  140427900.0   style_loss:  156029550.0   content_loss:  13168.583\n",
            "best: iteration:  1 loss:  120211176.0   style_loss:  133565380.0   content_loss:  23435.494\n",
            "best: iteration:  2 loss:  105931590.0   style_loss:  117698570.0   content_loss:  28772.602\n",
            "best: iteration:  3 loss:  96704184.0   style_loss:  107445630.0   content_loss:  31171.918\n",
            "best: iteration:  4 loss:  89739910.0   style_loss:  99707450.0   content_loss:  32107.867\n",
            "best: iteration:  5 loss:  83503300.0   style_loss:  92777830.0   content_loss:  32506.842\n",
            "best: iteration:  6 loss:  77822910.0   style_loss:  86466264.0   content_loss:  32795.836\n",
            "best: iteration:  7 loss:  72553070.0   style_loss:  80610860.0   content_loss:  32986.734\n",
            "best: iteration:  8 loss:  67439220.0   style_loss:  74928770.0   content_loss:  33299.76\n",
            "best: iteration:  9 loss:  62687668.0   style_loss:  69649224.0   content_loss:  33674.035\n",
            "best: iteration:  10 loss:  58530164.0   style_loss:  65029732.0   content_loss:  34098.613\n",
            "best: iteration:  11 loss:  54811388.0   style_loss:  60897700.0   content_loss:  34614.344\n",
            "best: iteration:  12 loss:  51332696.0   style_loss:  57032428.0   content_loss:  35120.277\n",
            "best: iteration:  13 loss:  48060264.0   style_loss:  53396340.0   content_loss:  35612.81\n",
            "best: iteration:  14 loss:  45010630.0   style_loss:  50007800.0   content_loss:  36120.676\n",
            "best: iteration:  15 loss:  42082736.0   style_loss:  46754520.0   content_loss:  36665.79\n",
            "best: iteration:  16 loss:  39259116.0   style_loss:  43617108.0   content_loss:  37188.305\n",
            "best: iteration:  17 loss:  36551800.0   style_loss:  40608924.0   content_loss:  37681.234\n",
            "best: iteration:  18 loss:  33941100.0   style_loss:  37708090.0   content_loss:  38188.27\n",
            "best: iteration:  19 loss:  31464952.0   style_loss:  34956760.0   content_loss:  38679.152\n",
            "best: iteration:  20 loss:  29124774.0   style_loss:  32356514.0   content_loss:  39111.586\n",
            "best: iteration:  21 loss:  26888212.0   style_loss:  29871400.0   content_loss:  39510.387\n",
            "best: iteration:  22 loss:  24754002.0   style_loss:  27500012.0   content_loss:  39919.56\n",
            "best: iteration:  23 loss:  22722410.0   style_loss:  25242644.0   content_loss:  40323.875\n",
            "best: iteration:  24 loss:  20802858.0   style_loss:  23109764.0   content_loss:  40703.703\n",
            "best: iteration:  25 loss:  18991500.0   style_loss:  21097102.0   content_loss:  41087.42\n",
            "best: iteration:  26 loss:  17279968.0   style_loss:  19195358.0   content_loss:  41457.887\n",
            "best: iteration:  27 loss:  15673850.0   style_loss:  17410750.0   content_loss:  41753.055\n",
            "best: iteration:  28 loss:  14181447.0   style_loss:  15752495.0   content_loss:  42015.18\n",
            "best: iteration:  29 loss:  12782874.0   style_loss:  14198498.0   content_loss:  42262.414\n",
            "best: iteration:  30 loss:  11489523.0   style_loss:  12761413.0   content_loss:  42515.703\n",
            "best: iteration:  31 loss:  10315173.0   style_loss:  11456553.0   content_loss:  42764.023\n",
            "best: iteration:  32 loss:  9239093.0   style_loss:  10260880.0   content_loss:  43006.1\n",
            "best: iteration:  33 loss:  8262009.0   style_loss:  9175205.0   content_loss:  43246.664\n",
            "best: iteration:  34 loss:  7361451.0   style_loss:  8174561.0   content_loss:  43465.844\n",
            "best: iteration:  35 loss:  6544672.5   style_loss:  7267004.5   content_loss:  43682.67\n",
            "best: iteration:  36 loss:  5805496.0   style_loss:  6445673.5   content_loss:  43898.145\n",
            "best: iteration:  37 loss:  5145480.5   style_loss:  5712299.0   content_loss:  44113.695\n",
            "best: iteration:  38 loss:  4559270.5   style_loss:  5060933.0   content_loss:  44308.387\n",
            "best: iteration:  39 loss:  4043000.8   style_loss:  4487280.5   content_loss:  44484.113\n",
            "best: iteration:  40 loss:  3585691.8   style_loss:  3979140.8   content_loss:  44652.23\n",
            "best: iteration:  41 loss:  3183273.5   style_loss:  3531990.5   content_loss:  44822.664\n",
            "best: iteration:  42 loss:  2835256.5   style_loss:  3145285.2   content_loss:  44998.598\n",
            "best: iteration:  43 loss:  2537312.0   style_loss:  2814216.5   content_loss:  45173.348\n",
            "best: iteration:  44 loss:  2281853.8   style_loss:  2530355.2   content_loss:  45339.062\n",
            "best: iteration:  45 loss:  2062747.2   style_loss:  2286887.0   content_loss:  45489.887\n",
            "best: iteration:  46 loss:  1874830.2   style_loss:  2078074.2   content_loss:  45635.13\n",
            "best: iteration:  47 loss:  1715101.1   style_loss:  1900581.9   content_loss:  45774.45\n",
            "best: iteration:  48 loss:  1579796.9   style_loss:  1750229.4   content_loss:  45905.48\n",
            "best: iteration:  49 loss:  1464259.8   style_loss:  1621841.8   content_loss:  46023.05\n",
            "best: iteration:  50 loss:  1365646.4   style_loss:  1512259.4   content_loss:  46129.703\n",
            "best: iteration:  51 loss:  1280759.1   style_loss:  1417929.4   content_loss:  46228.027\n",
            "best: iteration:  52 loss:  1207372.5   style_loss:  1336377.4   content_loss:  46329.03\n",
            "best: iteration:  53 loss:  1143707.2   style_loss:  1265626.6   content_loss:  46434.266\n",
            "best: iteration:  54 loss:  1088192.1   style_loss:  1203931.5   content_loss:  46537.77\n",
            "best: iteration:  55 loss:  1039302.3   style_loss:  1149598.5   content_loss:  46636.785\n",
            "best: iteration:  56 loss:  995109.25   style_loss:  1100484.4   content_loss:  46733.43\n",
            "best: iteration:  57 loss:  954740.75   style_loss:  1055619.5   content_loss:  46832.656\n",
            "best: iteration:  58 loss:  917476.9   style_loss:  1014204.0   content_loss:  46932.906\n",
            "best: iteration:  59 loss:  882708.9   style_loss:  975562.44   content_loss:  47027.094\n",
            "best: iteration:  60 loss:  849913.6   style_loss:  939114.1   content_loss:  47109.598\n",
            "best: iteration:  61 loss:  818766.75   style_loss:  904498.75   content_loss:  47179.027\n",
            "best: iteration:  62 loss:  789054.06   style_loss:  871477.4   content_loss:  47244.53\n",
            "best: iteration:  63 loss:  760749.1   style_loss:  840020.0   content_loss:  47311.027\n",
            "best: iteration:  64 loss:  733931.8   style_loss:  810215.6   content_loss:  47377.74\n",
            "best: iteration:  65 loss:  708543.6   style_loss:  781999.06   content_loss:  47445.3\n",
            "best: iteration:  66 loss:  684394.25   style_loss:  755159.44   content_loss:  47507.195\n",
            "best: iteration:  67 loss:  661339.25   style_loss:  729536.8   content_loss:  47561.0\n",
            "best: iteration:  68 loss:  639340.44   style_loss:  705088.3   content_loss:  47609.99\n",
            "best: iteration:  69 loss:  618534.3   style_loss:  681964.9   content_loss:  47659.516\n",
            "best: iteration:  70 loss:  598882.56   style_loss:  660123.75   content_loss:  47711.97\n",
            "best: iteration:  71 loss:  580348.1   style_loss:  639524.1   content_loss:  47764.504\n",
            "best: iteration:  72 loss:  562854.06   style_loss:  620080.75   content_loss:  47813.887\n",
            "best: iteration:  73 loss:  546374.75   style_loss:  601765.4   content_loss:  47859.418\n",
            "best: iteration:  74 loss:  530906.25   style_loss:  584573.1   content_loss:  47904.582\n",
            "best: iteration:  75 loss:  516352.7   style_loss:  568397.1   content_loss:  47952.715\n",
            "best: iteration:  76 loss:  502662.56   style_loss:  553180.3   content_loss:  48002.902\n",
            "best: iteration:  77 loss:  489821.9   style_loss:  538907.44   content_loss:  48052.285\n",
            "best: iteration:  78 loss:  477765.44   style_loss:  525506.06   content_loss:  48100.062\n",
            "best: iteration:  79 loss:  466478.34   style_loss:  512959.47   content_loss:  48148.414\n",
            "best: iteration:  80 loss:  455894.8   style_loss:  501194.44   content_loss:  48198.285\n",
            "best: iteration:  81 loss:  445934.88   style_loss:  490122.38   content_loss:  48247.355\n",
            "best: iteration:  82 loss:  436535.38   style_loss:  479673.5   content_loss:  48292.613\n",
            "best: iteration:  83 loss:  427650.4   style_loss:  469796.7   content_loss:  48334.02\n",
            "best: iteration:  84 loss:  419234.84   style_loss:  460441.66   content_loss:  48373.832\n",
            "best: iteration:  85 loss:  411252.8   style_loss:  451568.34   content_loss:  48413.055\n",
            "best: iteration:  86 loss:  403669.75   style_loss:  443138.34   content_loss:  48452.37\n",
            "best: iteration:  87 loss:  396442.03   style_loss:  435103.1   content_loss:  48492.582\n",
            "best: iteration:  88 loss:  389563.6   style_loss:  427455.88   content_loss:  48533.234\n",
            "best: iteration:  89 loss:  382997.94   style_loss:  420156.16   content_loss:  48574.004\n",
            "best: iteration:  90 loss:  376709.06   style_loss:  413163.97   content_loss:  48615.016\n",
            "best: iteration:  91 loss:  370672.0   style_loss:  406451.56   content_loss:  48656.066\n",
            "best: iteration:  92 loss:  364867.75   style_loss:  399997.75   content_loss:  48697.77\n",
            "best: iteration:  93 loss:  359262.4   style_loss:  393764.94   content_loss:  48739.645\n",
            "best: iteration:  94 loss:  353866.97   style_loss:  387765.4   content_loss:  48781.195\n",
            "best: iteration:  95 loss:  348671.16   style_loss:  381987.72   content_loss:  48822.137\n",
            "best: iteration:  96 loss:  343632.1   style_loss:  376384.5   content_loss:  48860.715\n",
            "best: iteration:  97 loss:  338743.56   style_loss:  370948.7   content_loss:  48897.363\n",
            "best: iteration:  98 loss:  334011.78   style_loss:  365687.38   content_loss:  48931.504\n",
            "best: iteration:  99 loss:  329431.78   style_loss:  360594.88   content_loss:  48964.133\n",
            "best: iteration:  100 loss:  325000.0   style_loss:  355667.12   content_loss:  48995.92\n",
            "best: iteration:  101 loss:  320712.84   style_loss:  350900.12   content_loss:  49027.535\n",
            "best: iteration:  102 loss:  316549.38   style_loss:  346270.62   content_loss:  49058.254\n",
            "best: iteration:  103 loss:  312509.0   style_loss:  341777.97   content_loss:  49088.535\n",
            "best: iteration:  104 loss:  308578.62   style_loss:  337407.53   content_loss:  49118.285\n",
            "best: iteration:  105 loss:  304758.97   style_loss:  333160.25   content_loss:  49147.527\n",
            "best: iteration:  106 loss:  301039.7   style_loss:  329024.47   content_loss:  49176.88\n",
            "best: iteration:  107 loss:  297422.53   style_loss:  325002.12   content_loss:  49206.168\n",
            "best: iteration:  108 loss:  293897.12   style_loss:  321081.88   content_loss:  49234.496\n",
            "best: iteration:  109 loss:  290469.47   style_loss:  317270.34   content_loss:  49261.684\n",
            "best: iteration:  110 loss:  287129.12   style_loss:  313555.84   content_loss:  49288.645\n",
            "best: iteration:  111 loss:  283875.12   style_loss:  309937.25   content_loss:  49315.855\n",
            "best: iteration:  112 loss:  280704.72   style_loss:  306411.5   content_loss:  49343.746\n",
            "best: iteration:  113 loss:  277623.5   style_loss:  302984.84   content_loss:  49371.598\n",
            "best: iteration:  114 loss:  274618.9   style_loss:  299643.38   content_loss:  49398.754\n",
            "best: iteration:  115 loss:  271685.12   style_loss:  296380.7   content_loss:  49424.88\n",
            "best: iteration:  116 loss:  268826.8   style_loss:  293201.9   content_loss:  49450.906\n",
            "best: iteration:  117 loss:  266037.1   style_loss:  290099.4   content_loss:  49476.535\n",
            "best: iteration:  118 loss:  263308.0   style_loss:  287064.3   content_loss:  49501.38\n",
            "best: iteration:  119 loss:  260645.22   style_loss:  284103.0   content_loss:  49525.383\n",
            "best: iteration:  120 loss:  258043.31   style_loss:  281209.38   content_loss:  49548.83\n",
            "best: iteration:  121 loss:  255495.16   style_loss:  278375.6   content_loss:  49571.203\n",
            "best: iteration:  122 loss:  253007.53   style_loss:  275609.2   content_loss:  49592.58\n",
            "best: iteration:  123 loss:  250578.95   style_loss:  272908.5   content_loss:  49613.1\n",
            "best: iteration:  124 loss:  248205.53   style_loss:  270269.16   content_loss:  49633.01\n",
            "best: iteration:  125 loss:  245888.83   style_loss:  267692.88   content_loss:  49652.57\n",
            "best: iteration:  126 loss:  243612.05   style_loss:  265160.94   content_loss:  49671.96\n",
            "best: iteration:  127 loss:  241382.03   style_loss:  262681.03   content_loss:  49691.145\n",
            "best: iteration:  128 loss:  239201.16   style_loss:  260255.84   content_loss:  49709.062\n",
            "best: iteration:  129 loss:  237065.14   style_loss:  257880.64   content_loss:  49725.633\n",
            "best: iteration:  130 loss:  234968.19   style_loss:  255548.88   content_loss:  49742.066\n",
            "best: iteration:  131 loss:  232914.48   style_loss:  253265.12   content_loss:  49758.715\n",
            "best: iteration:  132 loss:  230900.12   style_loss:  251025.1   content_loss:  49775.45\n",
            "best: iteration:  133 loss:  228921.6   style_loss:  248824.81   content_loss:  49792.645\n",
            "best: iteration:  134 loss:  226984.14   style_loss:  246670.19   content_loss:  49809.797\n",
            "best: iteration:  135 loss:  225087.94   style_loss:  244561.5   content_loss:  49825.973\n",
            "best: iteration:  136 loss:  223223.25   style_loss:  242487.89   content_loss:  49841.49\n",
            "best: iteration:  137 loss:  221387.66   style_loss:  240446.62   content_loss:  49857.094\n",
            "best: iteration:  138 loss:  219589.12   style_loss:  238446.53   content_loss:  49872.496\n",
            "best: iteration:  139 loss:  217825.42   style_loss:  236485.22   content_loss:  49887.35\n",
            "best: iteration:  140 loss:  216091.78   style_loss:  234557.27   content_loss:  49902.473\n",
            "best: iteration:  141 loss:  214387.23   style_loss:  232661.66   content_loss:  49917.54\n",
            "best: iteration:  142 loss:  212712.23   style_loss:  230798.84   content_loss:  49932.79\n",
            "best: iteration:  143 loss:  211062.9   style_loss:  228964.6   content_loss:  49947.855\n",
            "best: iteration:  144 loss:  209446.08   style_loss:  227166.44   content_loss:  49962.902\n",
            "best: iteration:  145 loss:  207852.69   style_loss:  225394.3   content_loss:  49978.297\n",
            "best: iteration:  146 loss:  206282.58   style_loss:  223648.0   content_loss:  49993.844\n",
            "best: iteration:  147 loss:  204740.47   style_loss:  221932.84   content_loss:  50009.215\n",
            "best: iteration:  148 loss:  203222.28   style_loss:  220244.28   content_loss:  50024.387\n",
            "best: iteration:  149 loss:  201731.0   style_loss:  218585.62   content_loss:  50039.383\n",
            "best: iteration:  150 loss:  200263.53   style_loss:  216953.5   content_loss:  50053.863\n",
            "best: iteration:  151 loss:  198819.98   style_loss:  215348.0   content_loss:  50067.918\n",
            "best: iteration:  152 loss:  197392.75   style_loss:  213760.66   content_loss:  50081.695\n",
            "best: iteration:  153 loss:  195987.34   style_loss:  212197.6   content_loss:  50095.215\n",
            "best: iteration:  154 loss:  194603.88   style_loss:  210658.98   content_loss:  50108.03\n",
            "best: iteration:  155 loss:  193240.02   style_loss:  209142.16   content_loss:  50120.754\n",
            "best: iteration:  156 loss:  191894.28   style_loss:  207645.44   content_loss:  50133.844\n",
            "best: iteration:  157 loss:  190567.9   style_loss:  206170.23   content_loss:  50147.03\n",
            "best: iteration:  158 loss:  189260.36   style_loss:  204715.97   content_loss:  50160.03\n",
            "best: iteration:  159 loss:  187968.17   style_loss:  203278.75   content_loss:  50173.035\n",
            "best: iteration:  160 loss:  186692.25   style_loss:  201859.62   content_loss:  50185.95\n",
            "best: iteration:  161 loss:  185432.42   style_loss:  200458.45   content_loss:  50198.12\n",
            "best: iteration:  162 loss:  184189.61   style_loss:  199076.19   content_loss:  50210.46\n",
            "best: iteration:  163 loss:  182962.14   style_loss:  197710.89   content_loss:  50223.414\n",
            "best: iteration:  164 loss:  181753.89   style_loss:  196366.89   content_loss:  50236.844\n",
            "best: iteration:  165 loss:  180561.98   style_loss:  195041.11   content_loss:  50249.836\n",
            "best: iteration:  166 loss:  179382.88   style_loss:  193729.55   content_loss:  50262.83\n",
            "best: iteration:  167 loss:  178220.39   style_loss:  192436.45   content_loss:  50275.96\n",
            "best: iteration:  168 loss:  177076.58   style_loss:  191164.16   content_loss:  50288.4\n",
            "best: iteration:  169 loss:  175949.31   style_loss:  189910.25   content_loss:  50300.9\n",
            "best: iteration:  170 loss:  174837.22   style_loss:  188673.22   content_loss:  50313.266\n",
            "best: iteration:  171 loss:  173738.48   style_loss:  187451.14   content_loss:  50324.688\n",
            "best: iteration:  172 loss:  172653.39   style_loss:  186244.28   content_loss:  50335.434\n",
            "best: iteration:  173 loss:  171582.7   style_loss:  185053.4   content_loss:  50346.37\n",
            "best: iteration:  174 loss:  170522.88   style_loss:  183874.61   content_loss:  50357.37\n",
            "best: iteration:  175 loss:  169478.06   style_loss:  182712.47   content_loss:  50368.387\n",
            "best: iteration:  176 loss:  168445.72   style_loss:  181564.19   content_loss:  50379.58\n",
            "best: iteration:  177 loss:  167424.4   style_loss:  180428.22   content_loss:  50390.203\n",
            "best: iteration:  178 loss:  166417.36   style_loss:  179308.22   content_loss:  50399.71\n",
            "best: iteration:  179 loss:  165421.56   style_loss:  178200.72   content_loss:  50409.26\n",
            "best: iteration:  180 loss:  164438.0   style_loss:  177106.78   content_loss:  50419.05\n",
            "best: iteration:  181 loss:  163468.22   style_loss:  176028.2   content_loss:  50428.42\n",
            "best: iteration:  182 loss:  162508.77   style_loss:  174961.1   content_loss:  50437.88\n",
            "best: iteration:  183 loss:  161562.47   style_loss:  173908.55   content_loss:  50447.777\n",
            "best: iteration:  184 loss:  160625.81   style_loss:  172866.72   content_loss:  50457.6\n",
            "best: iteration:  185 loss:  159699.3   style_loss:  171836.17   content_loss:  50467.57\n",
            "best: iteration:  186 loss:  158783.14   style_loss:  170817.08   content_loss:  50477.83\n",
            "best: iteration:  187 loss:  157877.39   style_loss:  169809.6   content_loss:  50487.715\n",
            "best: iteration:  188 loss:  156982.3   style_loss:  168813.97   content_loss:  50497.395\n",
            "best: iteration:  189 loss:  156098.27   style_loss:  167830.6   content_loss:  50507.37\n",
            "best: iteration:  190 loss:  155221.6   style_loss:  166855.44   content_loss:  50517.016\n",
            "best: iteration:  191 loss:  154353.45   style_loss:  165889.78   content_loss:  50526.51\n",
            "best: iteration:  192 loss:  153493.92   style_loss:  164933.69   content_loss:  50536.117\n",
            "best: iteration:  193 loss:  152644.8   style_loss:  163989.12   content_loss:  50545.918\n",
            "best: iteration:  194 loss:  151802.36   style_loss:  163052.06   content_loss:  50555.07\n",
            "best: iteration:  195 loss:  150970.1   style_loss:  162126.33   content_loss:  50564.07\n",
            "best: iteration:  196 loss:  150142.97   style_loss:  161206.31   content_loss:  50573.047\n",
            "best: iteration:  197 loss:  149325.69   style_loss:  160297.22   content_loss:  50581.918\n",
            "best: iteration:  198 loss:  148516.17   style_loss:  159396.73   content_loss:  50591.137\n",
            "best: iteration:  199 loss:  147716.02   style_loss:  158506.61   content_loss:  50600.83\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QHeZIi_P-gri",
        "colab_type": "text"
      },
      "source": [
        "# New Section"
      ]
    }
  ]
}